window.pages = [{"id":0,"title":"Interim Accreditation Process","heading":"Introduction","path":"./data-integration/accreditation/accreditation-process.html#introduction","content":"\r\n1. This paper outlines an interim accreditation process for integrating authorities undertaking high risk (Endnote 1) data integration projects involving Commonwealth data for statistical and research purposes, along with the criteria that must be met by agencies to gain accreditation. Accreditation is a key element in the governance and institutional arrangements for data integration. The aim of these arrangements is to ensure a safe and effective environment for data integration projects involving Commonwealth data. \r\n2. The interim accreditation process is an administrative scheme which does not over-ride legislation. All legal obligations (for example, obligations resulting from the Privacy Act 1988 (Privacy Act) or privacy and secrecy clauses in agency-specific legislation) must still be met. "},{"id":1,"title":"Interim Accreditation Process","heading":"Background","path":"./data-integration/accreditation/accreditation-process.html#background","content":"\r\n3.The High Level Principles for Data Integration involving Commonwealth Data for Statistical and Research Purposes stipulate that an integrating authority will be nominated for every data integration project (even the low risk ones) involving Commonwealth data for statistical and research purposes. Jointly with the data custodian(s) (owners of the datasets to be integrated), the integrating authority is accountable for the data integration project. The integrating authority, along with the data custodian(s), is responsible for achieving an appropriate balance between: maximising the inherent value of Commonwealth data sources; minimising privacy concerns and confidentiality concerns associated with the use of data before, during and after it has been integrated; and facilitating the use of this data within the constraints of privacy, confidentiality and the law. \r\n4.The four main roles of an integrating authority are to: \r\nnegotiate and implement arrangements with data custodians to achieve adequate control and manage risk appropriate to their datasets;\r\nimplement a safe and effective environment for data integration projects involving Commonwealth data;\r\nmanage datasets for the project, including providing suitable access for data users and ensuring that the agreed data retention/data destruction policies are carried out; and\r\nbe transparent in their operation.\r\n5. An accredited Integrating Authority must be used for high risk data integration projects involving Commonwealth data. The data custodian(s) will determine the risk rating of each project or family of projects. \r\n6. Using an accredited Integrating Authority does not guarantee access to data for a particular data integration project. Access to data needs to be negotiated with data custodians for each project (or for a family of data integration projects using the same source datasets, for similar purposes, with the same integrating authority). "},{"id":2,"title":"Interim Accreditation Process","heading":"Process for interim accreditation of integrating authorities to undertake high-risk data integration projects involving Commonwealth data","path":"./data-integration/accreditation/accreditation-process.html#process-for-interim-accreditation-of-integrating-authorities-to-undertake-high-risk-data-integration-projects-involving-commonwealth-data","content":"\r\n7. The process for interim accreditation of integrating authorities, which picks up key elements of Australian accreditation processes in the education and health sectors, involves: \r\n\r\nSelf-assessment. Integrating authorities apply for accreditation by preparing a self-assessment report explaining how they meet the criteria for accreditation. A template for the report is given at attachment 1. The criteria are presented in paragraphs 16 and 17 of this paper. The assessment must be signed off by the head of the agency (Endnote 2) or the application will not be considered. \r\n\r\nGenerally, the self-assessment will be no more than 20 pages long. Commonwealth data integration accreditation has recently undergone a period of review. The interim Data Integration Accreditation Subcommittee Secretariat can provide information on the governance and application process. Please email dsdg-coord@pmc.gov.au\r\n\r\nAudit. An independent third party audits the integrating authority\u2019s self-assessment against the criteria, in line with the ANAO Auditing Standards. If an integrating authority can demonstrate that a suitable program of audits has been done recently (in the two years prior to the application), these audits can be used to reduce the scope of the integrating authority accreditation audit.\r\nDecision. The Cross Portfolio Data Integration Oversight Board (Endnote 3) will make the final decision on interim accreditation, based on the self-assessment and results of the audit. Once a decision is made, a full report explaining the compliant and non-compliant criteria, with recommendations for what needs to change, will be supplied to the applicant.\r\nPublication of list of accredited agencies. The Secretariat will publish a list of accredited Integrating Authorities, together with a summarised version of the integrating authority\u2019s application and a summary of the audit report.\r\n8. The Oversight Board meets 3-4 times a year and will consider applications for accreditation at those meetings. "},{"id":3,"title":"Interim Accreditation Process","heading":"Costs","path":"./data-integration/accreditation/accreditation-process.html#costs","content":"\r\n9. The applicant for interim accreditation will pay audit costs which are expected to be in the order of $15,000 to $20,000 per audit. "},{"id":4,"title":"Interim Accreditation Process","heading":"Who can apply for accreditation?","path":"./data-integration/accreditation/accreditation-process.html#who-can-apply-for-accreditation?","content":"\r\n10. The interim accreditation arrangements will be tested on Commonwealth government agencies first. While this does not preclude state government agencies applying now for accreditation against the interim arrangements (provided that they meet all the requirements for accreditation), it will not be possible for any state government agencies to be accredited in the short term, as this would not allow time for sufficient testing and evaluation of the arrangements with Commonwealth agencies. The system is not yet mature enough to ensure that adequate safeguards apply to private firms. State government agencies and private firms can continue to apply for access to Commonwealth data under existing arrangements. \r\n11. The Cross Portfolio Data Integration Oversight Board will only consider applications for accreditation, against the interim arrangements, for those institutions covered by privacy legislation (either the Privacy Act 1988 or state/territory equivalent). "},{"id":5,"title":"Interim Accreditation Process","heading":"Legal framework \u2013 project level requirements","path":"./data-integration/accreditation/accreditation-process.html#legal-framework-\u2013-project-level-requirements","content":"\r\n12. When considering whether to apply for accreditation, integrating authorities will need to consider whether legislation allows them to undertake the data integration projects they are contemplating. \r\n13. Accreditation applies to an agency. Assessment of the legal framework, on the other hand, is a decision that must be made for each individual project, or family of projects. The data custodian, in partnership with the proposed integrating authority, will assess whether the proposed integrating authority: \r\nis authorised by legislation or consent to receive identifiable data from the custodian(s).\r\nhas appropriate legal protections in place prohibiting the disclosure of identifiable data, other than where allowed by law."},{"id":6,"title":"Interim Accreditation Process","heading":"Review of the process, to move it from an \u2018interim\u2019 process to a final process","path":"./data-integration/accreditation/accreditation-process.html#review-of-the-process,-to-move-it-from-an-\u2018interim\u2019-process-to-a-final-process","content":"\r\n14. The interim accreditation process will be reviewed by late 2014 to determine whether any changes are necessary to the process or criteria. The review will also determine the process and timing for ongoing reviews of accredited agencies to ensure continued compliance with the accreditation criteria. Once the review is complete, and the recommendations have been implemented, the interim accreditation process will become final. \r\n15. If the accreditation arrangements change, then agencies granted accreditation against the interim arrangements will need to demonstrate that they comply with any new requirements (e.g. additional accreditation criteria) for accreditation. "},{"id":7,"title":"Interim Accreditation Process","heading":"Accreditation criteria for integrating authorities wishing to undertake high risk data integration projects involving Commonwealth data","path":"./data-integration/accreditation/accreditation-process.html#accreditation-criteria-for-integrating-authorities-wishing-to-undertake-high-risk-data-integration-projects-involving-commonwealth-data","content":"\r\n16. The accreditation criteria are embedded in the requirements of the high level principles and the governance and institutional arrangements. There are eight criteria integrating authorities must meet to gain accreditation: \r\nability to ensure secure data management; \r\nintegrating authorities must demonstrate that information that is likely to enable identification of individuals or organisations is not disclosed to external users; \r\navailability of appropriate skills; \r\nappropriate technical capability; \r\nlack of conflict of interest; \r\nculture and values that ensure protection of confidential information and support the use of data as a strategic resource; \r\ntransparency of operation; and \r\nappropriate governance and administrative framework. \r\n17.\r\nAbility to ensure secure data management Integrating authorities seeking accreditation must demonstrate that they have secure data management systems in place to protect data both during and after integration, including systems for the safe exchange of sensitive data across agencies. This may include secure management of metadata or software programs to protect intellectual property, as negotiated with the data custodian(s). Agencies who demonstrate they meet Australian Government standards for security practices as set out in the Australian Protective Security Policy Framework would automatically be rated suitable on this criterion, provided that they can also demonstrate that they adhere to the separation principle and that they have an ongoing program of audits to ensure the continued security of the data. Agencies who cannot meet all the requirements in the Framework would need to comply with particular aspects, including control of access to the agency\u2019s premises and police checks for staff. \r\n\r\nIntegrating authorities must demonstrate that information that is likely to enable identification of individuals or organisations is not disclosed to external users \r\n\r\nIntegrating authorities seeking accreditation must be able to demonstrate that information that is likely to enable identification of individuals or organisations is not disclosed to external users. Removal of identifying information will not be sufficient. Integrating authorities must ensure that information is only released in a way that is not likely to enable identification, either directly or indirectly, of individuals or organisations. Examples of different ways this criterion can be met include: \r\nuse of formal confidentiality algorithms; and/or\r\nuse of statistical disclosure control techniques such as cell suppression and perturbation; and/or\r\nproviding access to data that are not likely to enable identification of individuals or organisations via on-site data laboratories; and/or\r\nproviding access to data that are not likely to enable identification of individuals or organisations via secure remote access facilities; and/or\r\nmanual review of data by staff with appropriate skills prior to any data release.\r\n\r\nAs an additional protective measure, integrating authorities may restrict access to data that are not likely to enable identification of individuals or organisations to approved applicants. \r\n\r\n\r\nAvailability of appropriate skills An integrating authority seeking accreditation will need to have a high level of relevant skills to undertake high risk data integration projects or be able to show how they can gain these skills (e.g. secondment provisions, training). Relevant skills include: \r\nexpertise in linkage and merging functions\r\nexpertise in privacy (for example, the ability to conduct a Privacy Impact Assessment)\r\nexpertise in confidentiality\r\ninformation management skills\r\nability to provide useful metadata to data users\r\nappreciation of data quality issues to allow the integrating authority to provide advice to stakeholders.\r\n\r\nThis may be evident in the experience of staff undertaking the integration projects and in the provision of training and documentation to support the integration projects. \r\n\r\nAppropriate technical capability To obtain accreditation an integrating authority must have the necessary technical expertise and infrastructure, including secure hardware and software systems and system support, to undertake high risk data integration projects. Two factors that the integrating authority\u2019s technical infrastructure will need to handle are the size of an integrated dataset (use of administrative data can result in very large files) and its complexity (e.g. maintaining a link that may be longitudinal or cross-sectional). The expertise and infrastructure required also extends to data access arrangements to maximise the public benefit of data integration. \r\nLack of conflict of interest The Commonwealth Statistical Integration Principles state that statistical data integration must be used for statistical and research purposes only. Agencies with a regulatory function or with responsibility for compliance monitoring must demonstrate how they will address a potential conflict of interest if linked datasets could help them with these non-statistical purposes. Possible ways an agency may demonstrate a lack of conflict of interest include the use of some legally enforceable obligation, policies, and separation principles (e.g. restricting access so that staff with regulatory/compliance roles cannot access data which would enable list matching). \r\n\r\nCulture and values that ensure protection of confidential information and support the use of data as a strategic resource \r\n\r\nIntegrating authorities seeking accreditation will need to demonstrate a consistently high standard of behaviour by all employees, commensurate with an agency statement equivalent to the APS Code of Conduct. Security needs to be part of the agency\u2019s culture. Staff working on data integration also need to value data as a strategic resource. Examples of how this standard may be demonstrated include: \r\na culture of protecting identifiable information\r\nadequate training on security/privacy/confidentiality matters\r\nappropriate mechanisms to consult with stakeholders (data custodians, data users and the public).\r\n\r\n\r\nTransparency of operation \r\n\r\nTo maintain public trust, use of government data, particularly in data integration projects for statistical and research purposes, must be open and transparent. Integrating authorities seeking accreditation will need to demonstrate the transparency of their operations, including the ability to apply sanctions. This may be evidenced by: \r\ntheir legislation and policies, particularly in relation to their implementation of Gov2.0 recommendations which focus on increased openness in government\r\nmechanisms to consult with and inform the public and key stakeholders about projects that are underway (e.g. via publications, presentations at conferences, focus groups)\r\npublishing relevant material on the web e.g. data retention statements.\r\n\r\n\r\nAppropriate governance and administrative framework \r\n\r\nAn integrating authority must have frameworks in place for management of cost recovery (if applicable), conducting investigations and handling of complaints. An integrating authority must also demonstrate that they have appropriate institutional and project governance in place. Examples include Chief Executive Instructions and a Control Framework. "},{"id":8,"title":"Interim Accreditation Process","heading":"Additional information to start an application for accreditation","path":"./data-integration/accreditation/accreditation-process.html#additional-information-to-start-an-application-for-accreditation","content":"\r\nThe information below is a summary of some of the key concepts involved in the Commonwealth governance arrangements for statistical data integration. \r\nScope: See Scope of the Commonwealth arrangements. \r\nConfidentiality: The wealth of information provided by integrated datasets can create additional risk by increasing the chance of identifying an entity (such as a person or business). Protecting the confidentiality of individuals or organisations in an integrated dataset is a key element in maintaining the ongoing trust of the Australian public. Removing identifying details, such as name, from a dataset does not necessarily protect identity, as other variables can be used to deduce the identity of an individual or organisation in the dataset. For example, the identity of a person with a very rare disease or health condition could be deduced even in highly aggregated data. \r\nConfidentialising data involves two steps, needed to mitigate the risk that a particular person or organisation could be directly or indirectly identified in a dataset: \r\nde-identifying the data (removing direct identifiers such as name and address); and\r\nmanaging the risk of indirect identification, for example by removing or altering information, or collapsing detail within a dataset.\r\nIt is the integrating authority's responsibility to confidentialise the integrated dataset.\r\nThe privacy of individuals and organisations also needs to be considered during the actual linking process used to form the integrated dataset. \r\nSeparation principle: The separation principle, that is the separation of identifying and content information, is one mechanism to protect the identities of individuals and organisations in datasets. Such separation means that no-one can see the identifying or demographic information, used to identify which records relate to the same person or organisation (e.g. name, address, date of birth), in conjunction with the content data (e.g. clinical information, benefit information, company profits). Instead, staff can see only the information they need to do the linking or analysis. So, rather than someone being able to see that John Smith has a rare medical condition, or the profits earned by Company X, the person doing the linking sees only the information needed to do the linking (e.g. John Smith\u2019s name and address) and the analyst just sees a record, with no identifying information, showing that a person has a rare medical condition together with any other variables needed for analysis (e.g. broad age group and sex). \r\nIntegrating authorities must ensure secure data management and ensure that information that is likely to enable identification of individuals or organisations is not disclosed to external users. One approach to achieving this is carrying out both the linking and merging functions within the same organisation, with sufficient procedural and technical controls to ensure the separation principle is internally applied. "},{"id":9,"title":"Interim Accreditation Process","heading":"Inquiries","path":"./data-integration/accreditation/accreditation-process.html#inquiries","content":"\r\nAny questions about the accreditation process should be emailed to dsdg-coord@pmc.gov.au\r\nAttachment 1: Proforma for applicants to complete Accreditation Proforma.docx"},{"id":10,"title":"Accredited Integrating Authorities","heading":"Australian Bureau of Statistics (ABS) ","path":"./data-integration/accreditation/accredited-integrating-authorities.html#australian-bureau-of-statistics-(abs)","content":"\r\nDate accredited: 24 April 2012\r\nAccreditation application summary: Australian Bureau of Statistics (ABS)\r\nAccreditation application summary (pdf):ABS - application for accreditation.pdf\r\nContact details:\r\nVisit the ABS web site at www.abs.gov.au\r\nEmail ABS: client.services@abs.gov.au\r\nContact your nearest ABS Office"},{"id":11,"title":"Accredited Integrating Authorities","heading":"Australian Institute of Health and Welfare (AIHW)","path":"./data-integration/accreditation/accredited-integrating-authorities.html#australian-institute-of-health-and-welfare-(aihw)","content":"\r\nDate accredited: 28 June 2012\r\nAccreditation application summary: Australian Institute of Health and Welfare (AIHW)\r\nAccreditation application summary (pdf): AIHW - application for accreditation.pdf\r\nContact details:\r\nVisit the AIHW web site at www.aihw.gov.au\r\nEmail AIHW: disc@aihw.gov.au\r\nVisit: 26 Thynne Street, Fern Hill Park, Bruce, ACT 2617"},{"id":12,"title":"Accredited Integrating Authorities","heading":"Australian Institute of Family Studies (AIFS)","path":"./data-integration/accreditation/accredited-integrating-authorities.html#australian-institute-of-family-studies-(aifs)","content":"\r\nDate accredited: 11 November 2014\r\nAccreditation application summary:\r\nAccreditation application summary (pdf):AIFS - application for accreditation.pdf\r\nContact details:\r\nVisit the AFIS web site at www.aifs.gov.au/our-work/resources/data-linkage\r\nEmail AIFS: dlia@aifs.gov.au\r\nVisit: Level 4, 40 City Road, Southbank, Melbourne, VIC 3006"},{"id":13,"title":"Accredited Integrating Authorities","heading":"Department of Social Services (DSS)","path":"./data-integration/accreditation/accredited-integrating-authorities.html#department-of-social-services-(dss)","content":"\r\nDate accredited: 5 October 2018\r\nAccreditation application summary (pdf):Department of Social Services (DSS) - Application for Accreditation.pdf\r\nContact details:\r\nVisit the DSS web site at www.dss.gov.au\r\nEmail DSS: Data.Integration@dss.gov.au\r\nVisit: 71 Athllon Drive, Greenway, ACT 2900"},{"id":14,"title":"Accredited Integrating Authorities","heading":"Queensland Government Statistician's Office (QGSO)","path":"./data-integration/accreditation/accredited-integrating-authorities.html#queensland-government-statistician's-office-(qgso)","content":"\r\nDate accredited: 5 October 2018\r\nAccreditation application summary: Queensland Government Statistician's Office (QGSO)\r\nAccreditation application summary (pdf): Download PDF: QGSO - Application for accreditation.pdf\r\nContact details: \r\nVisit the QGSO web site at www.qgso.qld.gov.au\r\nEmail QGSO: govstat@treasury.qld.gov.au\r\nContact the QGSO Brisbane Office (07) 3035 6421"},{"id":15,"title":"Accredited Integrating Authorities","heading":"Centre for Victorian Data Linkage (CVDL)","path":"./data-integration/accreditation/accredited-integrating-authorities.html#centre-for-victorian-data-linkage-(cvdl)","content":"\r\nDate accredited: 5 October 2018\r\nAccreditation application summary: Centre for Victorian Data Linkage (CVDL)\r\nAccreditation application summary (pdf): coming soon\r\nContact details:\r\nVisit the CVDL web site at health.vic.gov.au/about/reporting-planning-data/the-centre-for-victorian-data-linkage\r\nEmail CVDL: cvdl@dhhs.vic.gov.au\r\nVisit: 50 Lonsdale Street, Melbourne, VIC 3000"},{"id":16,"title":"Accredited Integrating Authorities","heading":"South Australia Northern Territory DataLink (SA NT DataLink)","path":"./data-integration/accreditation/accredited-integrating-authorities.html#south-australia-northern-territory-datalink-(sa-nt-datalink)","content":"\r\nDate accredited: 17 September 2019\r\nAccreditation application summary: South Australia Northern Territory DataLink (SA NT DataLink)\r\nAccreditation application summary (pdf): coming soon\r\nContact details: \r\nVisit the SA NT DataLink web site at www.santdatalink.org.au\r\nEmail SA NT DataLink: santdatalink@unisa.edu.au\r\nVisit: the SA NT DataLink Offices in Adelaide (South Australian Health Medical Research Institute [SAHMRI] building, North Terrace, Adelaide 5000) or Darwin (Level 2 Health House, Northern Territory Department of Health, 87 Mitchell Street, Darwin NT 0800)"},{"id":17,"title":"Accredited Integrating Authorities","heading":"Need more information?","path":"./data-integration/accreditation/accredited-integrating-authorities.html#need-more-information?","content":"\r\nThe Statistical Data Integration involving Commonwealth Data website includes information on statistical data integration involving Commonwealth data including the interim accreditation scheme. \r\nCommonwealth data integration accreditation has recently undergone a period of review. The interim Data Integration Accreditation Subcommittee Secretariat can provide information on the governance and application process. Please email dsdg-coord@pmc.gov.au "},{"id":18,"title":"Interim Accreditation Audit","heading":"What is the process for securing audit services for integrating authority accreditation?","path":"./data-integration/accreditation/interim-accreditation-audit.html#what-is-the-process-for-securing-audit-services-for-integrating-authority-accreditation?","content":"\r\nIntegrating authorities (including both Commonwealth and non-Commonwealth organisations) applying for accreditation must engage a qualified auditor for the provision of auditing services as part of the interim accreditation process.\r\nThe 'Terms of Reference for Audits of Integrating Authorities' must be incorporated into the contractual arrangement between the integrating authority and the audit firm, and the scope of work in the arrangement must clearly reflect the obligations set out at Clause 4 of the Terms of Reference. Terms of Reference For Audits of Integrating Authorities July 2014.docx\r\nThe integrating authority is responsible for the costs of the audit. \r\nIt is expected that the costs for these audit services will be below $80,000, and therefore Division 2 of the Commonwealth Procurement Rules will not apply. However, it is up to each integrating authority to follow its internal procurement procedures in engaging an audit provider."},{"id":19,"title":"Interim Accreditation Audit","heading":"Need more information?","path":"./data-integration/accreditation/interim-accreditation-audit.html#need-more-information?","content":"\r\nCommonwealth data integration accreditation has recently undergone a period of review. The interim Data Integration Accreditation Subcommittee Secretariat can provide information on the governance and application process. Please email dsdg-coord@pmc.gov.au"},{"id":20,"title":"Cross Portfolio Data Integration Oversight Board: Terms of Reference","heading":"Background","path":"./data-integration/data-integration-framework/cross-portfolio-data-integration-board.html#background","content":"\r\n1. In October 2010 the Secretaries\u2019 Board endorsed a set of governance and institutional arrangements for data integration involving Commonwealth data, including the establishment of a Cross Portfolio Data Integration Oversight Board ('the Board'). The aim is to build a safe and effective environment for data integration activities. "},{"id":21,"title":"Cross Portfolio Data Integration Oversight Board: Terms of Reference","heading":"Membership and conflict of interest provisions","path":"./data-integration/data-integration-framework/cross-portfolio-data-integration-board.html#membership-and-conflict-of-interest-provisions","content":"\r\n2. The Board will be chaired by the Australian Statistician and membership will include the Secretaries of the Department of Social Services; the Department of Health; and the Department of Human Services. Membership is not a delegable function. \r\n3. Any Board member who has a real or apparent conflict of interest in a particular decision must exempt himself or herself from the decision made by the Board. "},{"id":22,"title":"Cross Portfolio Data Integration Oversight Board: Terms of Reference","heading":"Role of the Board","path":"./data-integration/data-integration-framework/cross-portfolio-data-integration-board.html#role-of-the-board","content":"\r\n4. For data integration projects involving Commonwealth data, the Board will:\r\nagree guidelines for accreditation of Integrating Authorities and review and decide on applications from proponents to become Integrating Authorities with the capacity to deal with high risk data integration projects involving Commonwealth data;\r\nprovide strategic and collaborative leadership, support effective governance and help manage the risks of particular projects;\r\nhelp manage the systemic risk associated with conducting multiple data integration projects; and\r\nendorse changes or additions to the overall environment e.g. the development of new general tools to support integration or safe access to integrated data."},{"id":23,"title":"Cross Portfolio Data Integration Oversight Board: Terms of Reference","heading":"Activities of the Board","path":"./data-integration/data-integration-framework/cross-portfolio-data-integration-board.html#activities-of-the-board","content":"\r\n5. The Board will review data integration projects which pose a significant level of systemic risk, advise on risk mitigation strategies, and review any adverse incidents of high public concern. The Board will also approve a comprehensive set of guidelines describing best practice for data integration projects involving Commonwealth data, and establish reference groups, as required, to provide support. "},{"id":24,"title":"Cross Portfolio Data Integration Oversight Board: Terms of Reference","heading":"Consultation","path":"./data-integration/data-integration-framework/cross-portfolio-data-integration-board.html#consultation","content":"\r\n6. The Board will consult with the Office of the Australian Information Commissioner on a needs basis. This will allow the Office to remain independent of decisions made by the Board. The Board will also consult with representatives from the research community or other parties as required. "},{"id":25,"title":"Cross Portfolio Data Integration Oversight Board: Terms of Reference","heading":"Review","path":"./data-integration/data-integration-framework/cross-portfolio-data-integration-board.html#review","content":"\r\n7. The operations of, and arrangements for, the Cross Portfolio Data Integration Oversight Board and its Secretariat are to be reviewed at the end of 2015. "},{"id":26,"title":"Data Integration Involving Commonwealth Data","heading":"Building a safe and effective environment for data integration ","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#building-a-safe-and-effective-environment-for-data-integration","content":"\r\nStatistical data integration involves integrating data from different administrative and/or survey sources to provide new datasets for statistical and research purposes. The approach leverages more information from combining datasets than could be obtained by examining individual datasets separately. Data integration aims to maximise the statistical value of existing and new datasets, to improve community health as well as social, economic and environmental wellbeing, by integrating data across multiple sources, working with governments, the community and researchers to build a safe and effective environment for data integration activities.\r\nIntegrated datasets provide public benefits in terms of improved research, supporting good government policy making, program management and service delivery. Integrated datasets also create important opportunities to expand the range of official statistics to better inform Australian society. "},{"id":27,"title":"Data Integration Involving Commonwealth Data","heading":"High level principles for data integration involving Commonwealth data for statistical and research purposes","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#high-level-principles-for-data-integration-involving-commonwealth-data-for-statistical-and-research-purposes","content":"\r\nOn 3 February 2010, the Portfolio Secretaries Meeting (now Secretaries Board) endorsed a set of high level principles for the integration of Commonwealth data for statistical and research purposes. At the same time, a set of governance and institutional arrangements to support these principles was requested. \r\nA complete description of the high level principles is available at www.nss.gov.au and a summarised version is provided below. \r\nStrategic resource - Principle 1\r\nResponsible agencies should treat data as a strategic resource and design and manage administrative data to support their wider statistical and research use. \r\nCustodian\u2019s accountability - Principle 2\r\nAgencies responsible for source data used in statistical data integration remain individually accountable for their security and confidentiality. \r\nIntegrator\u2019s accountability - Principle 3\r\nA responsible \u2018integrating authority\u2019 will be nominated for each statistical data integration proposal. \r\nPublic benefit - Principle 4\r\nStatistical integration should only occur where it provides significant overall benefit to the public. \r\nStatistical and research purposes - Principle 5\r\nStatistical data integration must be used for statistical and research purposes only. \r\nPreserving privacy and confidentiality - Principle 6\r\nPolicies and procedures used in data integration must minimise any potential impact on privacy and confidentiality. \r\nTransparency - Principle 7\r\nStatistical data integration will be conducted in an open and accountable way. "},{"id":28,"title":"Data Integration Involving Commonwealth Data","heading":"Cross Portfolio Data Integration Oversight Board","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#cross-portfolio-data-integration-oversight-board","content":"\r\nA high level Cross Portfolio Data Integration Oversight Board (the Board) will be established by early 2011 to oversee the development of a cross government environment for data integration involving Commonwealth data for statistical and research purposes that is safe and effective. The Board will be chaired by the Australian Statistician and membership will initially include the heads of the Department of Health and Ageing; the Department of Families, Housing, Community Services and Indigenous Affairs; and the Department of Human Services. \r\nThe role of the Board will be to: \r\nProvide strategic and collaborative leadership, support effective governance and help manage the risks of particular data integration projects;\r\nHelp manage the systemic risk associated with conducting multiple data integration projects involving Commonwealth data through assessment of proposed risk mitigation strategies, and the provision of advice; and\r\nEndorse any changes or additions to the overall environment, including amendments to the principles or guidelines, or the development of new general tools to support integration or safe access to integrated data for statistical and research purposes.\r\nActivities of the Board will include: \r\nAdvising on data integration projects assessed as being of high risk and with the potential to significantly impact information related activities across government. Where the Board advises on amendments to, or discontinuation of, a particular project, the relevant custodians and integrating authority will need to consider these views in deciding whether to proceed with the proposed project.\r\nWorking with agencies to help ensure the systemic risk associated with high risk projects is adequately managed. It will do this by reviewing data integration projects involving Commonwealth data deemed by agencies to pose a significant level of systemic risk, and advising on the sufficiency of the intended risk mitigation strategies.\r\nReview of any adverse incidents of high public concern relating to data integration involving Commonwealth data for statistical and research purposes, and seen as having a likely systemic impact on public trust in government use of data.\r\nConsultation with the Office of the Australian Information Commissioner, as required. The Board is also free to consult representatives from the research community or other parties as required."},{"id":29,"title":"Data Integration Involving Commonwealth Data","heading":"Integrating Authorities ","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#integrating-authorities","content":"\r\nAn essential pillar of establishing a safe and effective environment for data integration involving Commonwealth data is the nomination of an agency as the authorised integrating authority for each statistical data integration proposal. The integrating authority will be responsible for the sound conduct of the data integration project and may work with other agencies to achieve components of the project, for example it might use another agency to undertake linkage or to support dissemination. The integrating authority has overall responsibility to ensure that risks have been assessed, managed and mitigated throughout the duration of the project, including regular reviews of ongoing projects. \r\nAs described by Principle 3, the integrating authority will ensure appropriate governance is in place for the data integration project including: using an open approval process; documenting the proposal; considering the privacy impacts, examining the expected costs and benefits of the proposal and considering the access arrangements and dissemination plans. The integrating authority will be responsible for the ongoing management of the integrated data, ensuring it is kept secure, confidential and fit for the purposes for which it was approved. \r\nIntegrating authorities are responsible for the implementation of the data integration project, and the management of the integrated datasets throughout their life cycle, ensuring full compliance with commitments made as part of the project approval, and in line with a set of guidelines to be developed as a priority by 2012. \r\nA key requirement of integrating authorities is that, to the extent that the data they deal with involves identifiable information, they be in a position to comply with the requirements of the Privacy Act 1988 (in regards to information about individuals) and secrecy provisions generally (in regards to information with respect to the affairs of any third party, corporate or individual). This may require either the consent of the individual to the particular use or disclosure for Privacy Act 1988 purposes, or an overriding public interest test certified in accordance with the relevant secrecy provision. \r\nIntegrating authorities will only be established at the initiative of an interested agency. Such agencies may wish to involve their respective Ministers in the course of preparing a proposal for accreditation to the Board. An integrating authority could also be established administratively within a Department or other agency, that is, it would be part of an agency subject to the provisions of the Privacy Act 1988. \r\nAccreditation Process\r\nFor data integration proposals considered by custodians to pose a high systemic risk, nomination of an authorised and accredited integrating authority is required. An accreditation process will be established through the Board to enable the endorsement of authorised and accredited integrating authorities with the capacity to deal with high risk data integration projects or families of projects involving Commonwealth data. \r\nData integration projects involving Commonwealth data for statistical and research purposes judged to pose a high systemic risk will need to be undertaken with particular care to help mitigate this risk. This will require a high level of relevant expertise, a strong understanding of, and capability for, maintaining security, as well as a consistently high standard of behaviour by all employees based on a strong culture, and set of values. To ensure effective use of specialist skills and infrastructure, the number of accredited integrating authorities is expected to be relatively limited. \r\nAn accreditation process including interim arrangements will be proposed through cross government consultation. It is expected that interim arrangements will be proposed for discussion and endorsement by the Board in early 2011 with final arrangements agreed early 2012. "},{"id":30,"title":"Data Integration Involving Commonwealth Data","heading":"Best Practice Guidelines ","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#best-practice-guidelines","content":"\r\nA comprehensive set of guidelines describing best practice for data integration projects involving Commonwealth data for statistical and research purposes will be jointly developed by a cross government working group and approved by the Board. These guidelines will build upon already available guidelines (e.g. National Statement on Ethical Conduct in Human Research, related guidelines of the Office of the Privacy Commissioner, and agency specific guidelines and proformas). \r\nThe guidelines will be considered in conjunction with legislation relevant to the data custodians, data providers and the integrating authority. \r\nThe guidelines will cover such areas as: \r\nPrivacy including Privacy Impact Assessments and the protection of privacy in medical research (Endnote 1)\r\nApproval\r\nRegistration\r\nAgreements \u2013 between data custodians and the integrating authority; or with end users\r\nResponsibilities of custodians and integrating authorities including accreditation criteria and accreditation process\r\nHandling of identifiers and application of the separation principle, for example, the separation of identifiers and key demographic data used for linking (e.g. date of birth) from the individual content or event information (e.g. clinical or benefit information)\r\nMinimum standards for the secure management of data during and after integration, including the exchange of sensitive data across agencies\r\nMinimum standards for consent to access Commonwealth data\r\nConfidentialising of integrated data sets and research outputs\r\nManaging access and use of integrated data sets\r\nMinimum standards for data destruction or review.\r\nThe guidelines will be developed progressively, commencing in 2011 with guidelines relating to integrating authorities. They will be made publicly available on an internet site, and maintained by the Secretariat to the Board. "},{"id":31,"title":"Data Integration Involving Commonwealth Data","heading":"Education and Training","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#education-and-training","content":"\r\nAn education and training strategy will be developed and implemented to support the guidelines for data integration projects involving Commonwealth data for statistical and research purposes. \r\nThe guidelines and the education and training strategy will be targeted to key stakeholders including government agencies (acting variously as custodians, integrating authorities, researchers, Privacy Commissioners), the private sector (as custodians or researchers), the academic/research community and the public. \r\nThe purpose of the education and training strategy will be to build an understanding of: \r\nThe underpinning values of a safe and effective environment for data integration projects. \r\nKey issues in managing privacy and confidentiality in data integration projects.\r\nKey legislative requirements within the management of data integration projects including maintaining privacy and confidentiality.\r\nSanctions that apply for non compliance with legislative requirements or other institutional requirements.\r\nSupport available in terms of specialist advice, knowledge and tools.\r\nFollowing its development and finalisation by January 2013, the education and training strategy will be publicly available on an internet site and maintained by the Secretariat to the Board. "},{"id":32,"title":"Data Integration Involving Commonwealth Data","heading":"Network of Survey Liaison Officers","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#network-of-survey-liaison-officers","content":"\r\nSurvey Liaison Officers (SLOs) have been established in many Commonwealth agencies to provide a central contact of information and expertise in statistical collections involving businesses. Survey Liaison Officers are part of an Australian Government initiative established by the Prime Minister in 1997 to reduce duplication, minimise the burden on business, and ensure that statistical data collections involving businesses are fit-for-purpose. \r\nThe role of the existing network of Survey Liaison Officers across Commonwealth agencies will be expanded to provide a central contact of information and expertise in data integration projects involving Commonwealth data. This network will be able to share information on good practice and help minimise duplication. \r\nSurvey Liaison Officers as at November 2010: \r\nAttorney-General\u2019s Department (AGs)\r\nAustralian Bureau of Agricultural and Resource Economics (ABARE)\r\nAustralian Communications and Media Authority (ACMA)\r\nAustralian Competition and Consumer Commission (ACCC)\r\nAustralian Crime Commission (ACC)\r\nAustralian Customs and Border Protection Service\r\nAustralian Institute of Criminology (AIC)\r\nAustralian Institute of Health and Welfare (AIHW)\r\nAustralian Prudential Regulation Authority (APRA)\r\nAustralian Taxation Office (ATO)\r\nAustralian Trade Commission (Austrade)\r\nDepartment of Agriculture, Fisheries and Forestry (DAFF)\r\nDepartment of Broadband, Communications and the Digital Economy (DBCDE)\r\nDepartment of Defence\r\nDepartment of Education, Employment and Workplace Relations (DEEWR)\r\nDepartment of Families, Housing, Community Services and Indigenous Affairs (FaHCSIA)\r\nDepartment of Foreign Affairs and Trade (DFAT)\r\nDepartment of Health and Ageing (DoHA)\r\nDepartment of Human Services (DHS)\r\nDepartment of Immigration and Citizenship (DIaC)\r\nDepartment of Infrastructure and Transport (DIT)\r\nDepartment of Innovation, Industry, Science and Research (DIISR)\r\nDepartment of Resources, Energy and Tourism (DRET)\r\nDepartment of the Prime Minister and Cabinet (PM&C)\r\nFood Standards Australia New Zealand (FSANZ)\r\nMedicare Australia\r\nNational Centre for Vocational Education Research (NCVER)\r\nPrivate Health Insurance Administration Council (PHIAC)\r\nPrivate Health Insurance Ombudsman (PHIO)\r\nProductivity Commission (PC)\r\nRoyal Australian Mint (RAM)\r\nScreen Australia (SA)"},{"id":33,"title":"Data Integration Involving Commonwealth Data","heading":"Register of Data Integration Projects ","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#register-of-data-integration-projects","content":"\r\nConsistent with a more open government, and to build trust through transparency, a web-based register will be established to include a description of data integration projects involving Commonwealth data for statistical and research purposes. A public feedback mechanism will enable members of the public to register support or concerns and make suggestions about particular projects or families of projects. \r\nThe register entry will describe the project purpose and data sources, recognising that specific details on individual use will generally not be made publicly available for in-confidence government business. For similar reasons, actual data will not be included. A format for such submissions will be developed across government and made available through self-help mechanisms (email, SLO network, internet site). \r\nThe integrating authority nominated for each project will be responsible for submitting an entry to the register once the project is finalised. \r\nThe register will be available through an appropriate whole-of-government web site, along with related information, including the high level principles, the guidelines and access to the public feedback mechanism. It is expected that development of the register will commence in 2011 with trialling through 2012 and final release by 2013. \r\nThe Secretariat will maintain the register and associated internet site. "},{"id":34,"title":"Data Integration Involving Commonwealth Data","heading":"Secretariat ","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#secretariat","content":"\r\nA small Secretariat will be established by early 2011 and based in the Australian Bureau of Statistics, to support the Board and its ongoing activities. \r\nThe Secretariat will support the Board by: \r\nProviding administrative support as needed to facilitate meetings, maintain centralised documentation and undertake investigation or development work as directed by the Board.\r\nAssisting the cross government development of the guidelines, the development and, in part, the delivery of the education and training strategy, and expansion of the network of survey liaison officers.\r\nDeveloping and maintaining a web-based public register of the description of projects and the provision of a public feedback mechanism, in conjunction with other agencies.\r\nMonitoring the risk assessment of projects, including legal and systemic risks, advising project managers where further advice has been requested, and identifying instances where apparently high risk projects have not been assessed as such, initiating discussion with the agency involved in the first instance to resolve concerns, and as required, escalating the assessed level of risk, for Board consideration.\r\nProviding a contact point in government for issues relating to data integration involving Commonwealth data for statistical and research purposes, whether coming from data custodians, integrating authorities, researchers or the public.\r\nFollowing development of the public register, releasing an annual report on key aspects of data integration activity involving Commonwealth data for statistical and research purposes, including a summarised report on public feedback."},{"id":35,"title":"Data Integration Involving Commonwealth Data","heading":"Transition Arrangements ","path":"./data-integration/data-integration-framework/data-integration-involving-commonwealth-data.html#transition-arrangements","content":"\r\nTransition arrangements will apply during the early stages of the implementation of the high level principles and the governance and institutional arrangements for data integration involving Commonwealth data for statistical and research purposes. Transition arrangements include the following: \r\nThe Board and Secretariat will be established in early 2011 to commission cross government work to develop and begin communicating the guidelines, the education and training strategy, the use of survey liaison officers, and accreditation criteria for integrating authorities. \r\nIn early 2011, it is expected that a small number of agencies will be accredited as authorised integrating authorities for high risk projects. This will be an interim accreditation, subject to review and finalisation of the formal accreditation process in early 2012.\r\nThe education and training strategy will be developed by January 2013 to provide a range of self help tools to inform stakeholders. This will be expanded to include seminars, workshops, and conferences. The strategy will also be designed to develop the skills of integrating authorities.\r\nNew data integration projects which commence prior to the development of the guidelines are expected to be set up to conform to the high level principles.\r\nHigh risk projects should be notified to the Secretariat for review by the Board. The project should be fully developed before consideration by the Board. However, in the initial stages, it may be useful for those developing the proposal to liaise with the Secretariat. Where a new, potentially high risk project has been substantially developed, and committed timeframes do not permit review by the Board, the Board should be notified of the project and it should be treated as a project currently underway.\r\nThose projects, including families of projects, which are underway as at October 2010, and which are expected to be completed by October 2012, will not be subject to the new arrangements, although project managers are encouraged to consider the conformity of the project to the principles and to seek advice from the Secretariat if there are aspects of the projects that may be of concern.\r\nThose projects, including families of projects, which are underway, and are expected to continue beyond October 2012, will need to become aligned with the principles, and with the proposed governance and institutional arrangements. It is proposed that such projects are brought into alignment by October 2012."},{"id":36,"title":"Principles for Data Integration","heading":"About CPSIC","path":"./data-integration/data-integration-framework/principles-for-data-integration.html#about-cpsic","content":"\r\nIn 2009, Australian Government Portfolio Secretaries established a Cross Portfolio Statistical Integration Committee (CPSIC), jointly chaired by DoHA and ABS, to create an Australian government approach to facilitate linkage of social, economic and environmental data for statistical and research purposes.\r\nCross Portfolio Statistical Integration Committee members were:\r\nAttorney-General\u2019s Department\r\nAustralian Bureau of Agricultural and Resource Economics\r\nAustralian Bureau of Statistics\r\nAustralian Public Service Commission\r\nDepartment of Broadband, Communications and the Digital Economy\r\nDepartment of Defence\r\nDepartment of Education, Employment and Workplace Relations\r\nDepartment of Families, Housing, Community Services and Indigenous Affairs\r\nDepartment of Finance and Deregulation\r\nDepartment of Foreign Affairs and Trade\r\nDepartment of Health and Ageing\r\nDepartment of Human Services\r\nDepartment of Immigration and Citizenship\r\nDepartment of Infrastructure and Transport\r\nDepartment of Innovation, Industry, Science and Research\r\nDepartment of Resources, Energy and Tourism\r\nDepartment of Sustainability, Environment, Water, Population and Communities\r\nDepartment of the Prime Minister and Cabinet\r\nDepartment of the Treasury\r\nDepartment of Veterans\u2019 Affairs"},{"id":37,"title":"Principles for Data Integration","heading":"Statistical Integration - Why?","path":"./data-integration/data-integration-framework/principles-for-data-integration.html#statistical-integration---why?","content":"\r\nStatistical data integration involves integrating unit record data from different administrative and/or survey sources to provide new datasets for statistical and research purposes. The approach leverages more information from the combination of individual datasets than is available from the individual datasets taken separately. Statistical integration aims to maximise the potential statistical value of existing and new datasets, to improve community health, as well as social and economic wellbeing by integrating data across multiple sources and by working with governments, the community and researchers to build a safe and effective environment for statistical data integration activities.\r\nIntegrated datasets provide public benefits in terms of improved research, supporting good government policy making, program management and service delivery. Integrated datasets also create an important opportunity to expand the range of official statistics to better inform Australian society."},{"id":38,"title":"Principles for Data Integration","heading":"Principle One - Strategic Resource","path":"./data-integration/data-integration-framework/principles-for-data-integration.html#principle-one---strategic-resource","content":"\r\nResponsible agencies should treat data as a strategic resource and design and manage administrative data to support their wider statistical and research use.\r\nThis principle aims to maximise statistical and research use of existing and new Commonwealth data sets.\r\nAdministrative data represents a public asset that requires protection and management for appropriate purposes. When designing and managing administrative datasets, the responsible agency should consider the potential statistical value of the datasets for public good, both in terms of use by their own agency, and use more broadly. Administrative data cannot be used for statistical purposes if this contravenes legislation, or any commitment made to data providers or the data is commercial in confidence. Nor should it be used for statistical purposes if this use clearly threatens the integrity of the administrative data.\r\nWhere administrative data is likely to have high public value for statistical use, those providing data should be informed of the potential for statistical use at the time of data collection. (Where historical data has been collected without providing this information it should still be considered for statistical use, but not if this is prohibited by commitments made to providers at the time of collection.)\r\nWhere administrative data is likely to have value for statistical use, efforts should be made to maximise that value through good data management, including the use of standard definitions and classifications and the maintenance of appropriate metadata, including quality attributes of the data.\r\nWhere data is sought for statistical purposes, consideration should be given to using existing administrative sources in preference to imposing additional load on providers through the institution of a new statistical collection.\r\nThe statistical and research value of administrative data should be maximised, within legal and practical constraints, by granting broad access for research purposes to data that is not likely to enable identification. Commonwealth administrative data should not generally be withheld from research for reasons of Intellectual Property."},{"id":39,"title":"Principles for Data Integration","heading":"Principle Two - Custodian's Accountability","path":"./data-integration/data-integration-framework/principles-for-data-integration.html#principle-two---custodian's-accountability","content":"\r\nAgencies responsible for source data used in statistical data integration remain individually accountable for their security and confidentiality.\r\nThis principle ensures that data custodians recognise their continued accountability for their data within integrated datasets and establish adequate controls over the use of personal or other sensitive data in data integration projects.\r\nEach responsible agency for source data:\r\nmust agree mechanisms to achieve adequate control and manage risk appropriate to their own situation. For some these mechanisms may include the use of particular institutional arrangements with trusted institutions, the use of specified standards and audits against those standards, and the potential application of sanctions.\r\nwill need to agree the nature of valid uses that can be made of the integrated datasets and the approval mechanism to be applied to applications to use the datasets, as well as any control mechanisms to be applied to such use.\r\nwill need to manage the potential increase in identifiability of data for which they are responsible when it is used in conjunction with data from other sources. It will need to agree mechanisms by which it can assure itself that outputs from the statistical data integration are not likely to enable the identification of individuals or businesses.\r\nwill need to agree the final content of any new data integration proposal, or any material change to an existing data integration proposal as part of the approval process. They must be kept informed of, and agree, more minor proposed changes to existing proposals.\r\nWhere an agency does not agree to the use of its source data in a statistical integration proposal, that data will not be included. For example this might occur if the proposal threatens the integrity of the administrative data."},{"id":40,"title":"Principles for Data Integration","heading":"Principle Three - Integrator's Accountability","path":"./data-integration/data-integration-framework/principles-for-data-integration.html#principle-three---integrator's-accountability","content":"\r\nA responsible \u2018integrating authority\u2019 will be nominated for each statistical data integration proposal.\r\nThis principle sets out the responsibilities of integrating authorities to manage the data integration project from start to finish in line with the agreements made with data custodians and requirements as part of approval processes.\r\nAn integrating authority must be identified for each statistical data integration proposal. This authority will be held responsible for the sound conduct of the statistical data integration proposed, in line with the agreed requirements of the responsible agencies.\r\nAlthough the integrating authority is the single organisation ultimately accountable for the Statistical Data Integration project, it may work with a network of agencies to achieve the data integration, for example it might use another agency to undertake linkage or to support dissemination.\r\nThe integrating authority will ensure appropriate governance is in place including:\r\nan open approval process is followed;\r\ndocumentation of the proposal;\r\nthe impact on privacy;\r\nrisks have been assessed, managed and mitigated;\r\nthe expected costs and benefits; and\r\nthe outputs.\r\nA family of data integration projects using the same source datasets, for similar purposes, with the same integrating authority, may be treated as a single program for the purposes of the approval process.\r\nThe integrating authority will be responsible for the ongoing management of the integrated data, ensuring it is kept secure, confidential and fit for the purposes for which it was approved.\r\nIf it is an ongoing project, the integrating authority will be responsible for initiating and managing its regular review, in consultation with source data agencies."},{"id":41,"title":"Principles for Data Integration","heading":"Principle Four - Public Benefit","path":"./data-integration/data-integration-framework/principles-for-data-integration.html#principle-four---public-benefit","content":"\r\nStatistical integration should only occur where it provides significant overall benefit to the public.\r\nThis principle ensures there is a demonstrated ability to produce significant outputs from the integrated dataset and an independent assessment is made that the public good outweighs the privacy imposition and risks to confidentiality.\r\nThere should be a demonstrated ability to produce significant outputs from the integrated dataset. There should be an independent assessment of the balance of public good against the privacy imposition and risks to confidentiality. Examples include community representation on the steering committee, the use of an ethics committee, or the use of an advisory committee with community representation and the ability to report independently of the agencies involved in the proposal.\r\nOngoing programs should be reviewed on a three yearly basis to ensure a continuing overall benefit."},{"id":42,"title":"Principles for Data Integration","heading":"Principle Five- Statistical & Research Purposes","path":"./data-integration/data-integration-framework/principles-for-data-integration.html#principle-five--statistical-&-research-purposes","content":"\r\nStatistical data integration must be used for statistical and research purposes only.\r\nThis principle requires that where data integration is approved and implemented for statistical and research purposes, it is not then used for regulatory purposes, compliance monitoring, or service delivery. This helps to ensure that the risk of breaches of personal information and the potential impact of any inadvertent breach remain low.\r\nStatistical data integration must not be used for non-statistical purposes requiring the identification of an individual person, household, family or business, for example the delivery of services to particular individuals, individual compliance monitoring, client management, incident investigation, or for regulatory purposes. However the insights gained through statistical and research outputs are expected to improve processes in these areas.\r\nThere must be no feedback of information relating to individuals or individual businesses, from the statistical data integration project back to the originating administrative sources, unless that feedback was derived from a single source and is returning the same data to that source."},{"id":43,"title":"Principles for Data Integration","heading":"Principle Six - Preserving Privacy & Confidentiality","path":"./data-integration/data-integration-framework/principles-for-data-integration.html#principle-six---preserving-privacy-&-confidentiality","content":"\r\nPolicies and procedures used in data integration must minimise any potential impact on privacy and confidentiality.\r\nThis principle ensures privacy and confidentiality are preserved to the maximum extent possible.\r\nOperational, administrative and personal identifiers should be removed from datasets as soon as they are no longer required to meet the approved purposes of the statistical data integration. Where identifiers need to be retained, for example for longitudinal studies, they should be kept separate from the integrated dataset. \r\nThe number of unit records and data variables to be included in an integrated dataset should be no more than required to support the approved purposes. \r\nThe type of matching used (exact, probabilistic or statistical) should be chosen as the minimum needed to support the approved purposes, and the range of attributes used to establish a common identity should be the minimum necessary for the linking operation to succeed. \r\nAccess to potentially identifiable data for statistical and research purposes, outside secure and trusted institutional environments should only occur where: legislation allows; it is necessary to achieve the approved purposes; and meets agreements with source data agencies. \r\nRisks of indirect as well as direct identification should be carefully managed when data is disseminated outside secure and trusted institutions, particularly in terms of units with unusual characteristics. This management must take account of the potential increase in identifiability of one set of data when combined with another set. It might involve strict data use licensing conditions, reducing detail, perturbing data, or seeking the consent of the individual or business involved to release potentially identifiable data, the last of these being most likely in the case of business data. \r\nOnce the approved purpose of the project is met, the related datasets should be destroyed, or if retained, the reasons for and necessity of retention documented, and a review process set up. If such retention was not part of the initial approval process, re-approval of the decision to retain is required. \r\nArchiving of statistically integrated data sets should be restricted to confidentialised datasets. "},{"id":44,"title":"Principles for Data Integration","heading":"Principle Seven - Transparency","path":"./data-integration/data-integration-framework/principles-for-data-integration.html#principle-seven---transparency","content":"\r\nStatistical data integration will be conducted in an open and accountable way.\r\nThis principle ensures the public is aware of how Commonwealth government data is being used for statistical and research purposes.\r\nThe main elements will be:\r\ngoverned in an open accountable way\r\nensure stakeholders and the community are kept informed of any statistical data integration project undertaken, by publishing appropriate details of the project such as the datasets, the purpose, provision for access, use made of the dataset, the make up and role of any advisory body or steering group, the role of involved institutions, the approval process, and the review process\r\nappropriate privacy impact assessment\r\neach project is subject to audit, agencies responsible for source data and data integration, will agree on audit schedules."},{"id":45,"title":"Deterministic Linking","heading":"Deterministic Linking and Linkage Keys","path":"./data-integration/data-integration-projects/deterministic-linking.html#deterministic-linking-and-linkage-keys","content":"\r\nDeterministic linking involves the exact matching of information on different records across the datasets being combined for a linking project.\r\nThe simplest form of deterministic linking uses a unique identifier, such as an Australian Business Number or a social security number, to determine if the records refer to the same entity. (An entity may be a person, household, organisation or locality.) \r\nThis is also called \u2018exact linking\u2019 because the identifier either matches or does not match. This means that if the unique identifier contains any errors, the matches will not be found because the identifiers must be identical on all the datasets being linked. \r\nIf it is the case that the unique identifiers may be unreliable for linking purposes, there are a number of other options available. One is to instead use probabilistic linking or other possible approaches could include variations of deterministic linking, such as \u2018stepwise deterministic linking\u2019 and \u2018rules-based linking\u2019. These techniques use other information on the records to overcome deficiencies in the quality of the unique identifier. \r\nIf a unique identifier is not available, or is not of sufficient quality, it is possible to create a proxy, often referred to as a linkage key. \r\nKey Terms"},{"id":46,"title":"Deterministic Linking","heading":"Key Terms","path":"./data-integration/data-integration-projects/deterministic-linking.html#key-terms","content":"\r\nConfidentiality \u2013 the legal and ethical obligation to maintain and protect the privacy and secrecy of the person, business, or organisation that provided their information.\r\nContent data \u2013 the term used for the administrative or clinical information on a record (such as medical condition, income, educational attainment), as opposed to identifying information (such as name and address).\r\nIdentifier \u2013 for the purpose of data linking, an identifier is information that establishes the identity of an individual or organisation. For example, for individuals it is often name and address. Also see Unique identifier.\r\nUnique identifier \u2013 a number or code that uniquely identifies a person, business or organisation, such as passport number or Australian Business Number (ABN).\r\nCreating a linkage key"},{"id":47,"title":"Deterministic Linking","heading":"Creating a linkage key","path":"./data-integration/data-integration-projects/deterministic-linking.html#creating-a-linkage-key","content":"\r\nA linkage key is a code created using a combination of identifying information on each record, such as name, address and date of birth (see Table 1 for an example). \r\nThe linkage key usually replaces identifiers on the linked record. If the records in the linked dataset are de-identified (by removing name and address), this helps to protect the identity of the people or organisations in the new dataset. \r\nHowever, this does not necessarily ensure privacy protection. Even without name and address it may still be possible to recognise a person or organisation, through a set of unusual characteristics in the linked dataset. For example, small-area data (e.g., a suburb) showing a 17-year-old widow with four children could be recognisable to someone living in that area. Therefore, further confidentiality techniques need to be applied before releasing the data. \r\nThe Confidentiality Information Series provides more information on privacy and confidentiality. \r\nTable 1 shows how a 12 character key might be built using: \r\nthe second, third and fifth letters of a person\u2019s last name, second and third letter from a person\u2019s first name\r\nthe second, fourth, sixth and seventh numbers from a person\u2019s date of birth (DD/MM/YYYY) \r\ngender (male is 1 and female is 2)\r\nthe second and third numbers of the postcode.\r\nTable 1: Example of creating a linkage key\r\n\r\nName\r\n\r\nDate of birth\r\n\r\nGender\r\n\r\nPostcode \r\n\r\nJohn Smith12/05/1970Male5623 \r\nLinkage key = MIHOH2597162 \r\n\r\nAs with the unique identifier, if there is an error or missing information on the records, the linkage key may not match exactly and therefore the records will not be linked. \r\nAs linkage keys use identifiers in their creation, technically they could be reconstructed, thereby identifying people in the dataset. Therefore, encryption of the key is recommended as an additional safety measure to avoid the risk of identification or re-identification. \r\nAn example of deterministic linking using a linkage key"},{"id":48,"title":"Deterministic Linking","heading":"An example of deterministic linking using a linkage key","path":"./data-integration/data-integration-projects/deterministic-linking.html#an-example-of-deterministic-linking-using-a-linkage-key","content":"\r\nStage 1: Assigning linkage keys to all records within datasets A and B. This example uses a linkage key (based on Table 1) for a project looking at educational attainment and earnings, by age and sex. \r\nStage 2: Extracting the content data and unique identifier. In this example, the linkage key (MIHOH2597162) identifies the records that refer to the same person, in this case John Smith. \r\nStage 3: Merging to create a linked record. Using the linkage key, only the information required for the project (highest educational attainment, income, sex and age) is extracted from each record and merged into a new linked record (now known by the identifier MIHOH2597162) in the new dataset. (See Diagram 1) \r\nDiagram 1: A simple example of deterministic linking using a linkage key\r\n\r\n\r\nAdditional Information Australian Institute of Health and Welfare and Australian Bureau of Statistics 2012, National best practice guidelines for data linkage activities relating to Aboriginal and Torres Strait Islander people, AIHW Cat. no. IHW 74, AIHW, Canberra.\r\nAustralian Institute of Health and Welfare 2011, \u2018Comparing an SLK-based and a name-based data linkage strategy: an investigation into the PIAC linkage]\u2019, Data linkage series, No. 11. Cat. no. CSI 11, AIHW, Canberra. \r\nAustralian Institute of Health and Welfare: Karmel, R. 2005, \u2018Data linkage protocols using a statistical linkage key\u2019, Data linkage series, No. 1. Cat. no. CSI 1, AIHW, Canberra.\r\nBass, J. and Garfield, C. 2002, \u2018Statistical linkage keys: How effective are they?\u2019 Proceedings of Symposium on health data linkage, Public Health Information Development Unit, held March 20-21 2002, Sydney, pp. 40-45.\r\nNCSIMG 2004, Statistical Data Linkage in Community Services Data Collection, AIHW, Canberra."},{"id":49,"title":"Linked Data Quality","heading":"Linked Data Quality","path":"./data-integration/data-integration-projects/linked-data-quality.html#linked-data-quality","content":"\r\nEvaluating linked data quality is a key component of the linking process and essential for any subsequent analysis that uses the linked datasets. A comprehensive understanding of the linked data is built through the measurement, assessment and documentation of the linked record pair quality. \r\nData quality assessment occurs in three stages. Stage 1 is when the data is received, Stage 2 when the data is cleaned, edited and standardised, and Stage 3 occurs after the data is linked. See Diagram 1. \r\nStages 1 and 2 are covered in Preparing for Linking. Stage 3 is covered on this page. \r\nFor more information on data quality and sound data management practices, see Brackstone (1999) and the National Statistical Service website. \r\nDiagram 1: Overview of data quality checks for linked data\r\n\r\nKey Terms"},{"id":50,"title":"Linked Data Quality","heading":"Key Terms","path":"./data-integration/data-integration-projects/linked-data-quality.html#key-terms","content":"\r\nFalse links \u2013 records that were incorrectly linked and do not refer to the same entity. See Box 1.\r\nFields \u2013 types of information, such as name, address, date of birth, on the records in datasets.\r\nLinks \u2013 combined record pairs assessed as referring to the same entity (i.e., person/family/organisation/region).\r\nMatches \u2013 record pairs that actually refer to the same entity (e.g., person/family/organisation/region).\r\nMetadata \u2013 provides data users with information about the purpose, processes, and methods involved in the data collection; from design through to communication.\r\nEvaluation of linked data quality"},{"id":51,"title":"Linked Data Quality","heading":"Evaluation of linked data quality","path":"./data-integration/data-integration-projects/linked-data-quality.html#evaluation-of-linked-data-quality","content":"\r\nEvaluation of linked data quality requires a number of assessments and techniques. To do this, it is important to understand the difference between a match and a link. \r\nA match is a pair of records that refer to the same entity (e.g., person or organisation), whereas a link is a pair of records combined by the linkage process irrespective of whether the records refer to the same entity. \r\nData quality measures calculate the number of records which were correctly linked (i.e., refer to the same entity), and which records were missed. Prior to analysis, it is important to consider and assess the factors that may have influenced the linked data quality. \r\nMeasuring the quality of the links"},{"id":52,"title":"Linked Data Quality","heading":"Measuring the quality of the links","path":"./data-integration/data-integration-projects/linked-data-quality.html#measuring-the-quality-of-the-links","content":"\r\nIdeally, the set of links will be identical to the set of matches. However, this is not usually the case as there may be records without a match or a linking error may occur. See Box 1. \r\nSome of the measures used to check the quality of the links involve considerable statistical expertise. These include evaluating the accuracy, specificity, sensitivity (match rate), precision (link accuracy), false negative rate and the false positive rate. Refer to Box 2 and Christen & Goiser (2007) for more information on the definition and calculation of these measures. \r\nMeasures which rely on knowing the number of records that do not have a match (i.e., are a true negative non-link) can be difficult to calculate. Of the techniques noted above, the accuracy, specificity, false negative rate and the false positive rate measures are included in this category. \r\nMore commonly, measures based on the total number of matches that are linked (i.e. true positive links) are used. These measures include match rate and link accuracy. \r\nThe match rate is defined as: \r\nMatch rate = number of true positive links / total matches \r\nThe match rate measures the proportion of matches linked (i.e., the set of record pairs, which refer to the same entity). For example, correctly linking all matches would mean the match rate would be 100%. However, calculation of the match rate is difficult if the total number of matches is unknown. \r\nLink accuracy is the proportion of links that are matches (i.e., the proportion of links which are correct). To measure this, an estimate of the number of links that are matches should be undertaken. \r\nLink accuracy = number of true positive links / total links\r\nFor example, if 6000 out of 8000 links are correct, the link accuracy is 75%. \r\nBox 1: Classification of matches and links\r\nThere are four classifications following the linking process. Records correctly assigned a link status are: \r\nTrue positive link \u2013 records which refer to the same entity and have been correctly linked. \r\nTrue negative link \u2013 records which do not have a match and are correctly classified as a non-link. \r\nThere are two types of linking errors: \r\nFalse positive link \u2013 records that have been linked, but do not belong together (also known as false links). \r\nFalse negative link \u2013 records that have not been linked, but do belong together (also known as missed links or missed matches. \r\nLink Status"},{"id":53,"title":"Linked Data Quality","heading":"Link Status","path":"./data-integration/data-integration-projects/linked-data-quality.html#link-status","content":"\r\n\r\n\r\nMATCH\r\n\r\nNON-MATCH \r\n\r\n\r\nLINK \r\nTrue positive link (matches that are linked)False positive link (non-matches that are linked) \r\nTotal links \r\n\r\n\r\nNON-LINK \r\nFalse negative link (matches that are not linked)True negative non-link (non-matches that are not linked) \r\nTotal non-links \r\n\r\n\r\n\r\nTotal matches\r\n\r\nTotal non-matches\r\n\r\nTotal records pairs \r\nAn example of a false positive link"},{"id":54,"title":"Linked Data Quality","heading":"An example of a false positive link","path":"./data-integration/data-integration-projects/linked-data-quality.html#an-example-of-a-false-positive-link","content":"\r\nTwin sisters living in the same house with the same initials and surname may have their records incorrectly paired with each other because their linking characteristics are so similar. If the linking software used surname, initials, address, sex and date-of-birth to determine the matches, it could assess their records as a \u2018link\u2019 because of the high level of agreement between the linkage fields. \r\nA description of a false negative link"},{"id":55,"title":"Linked Data Quality","heading":"A description of a false negative link","path":"./data-integration/data-integration-projects/linked-data-quality.html#a-description-of-a-false-negative-link","content":"\r\nEven if two records on different datasets belong to the same person, the linking process may not identify them as links if: \r\nthere are errors in the source data (such as misspellings of name, address) and/or\r\nthe information changes over time (e.g., if a person changes their name after marriage, the linking software cannot tell if Jane Smith on one dataset and Jane Barnett on another are the same person, if using only name to match).\r\nAdditional approaches to checking linked data quality"},{"id":56,"title":"Linked Data Quality","heading":"Additional approaches to checking linked data quality","path":"./data-integration/data-integration-projects/linked-data-quality.html#additional-approaches-to-checking-linked-data-quality","content":"\r\nPrior to analysis, there are a number of additional checks used to assess the quality of a linked dataset. This is to ensure any limitations or issues with the linked data are taken into account during analysis. \r\nAdditional checks include comparing linked datasets, clerical assessment, comparing the expected number of links with the actual number of links, and assessing discrepancies in the representation of sub-groups. \r\nThere are other more complex approaches, such as simulation-based methods, to assess linkage quality. For more information, refer to Winglee, Valliant and Scheuren (2005). \r\n1. Comparing linked datasets"},{"id":57,"title":"Linked Data Quality","heading":"1. Comparing linked datasets","path":"./data-integration/data-integration-projects/linked-data-quality.html#1.-comparing-linked-datasets","content":"\r\nResults are compared from two separate linking methods applied to the same datasets. This may involve comparing a linked dataset with a \u2018gold standard file\u2019 or \u2018truth file\u2019 (where available) to assess the quality of the linkage strategy. For further information, see Australian Bureau of Statistics (2013). \r\n2. Clerical assessment"},{"id":58,"title":"Linked Data Quality","heading":"2. Clerical assessment","path":"./data-integration/data-integration-projects/linked-data-quality.html#2.-clerical-assessment","content":"\r\nClerical assessment can be undertaken post linkage to check the quality of the link status assigned to the records. Checking link quality involves a review, usually manual, of the linked records. It is a time consuming and subjective process.\r\nClerical assessment is different to clerical review as it examines the quality of the link following the linkage process, rather than determining if the records should be a link. For more information, see AIHW and ABS (2012).\r\n3. Comparing the expected number of links with the actual number of links"},{"id":59,"title":"Linked Data Quality","heading":"3. Comparing the expected number of links with the actual number of links","path":"./data-integration/data-integration-projects/linked-data-quality.html#3.-comparing-the-expected-number-of-links-with-the-actual-number-of-links","content":"\r\nAn initial assessment of the two source datasets may yield an estimate of the number of matches. A simplified example is where a dataset containing 3000 records is known to be a subset of a dataset with 5000 records. In such a case, the estimated number of linked records on the new dataset is 3000. Therefore, if the number of links on the new dataset were significantly less than expected, this would be cause for investigation. \r\nThis method is particularly useful if one dataset is a subset (or near subset) of another, e.g., linking an administrative dataset to a census. However, even in cases where the overlap between datasets is quite small, an accurate estimate of this overlap can often be calculated. \r\n4. Assessing discrepancies in the representation of sub-groups"},{"id":60,"title":"Linked Data Quality","heading":"4. Assessing discrepancies in the representation of sub-groups","path":"./data-integration/data-integration-projects/linked-data-quality.html#4.-assessing-discrepancies-in-the-representation-of-sub-groups","content":"\r\nChecking the characteristics of the linked dataset also provides scope for highlighting any population groups that may have been over or under represented. \r\nSome sub-groups can be hard to correctly link. For example, young adults are more mobile, making geographic fields less reliable and children often have uniform or \u201Cnot applicable\u201D values on a number of fields (such as education, qualification, occupation, marital status). A linked dataset may be under-represented on younger individuals as a result. Refer to Bishop (2009) and Wright, Bishop and Ayre (2009). \r\nWhen assessing these characteristics it is useful to consider the key factors that have influenced the linked dataset. \r\nBox 2 - A simplified introduction to the key measures of linked data quality*\r\n\r\nAccuracy rate \r\nAccuracy rate is the proportion of all record pair comparisons that are true positive links or true negative links. The denominator for this rate is the number of all record pair comparisons, while the numerator is the number of record pairs that are correctly classified as true matches or false matches. \r\n\r\nFalse-negative rate \r\nFalse-negative rate is the proportion of all record pairs belonging to the same individuals or entities that are incorrectly assigned as non-links. \r\n\r\nFalse-positive rate \r\nFalse-positive rate is the proportion of all record pairs belonging to two different individuals or entities that are incorrectly assigned as links. \r\n\r\nPrecision (link accuracy) \r\nPrecision (Link accuracy) is the proportion of all classified links that are true links as opposed to classified links that are false links. It is calculated by dividing the number of links that are ascertained as true, by the total number of classified links. \r\n\r\nSensitivity (match rate) \r\nSensitivity (match rate) is the proportion of all records in a file or database with a match in another file that were correctly accepted as a link. \r\n\r\nSpecificity or true-negative rate \r\nSpecificity or true-negative rate is the proportion of all records on one file or database that have no match in the other file that were correctly not accepted as a link. \r\n* Sourced from Australian Institute of Health and Welfare (AIHW) and Australian Bureau of Statistics (ABS) 2012. Also see Christen and Goiser 2007.\r\nFactors affecting linked data quality"},{"id":61,"title":"Linked Data Quality","heading":"Factors affecting linked data quality","path":"./data-integration/data-integration-projects/linked-data-quality.html#factors-affecting-linked-data-quality","content":"\r\nA record may be missed or a link error may occur (a \u2018false link\u2019) for three main reasons. \r\nFirst, the source data may contain missing or incorrect values on key linking fields. Poor quality data used to link the records can lead to missed links, or records linked to the wrong record. \r\nThe source data should be standardised prior to linking, to correct as much as possible typographical errors and out-of-date information. For more information and examples, refer to the CHeReL Quality Assurance report (2013). \r\nImproving the source data quality will reduce the number of missed matches and thereby improve the quality of the linked dataset. For more information on editing and standardising, \r\nSecond, a decision point in the linking process is around the trade-off between link accuracy and match rate. A strategy aimed at producing high link quality usually comes at a cost of a reduced number of total links. \r\nThis trade-off may be influenced by data availability. For example, as discussed above, there is often limited information available relating to young persons. As a result, there may be a lower degree of certainty regarding the linkage. Therefore, only accepting links that have a high degree of certainty may lead to the linked dataset containing less linked records relating to young persons. \r\nThird, the linking strategy influences the data quality through the blocking strategy used (e.g., the quality of the blocking fields used and the number of passes run), clerical review (such as setting threshold cut-offs) and, if applicable, the quality of the linkage keys created. \r\nFor more information on how the linkage strategy affects the quality of the linked data, refer to Bishop and Khoo (2007), Richter, Saher and Campbell (2013) and Australian Institute of Health and Welfare (2011). \r\nUsing documentation to improve quality"},{"id":62,"title":"Linked Data Quality","heading":"Using documentation to improve quality","path":"./data-integration/data-integration-projects/linked-data-quality.html#using-documentation-to-improve-quality","content":"\r\nDocumentation is important, as it collates and enhances an understanding of the linked data, including any factors influencing the quality of the data, prior to analysis. \r\nData linking projects require the documentation of every stage to allow for relevant evaluation and application in future projects. This is particularly useful when different linking strategies are utilised to assess the quality of the linked data. \r\nDocumentation also provides the analyst with a more comprehensive understanding of the linked data, providing context around how it may or may not be used for analytical purposes. \r\nDocumentation includes:\r\nthe context and quality of the source data, including metadata statements \r\nrisks to confidentiality and how the risks were managed (refer to the Confidentiality Information Series)\r\nhow data has been edited and standardised before linking\r\nthe linking method \r\ntechniques used to overcome issues and/or problems and\r\nresults and findings from evaluation and quality assessments.\r\nAdditional Information\r\nAustralian Bureau of Statistics 2009, ABS Data Quality Framework, Cat. no. 1520.0, ABS, Canberra.\r\nAustralian Bureau of Statistics 2013, \u2018Assessing the Quality of Linking School Enrolment Records to 2011 Census Data: Deterministic Linkage Methods\u2019,Cat. no. 1351.0.55.045, ABS, Canberra.\r\nAustralian Institute of Health and Welfare 2011, \u2018Comparing an SLK-based and name-based data linkage strategy: an investigation into the PIAC linkage\u2019, Data linking series,No. 11 Cat. no. CSI 11, AIHW, Canberra.\r\nAustralian Institute of Health and Welfare (AIHW) and Australian Bureau of Statistics (ABS) 2012, National Best Practice Guidelines for Data Linkage Activities Relating to Aboriginal and Torres Strait Islander People, AIHW Cat. no. IHW 74, AIHW, Canberra. \r\nBishop, G. 2009, \u2018Assessing the Likely Quality of the Statistical Longitudinal Census Dataset\u2019, Methodology Research Papers, Cat. no. 1351.0.55.026, ABS, Canberra.\r\nBishop, G. and Khoo, J. 2007, \u2018Methodology of Evaluating the Quality of Probabilistic Linking\u2019, Methodology Research Papers, Cat. no. 1351.0.55.018, ABS, Canberra.\r\nBrackstone, G. 1999, \u2018Managing data quality in a statistical agency\u2019, Survey Methodology, December 1999, Vol. 25, No. 2, pp. 139-149.\r\nCHeReL, Quality Assurance, http://www.cherel.org.au/quality-assurance, viewed November 2013.\r\nChristen, P. and Goiser, K. 2007, \u2018Quality and complexity measures for data linkage and deduplication\u2019, in Guillet, F. and Hamilton, H. editors, Quality Measures in Data Mining, Vol. 43 of Studies in Computational Intelligence, Springer, pp. 127-151. \r\nNational Statistical Service 2011, Confidentiality Information Series, National Statistical Service, Canberra.\r\nRichter, K., Saher, G. and Campbell, P. 2013, \u2018Assessing the quality of linking migrant settlement records to 2011 Census data\u2019, Cat. no. 1351.0.55.043, ABS, Canberra.\r\nWinglee, M., Valliant, R. and Scheuren, F. 2005, \u2018A Case Study in Record Linkage\u2019, Survey Methodology, Cat. no. 12-001, Statistics Canada.\r\nWright, J., Bishop, G. and Ayre, T. 2009, \u2018Assessing the Quality of Linking Migrant Settlement Records to Census Data\u2019, Methodology Research Papers, Cat. no. 1351.0.55.027, ABS, Canberra."},{"id":63,"title":"Part 1","heading":"Why is confidentiality important?","path":"./data-integration/data-integration-projects/part-1.html#why-is-confidentiality-important?","content":"\r\nAgencies collecting data often rely on the trust and goodwill of the Australian people to provide information. \r\nMaintaining public trust helps to achieve better quality data and a higher response to data collections. \r\nProtecting confidentiality is a key element in maintaining the trust of data providers. \r\nThis leads to reliable data to inform governments, researchers and the community. \r\nConfidentiality and therefore trust can be broken when a person or organisation can be identified in a disseminated dataset, either directly or indirectly. \r\nFor example, a person could be directly identified in a dataset if that dataset contains their name and address. However, a person or an organisation could also be indirectly identified if there is a combination of information in the dataset from which their identity can be deduced. \r\nExample: the combination of date of birth and a detailed area code (for example, a town where 300 people live) may enable identification as there will be some unique dates of birth in such a small area. "},{"id":64,"title":"Part 1","heading":"What does \u2018confidentialise\u2019 mean?","path":"./data-integration/data-integration-projects/part-1.html#what-does-\u2018confidentialise\u2019-mean?","content":"\r\nThe term confidentialise refers to the steps a data custodian must take to mitigate the risk that a particular person or organisation could be identified in a dataset, either directly or indirectly. Confidentialisation requires two key steps: \r\nde-identification of the data, that is, the removal of any direct identifiers (e.g. name and address) from the data; and\r\nassessment and management of the risk of indirect identification occurring in the de-identified dataset.\r\nDe-identified data does not necessarily protect the identity of individuals or organisations. \r\nRemoving identifying information such as name and address protects data providers from direct identification. \r\nHowever, it may still be possible to indirectly identify a person or an organisation in a de-identified dataset. If enough detail is available, the identity of a particular person or organisation may be derived from the presence of a very rare characteristic or the combination of unique or remarkable characteristics. \r\nExample: the identity of a person could be deduced if a dataset indicates the person is over 85 years old, has yearly income of more than one million dollars, and resides in a town of 400 people. \r\nExample: the identity of a person with a very rare disease or health condition could be deduced even in highly aggregated data. \r\nTo protect the identity of individuals and organisations, both direct and indirect identification need to be considered.\r\nConfidentialising data involves removing or altering information, or collapsing detail, to ensure that no person or organisation is likely to be identified in the data (either directly or indirectly). \r\nThere are various methods used to confidentialise data. These methods aim to protect the identity of individuals and organisations while enabling sufficiently detailed information to be released to make the data useful for statistical and research purposes. \r\nThe main techniques for confidentialising data are described in below: \"How to confidentialise data: the basic principles\".\r\nFor more information about assessing and managing the risks of indirect identification in microdata see below: \"Managing the risk of disclosure in the release of microdata\"."},{"id":65,"title":"Part 1","heading":"The confidentiality information series","path":"./data-integration/data-integration-projects/part-1.html#the-confidentiality-information-series","content":"\r\nThis information sheet is part of a series designed to explain, and provide advice on, a range of issues around confidentialising data. The other sheets are below.\r\nThe obligation to protect identity and privacy\r\n\r\n\r\n\r\nConfidentiality refers to the obligation of data custodians (agencies that collect information) to keep the confidential information they are entrusted with secret. \r\n\r\nThis obligation is recognised in the Privacy Act 1988. The obligation to protect confidential information is also reflected in legislation governing the collection, use and dissemination of information for specific government activities. Examples include the Social Security (Administration) Act 1999, the Taxation Administration Act 1953, and the Census and Statistics Act 1905 (see examples below). Penalties apply if the secrecy provisions set out in these Acts are breached. \r\n\r\nAs well as the requirements set out in legislation, obligations to protect a person\u2019s or organisation\u2019s identity and privacy are also outlined in government policies and principles. These provide advice on the protocols and procedures required to manage information safely. \u2018High Level Principles for Data Integration Involving Commonwealth Data for Statistical and Research Purposes\u2019 is one example of a set of principle-based obligations for Commonwealth government agencies. \r\nManaging identification risks\r\n\r\n\r\n\r\nConfidentiality, and therefore trust, can be broken when a person or an organisation can be identified in a disseminated dataset, either directly or indirectly.\r\n\r\nOne of the biggest challenges in making data publicly available is ensuring that no person or organisation is likely to be identified in the data. \r\n\r\nIdentification (often referred to as disclosure) occurs when someone learns something that they did not already know about another person or organisation through data that has been disseminated. This may be in the form of aggregate data (typically data presented in tables) or microdata (unit record data where each record represents observations for a person or an organisation). \r\n\r\n\r\nDefinitions\r\n\r\nMicrodata are unit record data containing individual responses to questions on survey questionnaires, or administrative forms. For example, data in response to the question \u2018In what year were you born?\u2019. \r\n\r\nAggregate data (or macrodata) refers to aggregated microdata. For example, a count of the number of people of a particular age (obtained from the question \u2018In what year were you born?\u2019). \r\nHow to confidentialise data: the basic principles\r\n\r\n\r\n\r\nManaging the risks of identification in disseminated data (also called disclosure control) involves taking steps to evaluate and mitigate the risk that the identity of a particular person or organisation may be disclosed. \r\n\r\nRisks of identification can be managed by confidentialising data. The aim is to protect the identity of a person or an organisation, while at the same time maximising the usefulness of the data. \r\n\r\nIn simple cases, data can be manually confidentialised. However, the use of software is sometimes necessary. Specialised skills and knowledge of the data are also required to correctly confidentialise a dataset to minimise the risk of identification. \r\n\r\nThis information sheet outlines some common techniques for confidentialising data. The information is provided as a guide only and gives simple examples, using data presented in tables, to illustrate the concepts. However, most of the techniques apply to both aggregate and microdata. \r\n\r\nIssues specific to the management of the confidentiality of microdata are discussed in Information sheet 5, \u2018Managing the risk of disclosure in the release of microdata\u2019. \r\nManaging the risk of disclosure in the release of microdata\r\n\r\n\r\n\r\n\"As the world becomes more complex and computing capabilities increasingly advance, the role of microdata in statistics has become much more important. Decision makers are increasingly turning to and requesting access to microdata.\" Statistical Journal of the International Association for Official Statistics 26 (2009/2010) 57-63 \r\n\r\nMicrodata are unit record data where each record represents observations for a person or an organisation. Microdata contain individual responses to questions on survey questionnaires, or administrative forms, including identifying information such as name, address, telephone number and age. \r\n\r\nMicrodata are a valuable resource for researchers and policy makers. The challenge for data custodians is striking the right balance between fulfilling obligations to protect the identity of individuals and organisations, and maximising the information available for statistical and research purposes. This requires careful weighing of the identification risks and benefits. \r\nHow confidentiality affects research\r\n\r\nAgencies and users should work together to promote legislative, regulatory, and dissemination policies and practices that facilitate timely and cost-effective access to data for statistical research and policy analysis but do not permit full and open access by all of the public for any use. If confidentiality issues are not fully addressed in constructive and proactive ways, users face the very real risk of losing access to high quality data\r\n\r\nSource: Doyle P, Lane JW, Theeuwes JJM, Zayatz LM (2001) Confidentiality, disclosure and data access. Theory and practical applications for statistical agencies. North-Holland. \r\n\r\nConfidentialisation techniques are applied to microdata (unit record data where each record represents observations for a person or organisation) to enable them to be made available to analysts and researchers. Without these techniques, access to valuable information for research and analytic purposes would be severely restricted. Although application of confidentialisation techniques generally leads to losses in information availability, when confidentialisation is done well and with knowledge of the key research objectives in mind, the information loss can be minimal. This fact sheet looks at the impact of confidentialisation on information availability for use in research and analysis. \r\n\r\nThere has always been a debate over the delicate balance between gaining full, unrestricted access to data (for researchers), and the application of confidentiality techniques to protect the privacy of data providers (by data custodians). Selecting the confidentiality techniques to be applied to microdata is a careful balance between fulfilling obligations to protect the identity of individuals and organisations and maximising the information available for statistical and research purposes. \r\n\r\nThe information required by the research sector is becoming more sophisticated over time. Increases in the use of techniques such as data linkage, data modelling, and data mining mean that researchers\u2019 requirements are more detailed and more varied than ever before. As a consequence, there is more pressure on data custodians to provide greater access to microdata through high quality, detailed unit record files. \r\n\r\nUsers of microdata may be concerned that any reductions or changes made to datasets during the confidentialisation process may affect their ability to undertake analysis or research using the data, or may impact on the results of an analysis. However, generally very few changes need to be made to the dataset, and in most cases these have no impact on statistical analyses. \r\n\r\nThe goal of confidentialisation is to protect the identity of individual respondents. The main types of data cells affected when confidentialising a dataset are: \r\nrare events or characteristics;\r\nunusual data (extreme high or low reported values); and\r\nlow count cross-classification cells.\r\n\r\nGenerally, statistical analysis is based on observing trends and patterns in data, and most statistical techniques rely on multiple events or individuals with similar characteristics from which to draw inferences. Where there are multiple observations with similar characteristics, the risk of individual identification is low, and the confidentialisation process generally would not result in any change to the data. The low frequency events and unusual values that are targeted in confidentialisation procedures are generally not amenable to statistical analysis. "},{"id":66,"title":"Part 1","heading":"Definitions","path":"./data-integration/data-integration-projects/part-1.html#definitions","content":"\r\nMicrodata are unit record data containing individual responses to questions on survey questionnaires, or administrative forms. For example, data in response to the question \u2018In what year were you born?\u2019. \r\nAggregate data (or macrodata) refers to aggregated microdata. For example, a count of the number of people of a particular age (obtained from the question \u2018In what year were you born?\u2019). "},{"id":67,"title":"Part 2","heading":"Managing the risk of identification (disclosure control)","path":"./data-integration/data-integration-projects/part-2.html#managing-the-risk-of-identification-(disclosure-control)","content":"\r\nThe process for managing the risk of identification is the same for any data that are disseminated, whether it is aggregate data or microdata.\r\nThe first step is to assess potential identification risks. The second step is to manage the risks of identification by using an appropriate method to confidentialise the data.\r\nThe key elements in the process of managing the risk of identification are outlined in the following diagram.\r\nA process for managing identification risk"},{"id":68,"title":"Part 2","heading":"A process for managing identification risk","path":"./data-integration/data-integration-projects/part-2.html#a-process-for-managing-identification-risk","content":"\r\nUnderstand the legal and ethical obligations to protect the confidentiality of data.\r\nEstablish policies and procedures to meet confidentiality obligations.\r\nDe-identify the data (remove any direct identifiers from the dataset)\r\nAssess potential identification risks by evaluating the factors that contribute to the likelihood of identification.\r\nTest and evaluate to mitigate risk\r\nManage the risks of identification - confidentialise.\r\nProvide safe access to data.\r\nAssessment of potential identification risks"},{"id":69,"title":"Part 2","heading":"Assessment of potential identification risks","path":"./data-integration/data-integration-projects/part-2.html#assessment-of-potential-identification-risks","content":"\r\nThe likelihood of a person or an organisation being identified, and the confidentiality methods used to minimise the risk of identification, will vary depending on a range of factors including:\r\nthe amount of detail included in the data (the more detail, the higher the risk of identification);\r\nthe sensitivity of the variables within the data (data items such as financial, health and medical or criminal record information may increase the risk of identification and would cause serious public concern if disclosed); and\r\nhow the information is presented (aggregate data released in tables poses less risk of identification than the release of microdata).\r\nConfidentialisation to manage potential identification risk"},{"id":70,"title":"Part 2","heading":"Confidentialisation to manage potential identification risk","path":"./data-integration/data-integration-projects/part-2.html#confidentialisation-to-manage-potential-identification-risk","content":"\r\nThe objective of confidentialisation is to meet legal and ethical obligations to protect the identity and privacy of individuals and organisations, while at the same time maximising the usefulness of the data for statistical and research purposes.\r\nWhile confidentialisation can be used to manage the risk of identification, it may not completely eliminate the risk.\r\nThere are two general methods (often referred to as statistical disclosure control methods) used to confidentialise data that are to be disseminated:\r\ndata modification methods (perturbation) which involve changing the data slightly to reduce the risk of disclosure, while retaining as much content and structure as possible; and\r\ndata reduction methods which aim to control or limit the amount of detail available, without compromising the overall usefulness of the information available for research.\r\nThe techniques used to confidentialise data are similar for both aggregate data and microdata. However, the way in which the risks are assessed and the confidentiality techniques which are applied are different:\r\nfor aggregate data, the techniques are applied to cells in a table identified as unsafe, after aggregation; and\r\nfor microdata, the techniques are applied to data items within individual unit records, or to individual unit records, identified as unsafe before aggregation or analysis.\r\nThis information sheet provides a broad overview of the process involved in managing the risks of identification. More detailed information is given in the subsequent information sheets in this series.\r\nHow to confidentialise data: the basic principles focuses on the risk assessment that applies to aggregate data presented in tables, and the popular confidentiality techniques that apply to both aggregate and microdata.\r\nManaging the risk of disclosure in the release of microdata focuses on the risk assessment and confidentiality considerations that apply to microdata.\r\nSee Part 1 - What is confidentiality and why is it important? for the complete series."},{"id":71,"title":"Part 3","heading":"Meeting legislative obligations","path":"./data-integration/data-integration-projects/part-3.html#meeting-legislative-obligations","content":"\r\nAgencies protect the secrecy of information by implementing policies and procedures that address all aspects of data protection.\r\nThey do this by ensuring that identifiable information about individuals and organisations:\r\nis not released publicly;\r\nis available to authorised people on a need to know basis only;\r\ncannot be derived from disseminated data; and\r\nis maintained and accessed securely.\r\nPrivacy legislation"},{"id":72,"title":"Part 3","heading":"Privacy legislation","path":"./data-integration/data-integration-projects/part-3.html#privacy-legislation","content":"\r\nThe Privacy Act 1988 sets out people\u2019s rights in relation to the collection, use and sharing of information that they provide to the Commonwealth and ACT governments. These governments are bound to privacy protections under the Information Privacy Principles of the Act.\r\nSome private sector organisations, and all health service providers, are bound by rules of conduct called the National Privacy Principles, outlined in Schedule 3 of the Act.\r\nState and territory government agencies, except Western Australia, are bound by their state privacy legislation. Currently, various confidentiality provisions and privacy principles provided in the Freedom of Information Act 1992 apply to Western Australian government agencies.\r\nInformation Privacy Principles"},{"id":73,"title":"Part 3","heading":"Information Privacy Principles","path":"./data-integration/data-integration-projects/part-3.html#information-privacy-principles","content":"\r\nThe Information Privacy Principles for Commonwealth and ACT government agencies cover:\r\nhow personal information is collected;\r\nthe storage and security of personal information;\r\naccuracy and completeness of personal information;\r\nthe use of personal information and its disclosure to third parties; and\r\nthe general right of individuals to access and correct their own records.\r\nNational Privacy Principles"},{"id":74,"title":"Part 3","heading":"National Privacy Principles","path":"./data-integration/data-integration-projects/part-3.html#national-privacy-principles","content":"\r\nThe National Privacy Principles for business cover:\r\nwhat an organisation should do when collecting personal information;\r\nthe use and disclosure of personal information;\r\ninformation quality and security;\r\nopenness;\r\nthe general right of individuals to access and correct their own records; and\r\nrules around sensitive information (e.g. health, racial or ethnic background, or criminal record).\r\nExamples"},{"id":75,"title":"Part 3","heading":"Examples","path":"./data-integration/data-integration-projects/part-3.html#examples","content":"\r\nExample 1: Social Security (Administration) Act 1999\r\nThe confidentiality provisions in the Social Security (Administration) Act 1999 prohibit any person from misusing information about a person that is, or was, held in government records for social security purposes. The provisions specify offences related to the unauthorised disclosure or use of protected information. They also specify circumstances where obtaining, recording, disclosing, or otherwise using protected information may be authorised. The penalty for breaking the confidentiality provisions is up to two years imprisonment.\r\nReference: Social Security Act 1991 and Social Security (Administration) Act 1999 Part 5 Division 3 Confidentiality.\r\nExample 2: Australian Institute of Health and Welfare Act 1987\r\nThe provisions of the Australian Institute of Health and Welfare (AIHW) Act 1987 ensure that data collections managed by AIHW are kept under strict conditions with respect to confidentiality. The penalty for breaking the confidentiality provisions is $2,000 or imprisonment for 12 months, or both. The AIHW Act 1987 provides for AIHW to release health and welfare-related data for research purposes, with the approval of the AIHW Ethics Committee, under certain terms and conditions. However, AIHW is also subject to the Privacy Act 1988, which restricts AIHW\u2019s ability to release identifiable data about living individuals.\r\nThe combined effect of these Acts is that AIHW may make health data about living individuals available for research with the approval of the AIHW Ethics Committee, provided certain terms are met. Release of identifiable welfare data may only be approved by the AIHW Ethics Committee in respect of deceased individuals. Under Section 29 of the AIHW Act, a person to whom such information is divulged for any reason is subject to the same confidentiality obligations as apply to AIHW staff.\r\nReference: Australian Institute of Health and Welfare Act 1987, Section 29.\r\nExample 3: Taxation Administration Act 1953\r\nThe disclosure of information about the tax affairs of a particular entity is prohibited except in certain specified circumstances under the Taxation Administration Act 1953. Those exceptions are designed to meet the principle that disclosure of information should be permitted only if the public benefit derived outweighs the entity\u2019s privacy. The penalty for breaking these provisions of the Taxation Act is two years imprisonment.\r\nReference: Taxation Administration Act 1953, Schedule 1, Division 355, Confidentiality of taxpayer information.\r\nExample 4: Census and Statistics Act 1905\r\nThe Census and Statistics Act 1905 gives the Australian Bureau of Statistics (ABS) authority to collect data for statistical purposes. Under this Act, information supplied to the ABS cannot be published or disseminated in a manner that is likely to enable the identification of a particular person or organisation. The Act contains provisions obliging past and present employees of the ABS to maintain the secrecy of data collected under the Census and Statistics Act. A fine of up to $20,400, or a penalty of two years imprisonment, or both, applies to an unauthorised disclosure of information collected under the Act.\r\nReference: Census and Statistics Act 1905, Sections 12 and 19.\r\nExample 5: High Level Principles for Data Integration Involving Commonwealth Data for Statistical and Research Purposes\r\nCommonwealth Portfolio Secretaries have endorsed a set of principles for a safe and effective environment for data integration involving Commonwealth data for statistical and research purposes. Principle six, Preserving Privacy and Confidentiality, says that policies and procedures used in data integration must minimise any potential impact on privacy and confidentiality. For example, access to potentially identifiable data for statistical and research purposes outside secure and trusted institutional environments should only occur where: legislation allows; it is necessary to achieve the approved purposes; and it meets agreements with source data agencies."},{"id":76,"title":"Part 4","heading":"Identification risks in aggregate data","path":"./data-integration/data-integration-projects/part-4.html#identification-risks-in-aggregate-data","content":"\r\nAggregate data can be disseminated in various forms including tables, maps and graphs. Aggregate data in any form can present an identification risk if individual responses can be estimated or derived from the output (for example, outliers in a graph).\r\nTables are the most common way of presenting aggregate data and are the focus of the following discussion.\r\nThere are two main types of tables:\r\nCount (frequency) tables: cells contain the number of individuals or organisations contributing to the cell (e.g. the number of people in various age groups, or the number of businesses in each industry).\r\nMagnitude tables: cells contain values calculated from a numeric response (e.g. total income or profit).\r\nIt is sometimes possible to deduce information about a particular person or organisation from these two types of tables.\r\nFor example, when a cell in a frequency table has a low count (that is, only a very small number of contributors), it may be possible to deduce information about a particular person or organisation using the information you already know and the additional information presented in the table. This poses an identification (or disclosure) risk.\r\nIn magnitude tables, table cells present an identification (or disclosure) risk when they are dominated by values relating to one or two businesses or individuals.\r\nFurther identification risks exist if users have access to multiple tables that contain some common elements. It may be possible to use information from one table to determine the identity of a person or organisation contributing to a second table. This means it is important to keep track of all information that is released from the dataset.\r\nWhen should a cell be confidentialised?"},{"id":77,"title":"Part 4","heading":"When should a cell be confidentialised?","path":"./data-integration/data-integration-projects/part-4.html#when-should-a-cell-be-confidentialised?","content":"\r\nTo identify table cells that pose an identification (or disclosure) risk, confidentiality ruIes must be determined and applied to each cell in a table. If a cell fails such rules, then further investigation or action is needed to minimise the risk of identification.\r\nTwo common rules used to assess identification risk in a table cell are:\r\nThe frequency rule (also called the threshold rule), which sets a threshold value for the minimum number of units (contributors) in any cell. Common threshold values are 3, 5 and 10.\r\nThe cell dominance rule (also called the cell concentration rule) which applies to cells where a small number of data providers contribute a large percentage to the cell total.\r\nSetting values for these rules is the responsibility of individual data custodians. The value used will depend on that custodian\u2019s assessment of the identification risk. Some datasets may be more sensitive than others while legislation and organisational policies will also influence the values that are set and applied.\r\nFrequency Rule"},{"id":78,"title":"Part 4","heading":"Frequency Rule","path":"./data-integration/data-integration-projects/part-4.html#frequency-rule","content":"\r\nThe frequency rule is best applied to count tables. While it can be used for magnitude tables, the underlying frequency data (i.e. the number of contributing units for each cell) is needed to apply the rule.\r\nSometimes zero cells (cells with no contributors, or cells where all respondents reported a zero value for a magnitude table), or 100% cells (where all contributors within a category have a particular characteristic) are also considered confidential.\r\nA 100% cell that may not require protection is included in example 1. In this example all 15\u201319 year olds have a low income (20). This result may not be unexpected or sensitive and the cell may not require protection. However, if this same example related to a very small community and the 100% cell was instead for 15\u201319 year olds with high income then the cell may need to be protected from an identification risk as the result is unexpected and may be considered sensitive.\r\nCell Dominance Rule"},{"id":79,"title":"Part 4","heading":"Cell Dominance Rule","path":"./data-integration/data-integration-projects/part-4.html#cell-dominance-rule","content":"\r\nThe cell dominance rule is also referred to as the (n,k) rule and is used for magnitude tables.\r\nAccording to the cell dominance rule, a cell is regarded as unsafe if the combined contributions of the \u2018n\u2019 largest members of the cell represent more than \u2018k\u2019% of the total value of the cell.\r\nThe 'n' and 'k' values are determined by the data custodian.\r\nTechniques to confidentialise data"},{"id":80,"title":"Part 4","heading":"Techniques to confidentialise data","path":"./data-integration/data-integration-projects/part-4.html#techniques-to-confidentialise-data","content":"\r\nThere are various techniques used to confidentialise data that pose an identification risk \u2013 either as an unsafe cell in aggregated data, or as unsafe records in microdata. These are grouped into two broad groups: data reduction methods and data modification methods.\r\nData reduction methods"},{"id":81,"title":"Part 4","heading":"Data reduction methods","path":"./data-integration/data-integration-projects/part-4.html#data-reduction-methods","content":"\r\nThese methods maintain confidentiality of respondents by selecting appropriate aggregations or in presentation of data.\r\nCombining (or collapsing) categories \r\nThis method involves combining several response categories into one, or reducing the amount of classificatory detail available in a table or in microdata. It is often used for magnitude data and sometimes for count data. Combining or collapsing categories is best used when a handful of responses have a small number of contributors, or when a table is very detailed and there are many small cells. A good knowledge of the subject is important when combining or collapsing categories to ensure that the new category groupings are relevant to data users.\r\nPrimary and secondary suppression Data suppression \r\nThis involves not releasing information for unsafe cells, or, if nothing else works, deleting individual records or data items from the microdata file. If a table contains totals, it may be possible to calculate the value of a suppressed cell by subtracting the value of other cells from the total. At least one additional cell may also need to be suppressed to prevent identification. A cell that is suppressed because it fails one of the confidentiality rules is called a primary suppression cell. The suppression of other cells (to prevent the disclosure of a primary suppression cell) is called secondary suppression or consequential suppression.\r\nData modification methods (Perturbation)"},{"id":82,"title":"Part 4","heading":"Data modification methods (Perturbation)","path":"./data-integration/data-integration-projects/part-4.html#data-modification-methods-(perturbation)","content":"\r\nThese methods maintain respondent confidentiality by altering the identifiable data in a small way without affecting aggregate results.\r\nData rounding\r\nData rounding involves slightly altering small cells in a table to ensure results from analysis based on the data are not significantly affected, but the original values cannot be known with certainty. Data rounding may be random or controlled.\r\nRandom rounding is used in count tables and involves replacing small values that would appear in a table with other small random numbers. This results in some data distortion so that the sum of cell values within or between tables will not equal the table total. Random rounding to base X involves randomly changing every number in a table to a multiple of X. For example, random rounding to base 3 (RR3) means that all values are rounded to the nearest multiple of 3. Each value, including the totals, is rounded independently. Values which are already a multiple of 3 are left unchanged.\r\nGraduated random rounding is a rounding method used for magnitude tables. It is similar to random rounding, however after specified cell sizes the rounding base increases. That is, a small number will have a smaller rounding base than a large number. This ensures the protection offered does not diminish for large-valued cells.\r\nControlled rounding is a form of random rounding but it is constrained to have the sum of the cells equal to the appropriate row or column totals within a table. This method may not provide consistency between tables.\r\nSampling"},{"id":83,"title":"Part 4","heading":"Sampling","path":"./data-integration/data-integration-projects/part-4.html#sampling","content":"\r\nSampling provides some protection against identification risks because it reduces the certainty about whether a particular individual or organisation is in the data. A value may be unique in the sample, but not necessarily unique in the population."},{"id":84,"title":"Part 5","heading":"Types of disclosure risk in microdata","path":"./data-integration/data-integration-projects/part-5.html#types-of-disclosure-risk-in-microdata","content":"\r\nThere are two key types of disclosure risk associated with microdata:\r\nrisk that identification is made without any deliberate attempt to identify a person or organisation (spontaneous recognition); and\r\nrisk associated with a deliberate (malicious) attempt to identify a person or organisation.\r\nSpontaneous recognition - an identification made without any deliberate attempt, can occur if individuals with rare characteristics are present in the data. The identification risk this poses depends on how remarkable the characteristic(s) are. For example, the dataset may include people with unusual jobs (e.g. pop star or judge) or very large incomes which are highly visible in the data and could lead to their identification.\r\nDeliberate attempts to identify a person or an organisation in a dataset may include, for example, list matching (matching unique records to external files using a combination of characteristics common to both datasets) or a \u2018record attack\u2019 (where a user tries to find a particular person or organisation with a set of characteristics known to the user).\r\nManaging the risks of identification"},{"id":85,"title":"Part 5","heading":"Managing the risks of identification","path":"./data-integration/data-integration-projects/part-5.html#managing-the-risks-of-identification","content":"\r\nAssessing microdata for identification risks is a subjective process which requires a detailed examination of the data. Methods to assess identification risk in microdata include:\r\ncross-tabulation of variables (for example looking at age by income or marital status) to determine unique combinations that may enable a person or an organisation to be identified;\r\ncomparing sample data with population data to determine whether the unique characteristics in the sample are unique in the population; and\r\nacquiring knowledge of other datasets and publicly available information that could be used for list matching.\r\nThe risk of identification can also be assessed by considering factors that contribute to the likelihood of identification (see below).\r\nVarious software packages are available to help assess potential identification risks. These include:\r\nMu-ARGUS - a software package developed by Statistics Netherlands. The software is designed to protect against spontaneous recognition only and does not attempt to protect against list matching.\r\nSUDA - software developed by the University of Manchester. SUDA stands for 'Special Unique Detection Algorithm'. It examines unit record data files and looks for records that are at risk of identification because they have unique combinations of characteristics.\r\nProtecting microdata"},{"id":86,"title":"Part 5","heading":"Protecting microdata","path":"./data-integration/data-integration-projects/part-5.html#protecting-microdata","content":"\r\nThe first level of protection for microdata is to remove direct identifiers such as names and Australian Business Numbers. Direct identifiers should always be removed from the data before release. However, there is still a risk of indirect identification occurring in the de-identified data.\r\nTwo common approaches to protect microdata are confidentialising and/or restricting access to the file.\r\nConfidentialising microdata"},{"id":87,"title":"Part 5","heading":"Confidentialising microdata","path":"./data-integration/data-integration-projects/part-5.html#confidentialising-microdata","content":"\r\nData perturbation and data reduction methods are used to confidentialise microdata. These are the same basic principles used to protect aggregate data. Popular techniques to confidentialise microdata include:\r\nlimiting the number of variables included in the dataset;\r\nintroducing small amounts of random error (e.g. rounding or data swapping);\r\ncombining categories that are likely to enable identification (e.g. giving age in five year ranges);\r\ntop/bottom coding extreme values of continuous variables like income or age;\r\nsuppressing particular values or records that cannot otherwise be protected from the risk of identification; and\r\ndata swapping - this involves swapping a value in an identifiable record with a value in another record with similar characteristics to hide the uniqueness of the record. For example, a record with a unique language spoken in the region could be swapped with a similar record (based on age, sex, income etc.) in another region where the language is more commonly spoken.\r\nRestricting access to the microdata file"},{"id":88,"title":"Part 5","heading":"Restricting access to the microdata file","path":"./data-integration/data-integration-projects/part-5.html#restricting-access-to-the-microdata-file","content":"\r\nProviding controlled access to microdata is important in protecting the data from identification (or disclosure) risk.\r\nAccess to detailed microdata should only be provided under the strictest conditions to approved researchers for an approved purpose. Generally researchers must sign undertakings to abide by specified conditions for access and use of the data.\r\nThe extent to which the files are confidentialised will determine how the files are accessed. The more detailed the information, the more protection is required when providing access to microdata.\r\nOne way of releasing microdata is in the form of Confidentialised Unit Record Files (CURFs). These are files that have been confidentialised to ensure that the direct and indirect identification of individuals or organisations is highly unlikely.\r\nA highly confidentialised microdata file, such as a CURF, may be released publicly on CD-ROM. However, if more detail is left in the CURF, more secure ways of accessing the data need to be used.\r\n\r\nResearchers who need lots of detail may have to access the data through a very secure environment. Secure on-site data laboratories are one way of achieving this. The microdata are de-identified and should have some level of confidentialisation to avoid spontaneous recognition, but may still contain data that would allow indirect identification. For this reason, access to this data is available only at data custodian access sites so that all output generated is confidentialised before it leaves the premises.\r\nAnother option is providing access to microdata through a remote access facility. Remote access facilities are used by statistical agencies and research organisations around the world and mean data users can access microdata from their desktop. Approved researchers can submit data queries through a secure internet-based interface. Requests are generally run against the microdata which is securely stored within the data custodian\u2019s computing environment. The results of the queries are confidentialised.\r\nFactors that increase the risk of identification"},{"id":89,"title":"Part 5","heading":"Factors that increase the risk of identification","path":"./data-integration/data-integration-projects/part-5.html#factors-that-increase-the-risk-of-identification","content":"\r\nMotivation to attempt identification\r\nMotivation is very hard to assess but one issue to consider is whether an organisation or individual would receive any tangible benefit if identification was made.\r\nLevel of detail disclosed by the data\r\nThe more detail that is included in a unit record, the more likely identification becomes. Data items containing detailed categories, or unit records containing a large number of data items, could reveal enough information to enable identification to be made through a unique combination of characteristics.\r\nPresence of rare characteristics in the data\r\nEven if the number of data items and the number of categories within the data items are limited, there may be a risk of identification if there is a rare and remarkable characteristic in the data. The identification risk posed by the presence of a rare characteristic (or combination of characteristics) depends how remarkable the characteristic is. For example, a 19 year old girl who is widowed is likely to be noticeable in the data and further action would be needed to ensure confidentiality.\r\nAccuracy of the data\r\nThe more accurate the dataset, the higher the risk of identification. Conversely, data that are subject to reporting errors, or contain some data items that are not maintained and consequently are out of date, decrease the likelihood of identification.\r\nAge of the data\r\nAs a general rule, disclosing an individual's area of residence or marital status 10 years ago is less likely to enable a successful identification than disclosing their current characteristics. However, in some circumstances, the risk of identification can increase as age increases - for example, current quarter earnings for a business may be kept confidential and known only to a small number of people, but previous year earnings may be published in an annual report and so may be publicly available information, enabling identification.\r\nCoverage of the data (completeness)\r\nComplete coverage of a dataset increases the risk of disclosure because a researcher knows that any individual they are aware of in a sub-population will be represented somewhere in the dataset. The sampling process (and the fact that the specific sample selections that have been made are kept confidential) provides some protection against identification.\r\nPresence of other information that can assist in identification\r\nA de-identified dataset cannot, of itself, lead to an identification being made. For an identification to occur a researcher must, implicitly or explicitly, match the data to some other data source, either publicly available information or personal knowledge. Given this, other information that is likely to be accessible or known to the researcher(s) must be assessed."},{"id":90,"title":"Part 6","heading":"Types of research","path":"./data-integration/data-integration-projects/part-6.html#types-of-research","content":"\r\nWhile the data requirements for researchers are highly diverse, research studies can be broadly divided into two main groups: quantitative and non-quantitative.\r\nQuantitative studies require sufficient amounts of data for reliable estimates or models;\r\nnon-quantitative studies may focus on an in-depth analysis of an unusual characteristic or small cohort.\r\nQuantitative research and confidentiality"},{"id":91,"title":"Part 6","heading":"Quantitative research and confidentiality","path":"./data-integration/data-integration-projects/part-6.html#quantitative-research-and-confidentiality","content":"\r\nWhen undertaking analysis for quantitative based research, analysts require sufficient amounts of data to ensure high quality outputs. If the required variables of interest are available, Confidentialised Unit Record Files (CURFs) should be able to meet the needs of researchers. This is because the confidentiality techniques applied to these files are the same steps that analysts typically apply to the data to ensure robust outputs. That is:\r\ncollapse cells with small counts;\r\ncollapse numeric values into groups;\r\nrecode variables with long tails (extreme high or low reported values); and\r\nremove, or otherwise treat, outliers in distributions.\r\nFor these types of analyses the outputs achieved using CURFs should not differ greatly from the results that would have been achieved using the original non-confidentialised unit record files.\r\nExample: How does confidentiality affect statistical analysis?"},{"id":92,"title":"Part 6","heading":"Example: How does confidentiality affect statistical analysis?","path":"./data-integration/data-integration-projects/part-6.html#example:-how-does-confidentiality-affect-statistical-analysis?","content":"\r\nProfessor David Lawrence, Telethon Institute of Child Health Research (TICHR)\r\nCase study: Cigarette smoking and anxiety disorders\r\nTICHR conducted a study using the ABS\u2019 2007 Survey of Mental Health and Wellbeing expanded Confidentialised Unit Record File (CURF) to investigate the association between smoking and mental health problems. The expanded CURF was analysed through the Remote Access Data Laboratory (RADL). The RADL is a remote analysis environment where a client can submit analysis code to the data custodian, via the internet, and subsequently receive the output without ever having direct access to the unit record level information.\r\nAfter the project was completed, an evaluation was conducted to determine whether the confidentiality techniques of perturbation and re-coding of variables (high and low data values) applied to the CURF had any effect on the results of the analysis. An ABS officer re-ran the analyses using the Survey of Mental Health and Wellbeing master file (the original file before confidentialisation techniques were applied). The analysis included running several multi-way weighted tables of proportions, and fitting several logistic and proportional hazards regression models. Results from the study were published to three significant digits. None of the figures varied between the CURF and master file analyses at this level of precision.\r\nTable 1 shows estimated hazard ratios for quitting smoking to five significant digits as obtained from performing the same analyses on both the expanded CURF and the original master file. The largest difference was observed at the level of 4 significant digits, and represented 1% of the standard error of the relevant estimate.\r\nThe minor changes between the CURF and master file analyses were of neither practical or statistical significance. This result is consistent with the very small level of change to the dataset during the confidentialisation process as described in the User\u2019s Guide for the survey CURF.\r\nSummary: When our research on smoking and mental illness was run on the master file, the outputs were not practically different to those achieved using the expanded CURF. Therefore, the confidentiality techniques applied to the master file (perturbation and recoding of variables) did not affect the analyses conducted or the conclusions drawn from them during the project.\r\nFull details of the weighted analyses and models undertaken for this project are described in: Lawrence D, Considine J, Mitrou F, Zubrick SR (2010) Anxiety disorders and cigarette smoking. Results from the Australian Survey of Mental Health and Wellbeing. Australian and New Zealand Journal of Psychiatry. 44: 521-528.\r\nTable 1: Hazard ratios* for smoking cessation, people with anxiety disorders compared with people with no lifetime mental disorder, by type and nature of anxiety disorder \r\n\r\nDisorder \r\n\r\nHazard Ratio (from CURF) \r\n\r\nHazard Ratio (from master file) \r\n\r\nStandard Error of Hazard Ratio \r\n\r\nDifference between hazard ratios as proportion of standard error \r\n\r\nNo lifetime mental disorder 1.00 1.00 (reference category) \r\n\r\nAnxiety disorders, by type - \r\n\r\n\r\nPanic disorder \r\n0.59678 0.59615 0.10335 0.0102 \r\n\r\nAgoraphobia \r\n0.44936 0.44936 0.08420 0 \r\n\r\nSocial phobia \r\n0.55374 0.55374 0.07973 0 \r\n\r\nGeneralised anxiety disorder \r\n0.33631 0.33631 0.07846 0 \r\n\r\nObsessive-compulsive disorder \r\n0.47782 0.47782 0.10674 0 \r\n\r\nPost-traumatic stress disorder \r\n0.63221 0.63221 0.07865 0 \r\n\r\nAnxiety disorders, by severity -\r\n\r\n\r\nMild \r\n0.74901 0.74882 0.11495 0.00218 \r\n\r\nModerate \r\n0.58942 0.5892 0.08275 0.00447 \r\n\r\nSevere \r\n0.39196 0.39202 0.06016 0.00249 \r\n\r\nAnxiety disorders, by use of services - \r\n\r\n\r\nHas accessed services \r\n0.54875 0.54858 0.07046 0.00426 \r\n\r\nNo use of services \r\n0.59683 0.59669 0.07113 0.00323 \r\n\r\nAnxiety disorders, by years since first onset - \r\n\r\n\r\n0-2 years \r\n0.73114 0.73089 0.16758 0.00203 \r\n\r\n2-5 years \r\n0.74544 0.74492 0.20212 0.00346 \r\n\r\n5-10 years \r\n0.59126 0.59086 0.12845 0.00522 \r\n\r\nMore than 10 years \r\n0.53100 0.53093 0.05969 0.00201 \r\n* Hazard ratios measure how often a particular event occurs in one group compared to how often it occurs in another group, over time.\r\nNon-quantitative research"},{"id":93,"title":"Part 6","heading":"Non-quantitative research","path":"./data-integration/data-integration-projects/part-6.html#non-quantitative-research","content":"\r\nNon-quantitative research may include the qualitative investigation of the circumstances surrounding rare events of interest. CURFs do not meet the data requirements for these studies as CURFs are de-identified and subject to confidentialisation techniques. Alternative approaches are needed. This may require the consent of the subjects involved to participate in this type of research.\r\nExample: A qualitative study of children born with a rare birth defect\r\nThis type of study may aim to better understand what factors may have led to the occurrence of a rare birth defect, with the ultimate goal of preventing their occurrence or decreasing their incidence. Clearly these studies play an important role in understanding rare cases or phenomena, but they require an alternative approach to statistical analysis methods.\r\nIn this example, administrative microdata may be useful to identify potential participants in a more detailed study. The researcher would require special approval from the custodian to obtain the sensitive data records. This permission could be granted by a body such as a Human Research Ethics Committee constituted under the National Health and Medical Research Council (NHMRC).\r\nFurther to this, permission and further information may be needed from the parents of the child born with the rare birth defect. This type of research is best conducted by approaching the affected individuals and directly seeking their consent to participate in a research study. Statistical analysis of a microdata file, whether from a survey or an administrative data source, is rarely the most appropriate research design for this type of investigation.\r\nConclusion"},{"id":94,"title":"Part 6","heading":"Conclusion","path":"./data-integration/data-integration-projects/part-6.html#conclusion","content":"\r\nThere are generally two types of research: quantitative and non-quantitative.\r\nFor quantitative research, data custodians are turning to a diverse range of products to meet researchers\u2019 needs, including CURFs and data laboratories. Generally speaking, as the small changes that are made to unit record files during the confidentialisation process usually target unusual or extreme values only, the confidentiality techniques used to make the microdata available have little impact on the analyses performed in these types of studies. In many cases the small proportion of information that is lost from the original microdata has no impact on the question being analysed, and often similar steps would be taken by the researcher to prepare the data for the statistical analysis. As a result there will be little to no impact on the analysis using the confidentialised file compared to the original file.\r\nFor non-quantitative studies, such as examining unusual characteristics or small cohorts, or linking datasets, the current publicly available data products or methods are not able to meet the researcher\u2019s needs. In these cases, researchers are required to complete a more rigorous application process. This may include sign-off from an ethics committee, permission from the data custodian, and possibly, permission from the data provider.\r\nThese types of data requests are increasing and researchers and data custodians will need to work together to come up with innovative ways to streamline access to datasets while ensuring that the confidentiality of the data provider is always respected and maintained. This is critical to ensuring the continuation of Australia\u2019s high quality data collections."},{"id":95,"title":"Preparing for Linking","heading":"Preparing for Linking","path":"./data-integration/data-integration-projects/preparing-for-linking.html#preparing-for-linking","content":"\r\nSignificant effort is required to prepare datasets before they can be linked. Pre-linking preparation includes understanding the source dataset, selecting which fields to use for linking, data cleaning and standardising and, where required, secure data transfer. \r\nIt has been estimated that about three-quarters of the effort involved in data linking involves preparing the data to ensure the input files are ready for linking (Gill, 2001). \r\nIt is necessary to invest the time and effort in data preparation in order to ensure the quality of the linked dataset. \r\nUnderstanding the source datasets"},{"id":96,"title":"Preparing for Linking","heading":"Understanding the source datasets","path":"./data-integration/data-integration-projects/preparing-for-linking.html#understanding-the-source-datasets","content":"\r\nBefore attempting linking, it is important to understand the information in the datasets being linked, to ensure the linking software is comparing \u2018apples with apples\u2019. This can be achieved in a number of ways, including examining the metadata and checking a sample of the dataset. \r\nMetadata is information about data that provides context or additional information, such as how and when the data was collected, its purpose and quality. \r\nUnderstanding the metadata helps to avoid combining data that is not compatible. For example, one data source might report earnings on a financial year basis while the other uses calendar year reporting. This would need to be resolved before linking and analysis can occur. \r\nFor more information on metadata, there are references listed at the end of this sheet. \r\nSelecting which fields to use for linking"},{"id":97,"title":"Preparing for Linking","heading":"Selecting which fields to use for linking","path":"./data-integration/data-integration-projects/preparing-for-linking.html#selecting-which-fields-to-use-for-linking","content":"\r\nThe main requirement when selecting which fields to use for linking is to ensure that they exist on each of the datasets being linked. Other considerations include the quality of that data, such as whether the data contains any errors or missing information. These may be caused by, for example, variations in spelling (Smith and Smyth), incomplete information or spelling errors (e.g., is \u2018Ray\u2019s Burgers\u2019 the same business as \u2018Roy\u2019s Burgers\u2019?). \r\nDifferences in the fields on different datasets often arise as a result of factors in the data collection phase. Errors may occur if information is supplied by a relative rather than the person themselves, as could be the case, for example, for schools enrolment data or hospital admissions. \r\nVarying levels of quality between datasets often depend on the relative importance of a particular field for a dataset. For example, in mortality datasets the names are critical for identity resolution reasons and so this field is collected and transcribed very carefully and is, therefore, high quality. \r\nData cleaning and standardising"},{"id":98,"title":"Preparing for Linking","heading":"Data cleaning and standardising","path":"./data-integration/data-integration-projects/preparing-for-linking.html#data-cleaning-and-standardising","content":"\r\nThe terms \u2018data cleaning\u2019 and \u2018data standardisation\u2019 refer to the task of transforming the records on each dataset into a format that allows them to be linked with other datasets. \r\nThe key aim of data cleaning and standardising is to ensure all the data being linked is consistent and uniform, so the linking software can work effectively. \r\nMost datasets contain some incomplete, out-of-date or differently formatted information. Computerised records can contain errors because, for example, information has been provided or recorded incorrectly. \r\nThe most common data inconsistencies involve variations in spelling of names, such as nicknames (e.g., Rob and Robert), formats of date of birth, data coding and missing information. Techniques used to resolve these inconsistencies to convert data into standard forms include: editing, standardising, de-duplication and correspondences. \r\nEditing is the identification and treatment of data errors and anomalies. For example, editing may include the removal of an impossible response, such as a birth date in the future and its re-clarification as a missing value. \r\nWhere data is missing, sometimes there is enough information available to approximate the data. This is often called \u2018data repair\u2019. Data repair should be well documented in terms of the decisions arrived at and data used to make the repairs. \r\nThis may involve accessing additional information from previous data collections similar to the one being linked, to check for inconsistencies and help to inform decisions about missing information. An example of data repair would involve changing a postcode to match suburb and street information. \r\nStandardising is the formatting of data items so they are consistently represented in all of the datasets. For example, dates can be represented in different formats such as, DD/MM/YYYY or MM/DD/YYYY. One format should be selected and employed across all of the datasets for that project. \r\nDe-duplication is removing duplicates from a dataset. For example, when a record incorrectly appears more than once in a dataset with exactly the same data item value, one copy should be retained, and the others should be removed. Alternatively, the same unit may appear more than once in the same dataset but with different values for some of the data items. Sorting and ordering the datasets will highlight these cases. A set of rules should be developed to treat such duplicates in a consistent manner, such as how to decide which records to keep. \r\nCorrespondence involves creating a consistent coding classification across all datasets. A sound understanding of the data is required to produce the best correspondence. Table 1 shows how marital status could be coded in two different datasets. \r\nDataset 2 could be used as the standard and the first dataset would be altered to be consistent with that coding. \r\nTable 1: Example of a correspondence for marital status\r\n\r\nDataset 1\r\n\r\nDataset 2 \r\n\r\n1. Never Married1. Never Married \r\n\r\n2. Currently Married2. Currently Married \r\n3. Separated3. No Longer Married \r\n4. Divorced \r\n5. Widowed \r\nSecure data transfer"},{"id":99,"title":"Preparing for Linking","heading":"Secure data transfer","path":"./data-integration/data-integration-projects/preparing-for-linking.html#secure-data-transfer","content":"\r\nWhen transferring data between organisations, secure data transfer considerations are essential to preserve privacy. They include consideration of the format, method and encryption. \r\nBox 1 shows an example of secure data transfer, based on Statistics New Zealand\u2019s key steps in encrypted-DVD courier delivery \u2013 a common method of data transfer for large datasets. \r\nEmail transfer is often only suitable for small datasets. More secure email systems are being developed that could provide better options for consideration in the future. \r\nBox 1: Example of key steps for secure data transfer by courier\r\n\r\n1. Media creation and encryption \r\nThe data custodian extracts information from their systems and copies it to a CD/DVD using an encrypted format. \r\n\r\n\r\n2. Handover to courier \r\nThe data custodian hands the media to the courier, with the name and address of the recipient (the organisation doing the linking). \r\n\r\n\r\n3. Delivery \r\nA key contact person from the linking organisation receives the data and signs for its receipt. All transactions must be recorded. \r\n\r\n\r\n4. Transfer to IT secure facilities \r\nThe data should be personally carried by the key contact person to the relevant secure IT facilities of the linking organisation. \r\n\r\n5. Place in safe storage \r\nThe data transfer and the database loading are completed and stored securely. \r\n\r\n6. Disposal \r\nOnce transfer is completed, the linking organisation destroys the media (i.e., shredding of DVDs, deletion of back-up files, and for very sensitive information at high risk, degaussing (demagnetisation)). \r\n\r\n\r\n7. Confirmation to data custodian \r\nThe linking organisation informs the data custodian when the data transfer is successful (or not). \r\n\r\n\r\n8. Preliminary checks of the data \r\nOnce the data has been received, the linking organisation checks the received data to confirm it is fit-for-purpose. \r\nAdditional Information\r\n\r\nData quality\r\nAustralian Bureau of Statistics 2011, Information Paper: Quality Management of Statistical Outputs Produced from Administrative Data, Cat. no. 1522.0, Australian Bureau of Statistics, Canberra.\r\nAustralian Institute of Health and Welfare Metadata Online Registry (METeOR), metadata, quality statements and National Data Dictionaries http://meteor.aihw.gov.au\r\n\r\nData cleaning and standardising\r\nGill, L. 2001, \u2018Methods for Automatic Record Matching and Linkage and their Use in National Statistics\u2019, National Statistics Methodological Series, No. 25, Oxford University, Norwich."},{"id":100,"title":"Probabilistic Linking","heading":"Probabilistic Linking","path":"./data-integration/data-integration-projects/probabilistic-linking.html#probabilistic-linking","content":"\r\nProbabilistic linking is a method for combining information from records on different datasets to form a new linked dataset. \r\nIt has been described as a process that attempts to link records on different files that have the greatest probability of belonging to the same person/organisation. \r\nWhereas deterministic (or exact) linking uses a unique identifier to link datasets, probabilistic linking uses a number of identifiers, in combination, to identify and evaluate links. \r\nProbabilistic linking is generally used when a unique identifier is not available or is of insufficient quality. \r\nThe method derives its name from the probabilistic framework developed by Fellegi and Sunter (1969) and requires sophisticated software to perform the calculations. References at the end of this sheet provide more information about linking algorithms. \r\nThe key steps of probabilistic linking (as shown in Diagram 1) are:\r\nData cleaning and standardisation\r\nBlocking\r\nLinking\r\nClerical review\r\nEvaluating data quality\r\nDiagram 1: Key steps in probabilistic linking\r\nKey Terms"},{"id":101,"title":"Probabilistic Linking","heading":"Key Terms","path":"./data-integration/data-integration-projects/probabilistic-linking.html#key-terms","content":"\r\nBlocking \u2013 divides datasets into groups, called blocks, in order to reduce the number of comparisons that need to be conducted to find which pairs of records should be linked. Only records in corresponding blocks on each dataset are compared, to identify possible links.\r\nFields \u2013 types of information, such as name, address, date of birth, on the records in datasets.\r\nLinked dataset \u2013 the result of linking different datasets is a new dataset whose records contain some information from each of the original datasets.\r\nLinks \u2013 records that have been combined after being assessed as referring to the same entity (i.e., person/family/organisation/region).\r\nUnique identifier \u2013 a number or code that uniquely identifies a person, business or organisation, such as passport number or Australian Business Number (ABN).\r\nKey steps in probabilistic linking"},{"id":102,"title":"Probabilistic Linking","heading":"Key steps in probabilistic linking","path":"./data-integration/data-integration-projects/probabilistic-linking.html#key-steps-in-probabilistic-linking","content":"\r\n1. Data cleaning and standardisation\r\nSee Preparing for Linking in this information series. \r\n2. Blocking\r\nData linking involves a large number of record comparisons. Ideally, every record on Dataset A is compared with each one on Dataset B to find which record pairs are most likely to be links. However, if every record is compared between two datasets containing 100 000 records each, this would require 10 billion comparisons. Even using advanced computer power, this would take a long time to perform. \r\nAs a way to save time, \u2018blocking\u2019 is used to reduce the number of record comparisons required to find potential record pairs. \r\nBlocking is similar to sorting a basket of socks into like colours before trying to locate the pairs. See Diagram 2. \r\nFor example, by using gender for blocking, only records with the same sex (males or females) are compared to each other, which usually cuts in half the number of comparisons required. \r\nHowever, gender is not overly useful for blocking as it only separates the dataset into two large blocks, so a lot of comparisons are still required. Ideally, a blocking strategy should result in small, equal-sized blocks on each dataset. \r\nFor example, using month of birth would result in 12 blocks (one for each month) and be expected to have a fairly even number of records in each block. A common strategy is to keep the block sizes as small as possible and run multiple blocking passes. \r\nBlocking Passes\r\nSometimes links are missed because the information in the selected blocks was missing or incorrectly recorded.\r\n\r\n\r\nThe more blocking passes used, the more links are likely to be identified, but there will generally be diminishing returns on subsequent passes. \r\nDevising a blocking strategy\r\nAlthough all the fields that are common to both datasets could potentially be used to compare the records, some are more appropriate than others, as discussed in Table 1. \r\nSelecting which fields will be used for blocking and linking should be established before the process starts. It is good practice to plan and document the blocking strategy used for the project. \r\nBlocking often requires some trial and error to determine the best outcome. References at the end of this sheet provide more information on blocking. \r\nTable 1: Considerations when choosing which fields to use for linking and blocking\r\n\r\nSurnames \r\nStandardising makes this field more useful for linking and blocking. Sometimes parts of the surname and first name (e.g., first two letters of each) may be used as a blocking variable. Note that name changes can occur as a result of marriage and divorce and sometimes surnames and first names are swapped around. Spelling variations can result from errors during recording or transcription. \r\n\r\nFirst names \r\nInconsistencies can result when both nicknames and formal names are used interchangeably, which can cause discrepancies between data sources. \r\n\r\nGender \r\nGender is not overly useful for blocking as it only separates the datasets into two large blocks. Gender is often good for linking as it is generally well reported and unlikely to change during a person\u2019s lifetime. \r\n\r\nBirth date \r\nBirth month and birth day are usually reliable because they do not change over a person\u2019s lifetime and are usually well reported. If age is collected, it can be checked against birth year for consistency. There may be different date formats (e.g., MM/DD/YYYY or DD/MM/YYYY) which can be addressed by standardisation. Transcription errors may occur when digits are accidentally transposed. Blocking often uses month and year aggregated, rather than the date of birth. \r\n\r\nAge \r\nAge may be checked against birth year, if available. Age groups may be used as blocks. It is not recommended that age be used in the same blocking pass as birth date because there is a direct relationship between the two fields. \r\n\r\nAddress \r\nAs with birth dates, there can be formatting differences in address records, so these generally require standardising. People may change address and sometimes use postal address and street address interchangeably, which affects its usefulness. However, address can still be useful for confirming matches. When address is used in combination with other non-geographical blocks, there is still a chance of identifying links even if people have moved address. For blocking, it is often useful to use an aggregated form of address, such as the suburb or postcode. \r\n3. Linking\r\nLinking involves a number of steps including assigning field probabilities and using these to calculate field and composite weights. The weights reflect the similarities of each pair of records and provide a way to decide whether they are links, or not. \r\nCalculating probabilities\r\nEach linking field (e.g., name, address, date of birth) on a record has two probabilities associated with it. They are called the \u2018m\u2019 and \u2018u\u2019 probabilities. \r\nThe m probability is the likelihood of the field values agreeing on a pair of records, given the records refer to the same entity (e.g., person, organisation). \r\nIt can be thought of as follows: if two different datasets contain records that refer to the same person, what would prevent the information in those records from agreeing? The answer is usually errors in spelling or missing information. \r\nTherefore, the m probability reflects the reliability of the field, and is calculated as 1 minus the error rate of the field. For example, most people report their gender consistently over time and on different datasets, so the m probability is close to 1 (0.95 in the example on the next page). Address, however,may only have an m probability of 0.7 because different datasets can have different addresses for the same person because they may have moved house. \r\nThe probabilistic linking software is used to produce estimates for the m probability. These estimates may be based on prior knowledge of the datasets or similar linking projects, through the identification of a large number of linked and non-linked records that \u2018train\u2019 the software, or by using the EM (Expectation-Maximisation) algorithm (see Samuels, 2012 for more information). \r\nThe u probability is the likelihood that the field values on two records will agree, given the two records refer to different entities. \r\nIt is essentially a measure of how likely two fields on different records will agree by chance. Another way to think of this is: given two records belong to two different people, what is the probability that they will agree anyway? \r\nThe u probability is often estimated by 1/n (where n is the number of possible values). For gender, there are two possible values (male or female) so the u probability for gender is \u00BD (0.5). For month of birth, the u probability can be estimated as 1/12 (0.08). \r\nCalculating the field weights\r\nUsing the m and u probabilities, the probabilistic linking software generates an estimate of how closely the relevant fields agree on each record pair being compared. This is called a field weight. \r\nIn practice, field weights may be modified to allow for partial agreement, such as a minor difference in spelling (e.g., Block vs Black in the example in Box 1). \r\nThis is achieved using a \u2018string comparator\u2019 to generate a lower, but still positive agreement field weight depending on the specified degree of similarity. Some string comparator options include: \r\nExact match where the fields either agree or they do not \u2212 no adjustment is made to the field weight (e.g., gender).\r\nExact match but the weight is modified so that rarer values are given higher weights than more common values when they agree (e.g., country of birth).\r\nApproximate string comparison (e.g., name) where the weight depends on the number of characters that differ, allowing for misspellings and poor handwriting (see Winkler, 1990). \r\nFor more information about m and u probabilities and field weights, refer to Fellegi and Sunter (1969). \r\nFor each possible record pair, the field weights are summed to produce an overall weight \u2212 the composite weight. The higher the composite weight, the more likely that both records refer to the same entity. Box 1 provides a highly simplified example of this process. \r\nDetermining links based on threshold cut-offs\r\nThe composite weight for each record pair is compared to the cut-off threshold. If the composite weight is above the cut-off, the record pair is deemed to be a link. If the composite weight is below the cut-off, the record pair is deemed not to be a link. Sometimes two cut-off thresholds (upper and lower) are used. \r\nA key feature of this methodology is the ability to rank all of the possible links and then, using an \u2018optimal threshold\u2019 algorithm (see Christen, 2012), assign the link to the most optimal record pair based on how well the records match. \r\nVarious manual and automated methods are available to determine thresholds based on the distribution of the composite weights for the linked records. \r\n4. Clerical Review\r\nClerical review is a useful tool to manually assess those records without a designated link/non-link status and to examine records close to the thresholds to check if they are links. \r\nHowever, clerical review is time-consuming and resource-intensive. To minimise the number of records that need to be reviewed, it is necessary to ensure that threshold values are appropriate and the linking software is operating as efficiently as possible. For more information on clerical review see Guiver (2011). \r\n5. Evaluating data quality\r\nThis is covered in Preparing for Linking and Linked Data Quality\r\nBox 1: A simplified example of probabilistic linking\r\nThe following example is taken from the Statistics New Zealand Data Integration Manual. \r\nIt looks at two records on two different datasets to see whether they are a match and, therefore, should be linked. \r\n\r\nField\r\n\r\nRecord A\r\n\r\nRecord B \r\n\r\n\r\nName \r\nJon Block John Black \r\n\r\nDate of birth \r\n23-11-65 23-11-63 \r\n\r\nSex \r\nM M \r\n\r\nAddress \r\n89 Molesworth Street 112 Hiropi Street \r\nThe linking software assigns m and u probabilities for each field (shown below) which range between 0 and 1. \r\n(The calculation of the agreement field weight is log2[m/u]. The disagreement field weight is log2([1 \u2212 m]/[1 \u2212u]).) \r\n\r\nField\r\n\r\nm probability\r\n\r\nu probability\r\n\r\nAgreement field weight\r\n\r\nDisagreement field weight \r\n\r\n\r\nName \r\n0.950.016.57\u22124.31 \r\n\r\nDate of birth \r\n0.90.016.49\u22123.31 \r\n\r\nSex \r\n0.950.50.93\u22123.32 \r\n\r\nAddress \r\n0.70.016.13\u22121.72 \r\nThe fields on the two records are compared (see table below). Field weights with positive values indicate that fields agree, while negative values indicate disagreement. In this example, the field weight of \u22121.72 indicates that the records do not agree on address. \r\nFor simplicity, this example assumes no partial field agreement, although in practice, \u2018Jon\u2019 and \u2018John\u2019 are sufficiently similar that there would probably be some sort of adjustment to the field weights to take account of this, resulting in a lower, but still positive, agreement weight. \r\n\r\nField\r\n\r\nFile A\r\n\r\nFile B\r\n\r\nAgreement?\r\n\r\nField weight \r\n\r\n\r\nName \r\nJon BlockJohn BlackNo\u22124.31 \r\n\r\nDate of birth \r\n23-11-6523-11-63No\u22123.31 \r\n\r\nSex \r\nMMYes0.93 \r\n\r\nAddress \r\n89 Molesworth Street112 Hiropi StreetNo\u22121.72 \r\nComposite weight (sum of field weights)\u22128.41 \r\nThe field weights are summed: (\u22124.31) + (\u22123.31) + (0.93) + (\u22121.72) = \u22128.41 (= composite weight). As the composite weight in this example is negative (\u22128.41), the linking process would determine that these records are a non-link. \r\nFor more information, see Statistics New Zealand, Data Integration Manual, 2006, pp.36-44. \r\nAdditional Information \r\n\r\nProbabilistic linking theory\r\nFellegi, I. and Sunter, A. 1969, \u2018A Theory for Record Linkage\u2019, Journal of the American Statistical Association, Vol.64, no.328, pp. 1183-1210.\r\n\r\nLinking (including m and u probabilities)\r\nChristen, P. 2012, Data Matching: Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection, Springer, Canberra.\r\nHerzog, T.N., Scheuren, F.J. and Winkler, W.E. 2007, Data quality and record linkage techniques, Springer, New York.\r\nJaro, M. 1995, \u2018Probabilistic Linkage of Large Public Health Data Files\u2019, Statistics in Medicine, Vol. 14, pp. 491-498.\r\nSamuels, C. 2012, \u2018Using the EM Algorithm to Estimate the Parameters of the Fellegi-Sunter Model for Data Linking research paper\u2019, Methodology Advisory Committee Paper, Cat. no. 1352.0.55.120, Australian Bureau of Statistics, Canberra.\r\nStatistics New Zealand 2006, Data Integration Manual, Statistics New Zealand, Wellington.\r\nWinkler, W.E. 1990, \u2018String Comparator Metrics and Enhanced Decision Rules in the Fellegi-Sunter Model of Record Linkage\u2019, Proceedings of the Section on Survey Research Methods, American Statistical Association, pp. 354-359.\r\n\r\nClerical review\r\nGuiver, T. 2011, \u2018Sampling-Based Clerical Review Methods in Probabilistic Linking\u2019, Methodology Research Papers, Cat. no. 1351.0.55.034, Australian Bureau of Statistics, Canberra.\r\nBishop, G. and Khoo, J. 2007, \u2018Methodology of Evaluating the Quality of Probabilistic Linking\u2019, Methodology Research Papers, Cat. no. 1351.0.55.018, Australian Bureau of Statistics, Canberra."},{"id":103,"title":"Sheet 1","heading":"What is data integration for statistical and research purposes?","path":"./data-integration/data-integration-projects/sheet-1.html#what-is-data-integration-for-statistical-and-research-purposes?","content":"\r\nData integration involves combining data about an individual person, household, family or business from different administrative and/or survey sources to produce new datasets for statistical and research purposes. This approach leverages more information from the combination of datasets than is available from the individual datasets separately. Data integration for statistical purposes means that the information is not used to identify an individual person, household, family or business for regulatory purposes, compliance monitoring or service delivery. \r\nWhy conduct data integration using Commonwealth data for statistical and research purposes?"},{"id":104,"title":"Sheet 1","heading":"Why conduct data integration using Commonwealth data for statistical and research purposes?","path":"./data-integration/data-integration-projects/sheet-1.html#why-conduct-data-integration-using-commonwealth-data-for-statistical-and-research-purposes?","content":"\r\nThere is an increasing demand for integration of datasets at a unit record level in Australia. This demand is being driven by the potential data integration has to produce rich and dynamic datasets. Integrated datasets can assist research into complex problems that have multiple contributing and confounding causes, such as climate change, unemployment, homelessness and obesity. Data integration allows better use of data that is already available, it can be a cost effective and timely way of gathering more information for statistical and research purposes. \r\nWhile there are clear benefits to data integration, there is also a responsibility for stakeholders of data integration projects to preserve privacy and confidentiality through policies and procedures. \r\nPreservation of privacy and confidentiality is needed to prevent harm to data providers (including individuals, families, households or organisations who have contributed data) or a loss of public trust in the Australian Government or its institutions. \r\nArrangements for the integration of Commonwealth data for statistical and research purposes"},{"id":105,"title":"Sheet 1","heading":"Arrangements for the integration of Commonwealth data for statistical and research purposes","path":"./data-integration/data-integration-projects/sheet-1.html#arrangements-for-the-integration-of-commonwealth-data-for-statistical-and-research-purposes","content":"\r\nThe demand for data integration, coupled with the responsibility to maintain the privacy and confidentiality of those providing the data, have led to the development of the arrangements for data integration involving Commonwealth data for statistical and research purposes (the Commonwealth arrangements). To establish the Commonwealth arrangements seven high level principles were developed. These principles outline when data integration should occur, who is responsible for the data and the data integration process, how the data should be treated and why transparency is important in the process of data integration, see below for a description of each principle. \r\nThe High Level Principles are supported by a set of Governance and Institutional Arrangements for the integration of Commonwealth data. These arrangements provide a framework for how data integration projects using Commonwealth data will be managed and governed, providing a foundation for the increased use of Commonwealth data as a strategic resource.\r\nThe main components of the Governance and Institutional Arrangements are:\r\na Cross Portfolio Data Integration Oversight Board (the Board) to oversee the development and ongoing administration of the Commonwealth arrangements for data integration. There is also a small Secretariat, to provide support to the Board and its ongoing activities.\r\nnomination of an integrating authority for each project involving Commonwealth data. The integrating authority is responsible for the end to end management of the project and the ongoing management of the integrated dataset throughout its lifecycle.\r\nan accreditation process to enable the Board to endorse integrating authorities with the demonstrated capacity to deal with projects that present a high risk.\r\na guide for stakeholders of data integration projects involving Commonwealth data. The guide contains information describing practices and procedures that can be used to ensure compliance with the Commonwealth arrangements.\r\na public register of data integration projects and a public feedback mechanism. The public register builds public trust through transparency and ensures that data integration involving Commonwealth data is conducted in an open and accountable way.\r\nan Engagement and Education strategy to support the Commonwealth arrangements.\r\nHigh Level Principles for Data Integration"},{"id":106,"title":"Sheet 1","heading":"High Level Principles for Data Integration","path":"./data-integration/data-integration-projects/sheet-1.html#high-level-principles-for-data-integration","content":"\r\nPrinciple 1 - Strategic Resource\r\nAgencies should treat data as as strategic resource and design and manage administrative data to support their wider statistical and research use \r\nPrinciple 2 - Custodian\u2019s Accountability\r\nAgencies responsible for source data used in statistical data integration remain individually accountable for their security and confidentiality. \r\nPrinciple 3 - Integrator\u2019s Accountability\r\nA responsible \u2018integrating authority\u2019 will be nominated for each statistical data integration proposal \r\nPrinciple 4 - Public Benefit\r\nStatistical integration should only occur where it provides significant overall benefit to the public\r\nPrinciple 5 - Statistical and Research Purposes\r\nStatistical data integration must be used for statistical and research purposes only.\r\nPrinciple 6 - Preserving Privacy and Confidentiality\r\nPolicies and procedures used in data integration must minimise any potential impact on privacy and confidentiality. \r\nPrinciple 7 - Transparency\r\nStatistical data integration will be conducted in an open and accountable way.\r\n\r\n"},{"id":107,"title":"Sheet 2","heading":"Implementation of the Commonwealth Arrangements","path":"./data-integration/data-integration-projects/sheet-2.html#implementation-of-the-commonwealth-arrangements","content":"\r\nInitial implementation of the Commonwealth arrangements commenced on 1 July 2014. The implementation priority in the first six months of operation is to establish the arrangements for external statistical and research projects involving Commonwealth data. External projects are defined as those projects where the data user (researcher) is external to the the Commonwealth (e.g. from a State/Territory government agency or an academic research organisation).\r\nProjects are in scope of the Commonwealth arrangements for data integration if they: \r\nare approved and undertaken for statistical and research purposes only. Integration for non-statistical purposes, such as delivery of services to particular individuals, compliance monitoring, incident investigation or regulatory purposes, are out of scope, as these activities have different processes and legislative requirements governing them; and\r\ninvolve integration at the unit record level (records for a person or business), or at the micro level (e.g. information on small geographic areas); and\r\nthe data custodian for at least one dataset is a Commonwealth agency; and\r\nthe data user is external to the Commonwealth (e.g. for State/Territory government or academic research), as mentioned above.\r\nThe initial implementation of the Commonwealth arrangements will be for selected external projects. Once approved, details of the selected projects will be available on the public register of data integration projects. During the initial implementation, the integrating authority for the selected projects are to be Commonwealth agencies. If the project is assessed as a high risk after using the Risk Framework the integrating authority must be accredited. \r\nAgencies are encouraged to use the Commonwealth arrangements for all external projects during this initial implementation period. This will help in minimising the general risk presented during the execution of a data integration project. Other data integration projects that satisfy the first three criteria, but are not external projects may also utilise the Commonwealth arrangements for data integration, if this is the preference of data custodians. Data users wishing to apply for access to Commonwealth data for a data integration project should discuss their proposal with the Commonwealth data custodian(s). \r\nPlease be advised that the scope of the Commonwealth arrangements is subject to change at the discretion of the Cross Portfolio Data Integration Oversight Board. \r\nHelp for conducting data integration projects"},{"id":108,"title":"Sheet 2","heading":"Help for conducting data integration projects","path":"./data-integration/data-integration-projects/sheet-2.html#help-for-conducting-data-integration-projects","content":"\r\nAs part of the implementation of the Commonwealth arrangements, a guide has been released to assist stakeholders when conducting statistical data integration projects involving Commonwealth data. The guide provides practical advice on how to comply with the Commonwealth arrangements, including guidance on the planning, management and approval processes for stakeholders of data integration projects. "},{"id":109,"title":"Sheet 3","heading":"Role and responsibilities","path":"./data-integration/data-integration-projects/sheet-3.html#role-and-responsibilities","content":"\r\nThe data user (or researcher) is the person or entity who accesses the integrated dataset (at a unit record level) to conduct research. For example, the data user can be an academic working in a research institution, or an employee in a State/Territory government agency. \r\nThe data custodianis the entity responsible for the source data and any activities relating to it, such as its collection, management, protection and access approval. Often their responsibilities are set out in relevant legislation. \r\nThe integrating authority is the single organisation ultimately responsible for the sound conduct of the statistical data integration project. It is responsible for the implementation of the data integration project and the management of the integrated dataset throughout its entire life cycle, ensuring full compliance with commitments made to data custodians, and in line with the Commonwealth arrangements. The integrating authority is also responsible for providing data users with safe and secure access to the integrated data in line with the requirements of data custodians. \r\nThe process for conducting a project"},{"id":110,"title":"Sheet 3","heading":"The process for conducting a project","path":"./data-integration/data-integration-projects/sheet-3.html#the-process-for-conducting-a-project","content":"\r\nThere are many ways a data integration project can be conducted. On the reverse side of this information sheet a process map outlines the stages a project will generally go through to align with the Commonwealth arrangements, although there may be variations depending on specific project requirements. Most of the stages should already align with existing project approval procedures, with only some additional steps incorporated to reflect the requirements of the Commonwealth arrangements.\r\nA Process Map for Data Integration Projects"},{"id":111,"title":"Sheet 3","heading":"A Process Map for Data Integration Projects","path":"./data-integration/data-integration-projects/sheet-3.html#a-process-map-for-data-integration-projects","content":"\r\n\r\n\r\n"},{"id":112,"title":"Sheet 4","heading":"Deciding if data can be released","path":"./data-integration/data-integration-projects/sheet-4.html#deciding-if-data-can-be-released","content":"\r\nEach data custodian is responsible for deciding whether to approve the release of their data for a data integration project (a project). When a project is first proposed and access to data is requested, each data custodian must consider if they are authorised to provide the data under governing legislation or with data provider\u2019s consent.\r\nIf there is authorisation to release the data, the data custodian may then also consider if the release of their data for the project will provide a public benefit that outweighs the privacy imposition and risks to confidentiality involved.\r\nData custodian roles within the Commonwealth arrangements"},{"id":113,"title":"Sheet 4","heading":"Data custodian roles within the Commonwealth arrangements","path":"./data-integration/data-integration-projects/sheet-4.html#data-custodian-roles-within-the-commonwealth-arrangements","content":"\r\n\r\nRole 1 - Maximise the value of data holdings\r\n\r\n\r\nRole 2 - Assess project risk\r\n\r\n\r\nRole 3 - Comply with policy and legislation\r\n\r\n\r\nRole 4 - Ensure safe storage of unit record data\r\n\r\n\r\nRole 5 - Safely transmit unit record data\r\n\r\n\r\nRole 6 - Enter project agreements\r\nAssessing the risk of the project"},{"id":114,"title":"Sheet 4","heading":"Assessing the risk of the project","path":"./data-integration/data-integration-projects/sheet-4.html#assessing-the-risk-of-the-project","content":"\r\nIt is the responsibility of data custodian(s) to assess the risk of a project. The risks to be considered are: \r\n\r\na breach resulting in an unauthorised disclosure of personal or business information; and\r\n\r\n\r\na reduction in public trust of the Australian government and its institutions.\r\nWhile the final decision and agreement on the risk rating (high, medium or low) of the project remain with the data custodian(s), input may be sought from integrating authorities (the agency that manages, and is ultimately accountable for, the sound conduct of the project, (see Information Sheet 5).\r\nAppointing an integrating authority"},{"id":115,"title":"Sheet 4","heading":"Appointing an integrating authority","path":"./data-integration/data-integration-projects/sheet-4.html#appointing-an-integrating-authority","content":"\r\nFollowing the completion of the risk assessment, the data custodian(s) is then responsible for appointing an integrating authority. If the project risk is rated high, then the project must be managed by an accredited Integrating Authority (refer to Information Sheets 5 and 6).\r\nThe data custodian(s) should also ensure the integrating authority nominated to manage the project is authorised to receive the data, either through legislation or data providers\u2019 consent.\r\nFinalising project agreements"},{"id":116,"title":"Sheet 4","heading":"Finalising project agreements","path":"./data-integration/data-integration-projects/sheet-4.html#finalising-project-agreements","content":"\r\nOnce the details of the project have been decided, project agreements are signed between the data custodian(s) and the integrating authority. These agreements provide a mechanism for the data custodian(s) to exercise their accountability for the security and confidentiality of their data once it is provided to the integrating authority for the project.\r\nAgreements should detail any conditions specified by the data custodian(s) relating to data security obligations, privacy and confidentiality requirements, data access provisions and potential sanctions which may apply to misuse of the data.\r\nExtracting and providing data"},{"id":117,"title":"Sheet 4","heading":"Extracting and providing data","path":"./data-integration/data-integration-projects/sheet-4.html#extracting-and-providing-data","content":"\r\nData custodian(s) are responsible for ensuring the safe extraction and transmission of their data (as specified in the project agreements) to the integrating authority. This transmission of data should be consistent with Australian Privacy Principles (APPs) and the Australian Government Protective Security Policy Framework.\r\nA checklist for data custodians"},{"id":118,"title":"Sheet 4","heading":"A checklist for data custodians","path":"./data-integration/data-integration-projects/sheet-4.html#a-checklist-for-data-custodians","content":"\r\nThis is a list of considerations for data custodians who have been approached for their data to be included in a data integration project for statistical or research purposes.\r\nIn Principle approval\r\n\u2714 Is your project in scope of the Commonwealth arrangements?\r\n\u2714 Does the public benefit outweigh the privacy imposition of the project?\r\n\u2714 Do you have authorisation to release the data for the purpose of the project?\r\n\u2714Is the purpose consistent with departmental policies and purposes?\r\n\u2714 Have you completed the risk assessment in conjunction with other data custodians?\r\n\u2714 Are you satisfied that this project does not present an unacceptably high risk to public trust in the Australian Government and its institutions?\r\n\u2714 Do you require an accredited Integrating Authority to manage the project?\r\n\u2714 Do you require any further assessments to be undertaken prior to signing project agreements (e.g. ethics committee approval or privacy impact assessment)?\r\n\u2714 Have you specified any special conditions to be met as part of your project approval?\r\n\u2714 Do you give in principle approval for this project to proceed to the next stage?\r\nFinal approval\r\n\u2714 Are you satisfied with the arrangements provided by the integrating authority for security of the data (e.g. data transfer, access, use, storage and destruction or retention)?\r\n\u2714 Have you considered how confidentiality and privacy will be protected?\r\n\r\nHow will the separation principle be applied (if applicable)?\r\n\r\n\r\nHow will data be de-identified and/or confidentialised?\r\n\r\n\r\nWhat conditions will data users be expected to comply with (e.g. signing confidentiality undertakings, review of research results before publication)?\r\n\r\n\r\nWhat are the consequences if there is a misuse of data or breach of privacy?\r\n\u2714 Have all necessary authorisations been received (e.g. Ethics committee approval, privacy impact assessment, departmental authorisation, consent of the data provider, Public Interest Determination)?\r\n\u2714 Have you entered into a project agreement with the integrating authority (and all other data custodians)?\r\nProject delivery\r\n\u2714 Has data been extracted and delivered to the integrating authority according to project agreements?\r\n\u2714 Have you provided metadata and information about the quality of the data to assist the integrating authority and data users understand the source data?"},{"id":119,"title":"Sheet 5","heading":"Nominating an integrating authority","path":"./data-integration/data-integration-projects/sheet-5.html#nominating-an-integrating-authority","content":"\r\nWhen a data integration project involving Commonwealth data for statistical and research purposes (a project) is proposed, it is considered by the data custodians and a risk assessment is conducted (see Information Sheet 4). Once this is complete, the data custodians appoint an integrating authority to manage and conduct the project from start to finish.\r\nThe integrating authority must be a secure and trusted institution (an individual cannot be an integrating authority) and in a position to comply with the requirements of the Privacy Act 1988 or the equivalent State/Territory legislation (in regards to information about individuals) and secrecy provisions generally (in regards to information with respect to the affairs of any third party, corporate or individual). In addition, if the project is rated as high risk, the integrating authority appointed must be accredited (see Information Sheet 6).\r\nWhen nominating an integrating authority, the data custodians should also ensure they are authorised to release the identifiable data, either by legislation or consent, to the integrating authority appointed (see Information Sheet 4)\r\nIntegrating authority roles within the Commonwealth arrangements"},{"id":120,"title":"Sheet 5","heading":"Integrating authority roles within the Commonwealth arrangements","path":"./data-integration/data-integration-projects/sheet-5.html#integrating-authority-roles-within-the-commonwealth-arrangements","content":"\r\n\r\nRole 1 - Enter into project and data access agreements\r\n\r\n\r\nRole 2 - Implement safe and effective arrangements for data integration projects\r\n\r\n\r\nRole 3 - Manage datasets for the duration of data integration projects\r\n\r\n\r\nRole 4 - Provide transparency in operation\r\nFinalising agreements"},{"id":121,"title":"Sheet 5","heading":"Finalising agreements","path":"./data-integration/data-integration-projects/sheet-5.html#finalising-agreements","content":"\r\nOnce appointed, the integrating authority is responsible for reviewing and finalising the arrangements for the project and preparing project agreements with data custodians and data access agreements with data users.\r\nThe purpose of project agreements is to help ensure that integrated datasets are managed and used in accordance with data custodian requirements, protecting privacy and ensuring that data is not likely to enable the identification (or re-identification) of individuals and businesses. Project agreements set out the terms and conditions that accompany the final project approval.\r\nOnce the project is approved the integrating authority is responsible for registering the project on the public register of data integration projects.\r\nDelivering a project"},{"id":122,"title":"Sheet 5","heading":"Delivering a project","path":"./data-integration/data-integration-projects/sheet-5.html#delivering-a-project","content":"\r\nThe integrating authority has an important role in managing the increased risk of identification that exists when two or more datasets are integrated. Generally an integrating authority will be chosen because they have the skills and expertise to conduct a data integration project safely and securely.\r\nHowever, it is possible for an integrating authority to outsource or involve consortium/partnership arrangements to complete a project. For example, it might use another agency to create linkage keys, or it may use infrastructure provided by another agency to support dissemination or access to the integrated dataset by data users.\r\nProviding access to integrated data"},{"id":123,"title":"Sheet 5","heading":"Providing access to integrated data","path":"./data-integration/data-integration-projects/sheet-5.html#providing-access-to-integrated-data","content":"\r\nPart of the integrating authority's role in managing integrated datasets is to provide data users with secure access to the integrated data.\r\nData access agreements between the integrating authority and data users should set out the conditions and arrangements for accessing and producing output from the integrated data.\r\nThe conditions and nature of access may vary from project to project, according to the requirements of data custodians.\r\nA checklist for integrating authorities"},{"id":124,"title":"Sheet 5","heading":"A checklist for integrating authorities","path":"./data-integration/data-integration-projects/sheet-5.html#a-checklist-for-integrating-authorities","content":"\r\nThis is a list of considerations for integrating authorities who have been approached to undertake the end to end management of a data integration project for statistical or research purposes.\r\nIf the project is assessed as high risk, the integrating authority must be accredited.\r\nIn Principle approval\r\n\u2714 Have you assessed the technical feasibility of the project and ensured that you can deliver on all aspects of the project? (e.g. linking methods, data security and provision of secure access to the integrated data, timeframes, data quality, risk management, etc.)\r\nFinal Project Details\r\n\u2714 Have you discussed and agreed the arrangements for security of the data (e.g. data transfer, access, use, storage and destruction or retention) with all data custodians?\r\n\u2714 Have you discussed and agreed with data custodians how confidentiality and privacy will be protected?\r\n\r\nHow will the separation principle be applied (if applicable)?\r\n\r\n\r\nHow will the data be de-identified and/or confidentialised?\r\n\r\n\r\nDo the data custodians have any special conditions to be met for users of the data (e.g. signing confidentiality undertakings, review of research results before publication)?\r\n\r\n\r\nAre the consequences, if there is a misuse of data or breach of privacy, understood for both the integrating authority and the data user?\r\n\u2714 Will there be a fee for service or cost recovery charge to the data user and has a quote been prepared and accepted?\r\n\u2714 Do you need to assist the data users to seek Ethics Committee approval for the project?\r\n\u2714 Is a privacy impact assessment required?\r\n\u2714 Do you intend to outsource or work in partnership with other organisations to complete components of the project (such as creation of linkage keys) and have the data custodians been advised?\r\n\u2714 Have you entered into a project agreement with all of the data custodians to formalise the arrangements for the project?\r\n\u2714 Have you entered into a data access agreement with the data user to set out the conditions and arrangements for accessing the integrated data for research and analysis?\r\n\u2714 Have you registered the project on the public register of data integration projects and submitted the risk assessment to the Oversight Board?\r\nProject delivery\r\n\u2714 Have you conducted the following steps in accordance with the project agreements?\r\n\r\nData prepared, linked, merged and quality checked using agreed protocols (e.g. application of the separation principle);\r\n\r\n\r\nIntegrated data de-identified and confidentialised;\r\n\r\n\r\nSecure access to the integrated data provided to data users;\r\n\r\n\r\nEnsure that the integrated data is stored securely if it is to be retained and a review process is in place or that it is destroyed at project completion; and"},{"id":125,"title":"Sheet 6","heading":"Accreditation","path":"./data-integration/data-integration-projects/sheet-6.html#accreditation","content":"\r\nAccreditation of an integrating authority is the recognition by the Cross Portfolio Data Integration Oversight Board (the Oversight Board) that the organisation has the requisite expertise, skills and knowledge, infrastructure and secure environment to undertake data integration projects, particularly those considered to be a high risk rating.\r\nIt is important to note, the accreditation scheme is an administrative arrangement which does not override legislation. All legal obligations (e.g. with regard to the Privacy Act 1988 or privacy and secrecy provisions in agency-specific legislation) must be met.\r\nAccreditation criteria"},{"id":126,"title":"Sheet 6","heading":"Accreditation criteria","path":"./data-integration/data-integration-projects/sheet-6.html#accreditation-criteria","content":"\r\nThe eight criteria integrating authorities must meet to gain accreditation are:\r\nability to ensure secure data management;\r\ndemonstrated ability to ensure that information that is likely to enable identification of individuals or organisations is not disclosed to external users;\r\navailability of appropriate skills;\r\nappropriate technical capability;\r\nlack of conflict of interest;\r\nculture and values that ensure protection of confidential information and support the use of data as a strategic resource;\r\ntransparency of operation; and\r\nappropriate governance and administrative framework.\r\nThe steps involved in gaining accreditation"},{"id":127,"title":"Sheet 6","heading":"The steps involved in gaining accreditation","path":"./data-integration/data-integration-projects/sheet-6.html#the-steps-involved-in-gaining-accreditation","content":"\r\nThe process for accreditation of integrating authorities involves:\r\nSelf-assessment. Integrating authorities apply for accreditation by preparing a self-assessment report explaining how they meet the criteria for accreditation and evidenced by supporting documentation. The self-assessment should be succinct and avoid qualitative statements that cannot be directly verified in the supporting documentation provided. The assessment should be signed off by the head of the agency.\r\nAudit. An independent third party audits the integrating authority\u2019s self-assessment to verify the statements of the claims made in the self-assessment. This verification is made on the basis of the documentary evidence. This audit is paid for by the integrating authority applying to become accredited.\r\nDecision. The Oversight Board will make the final decision on interim accreditation, based on the self-assessment and results of the audit.\r\nPublication of list of accredited agencies. The Secretariat publishes a list of accredited integrating authorities, together with a summarised version of the integrating authority\u2019s application and a summary of the audit report\r\nWho can apply for accreditation?"},{"id":128,"title":"Sheet 6","heading":"Who can apply for accreditation?","path":"./data-integration/data-integration-projects/sheet-6.html#who-can-apply-for-accreditation?","content":"\r\nThe interim accreditation arrangements will be tested on Commonwealth government agencies first. While this does not preclude State/Territory government agencies applying for accreditation against the interim arrangements (provided that they meet all the requirements), it will not be possible for any State/Territory government agencies to be accredited in the short term, as this would not allow time for sufficient testing and evaluation of the arrangements with Commonwealth agencies.\r\nThe system is not yet mature enough to ensure that adequate safeguards apply to private firms. State/Territory government agencies and private firms can continue to apply for access to Commonwealth data under existing arrangements. The Oversight Board will only consider applications for accreditation, against the interim accreditation arrangements, for those agencies covered by privacy legislation (either the Privacy Act 1988 or State/Territory equivalent).\r\nWill the accreditation process be reviewed?"},{"id":129,"title":"Sheet 6","heading":"Will the accreditation process be reviewed?","path":"./data-integration/data-integration-projects/sheet-6.html#will-the-accreditation-process-be-reviewed?","content":"\r\nThe accreditation process is currently interim. Once a sufficient number of organisations have successfully gone through the interim accreditation process, a review will be conducted, and any necessary changes will be made to the process. The accreditation process will then become final.\r\nENDNOTES\r\n\r\nSystemic risk in this context is the ability of a project, by its very nature or where a breach occurs, to either harm data providers and/or create a loss of public trust in the Australian Government or its institutions."},{"id":130,"title":"Sheet 7","heading":"Initiating a data integration project","path":"./data-integration/data-integration-projects/sheet-7.html#initiating-a-data-integration-project","content":"\r\nTo initiate a data integration project involving Commonwealth data for statistical or research purposes (a project), data users should prepare a project proposal for consideration by the data custodian(s) (see Information Sheet 4). The project proposal can be developed in consultation with the data custodian(s) and/or, where appropriate, an integrating authority (the agency that manages, and is ultimately accountable for, the sound conduct of the project, (see Information Sheet 5).\r\nWhen proposing a project, it is important to take into account the public benefit (e.g. social, economic and/or environmental benefit) that can be derived. A project should only occur where the public good outweighs the privacy imposition and risks to confidentiality. Under the Commonwealth arrangements, data users may work with the nominated integrating authority and the data custodian(s) to finalise the details of the project.\r\nData user roles within the Commonwealth arrangements"},{"id":131,"title":"Sheet 7","heading":"Data user roles within the Commonwealth arrangements","path":"./data-integration/data-integration-projects/sheet-7.html#data-user-roles-within-the-commonwealth-arrangements","content":"\r\nRole 1 - Develop research proposals that produce significant overall public benefit\r\nRole 2 - Collaborate with the integrating authority and data custodian(s) to get projects approved\r\nRole 3 - Enter into agreements with integrating authorities to ensure the safe management and use of datasets\r\nRole 4 - Access integrated datasets through secure arrangements in order to conduct analysis for statistical and research purposes\r\nRole 5 - Liaise with data custodians on the valid uses of integrated datasets\r\nAccess to integrated data - preserving privacy and confidentiality"},{"id":132,"title":"Sheet 7","heading":"Access to integrated data - preserving privacy and confidentiality","path":"./data-integration/data-integration-projects/sheet-7.html#access-to-integrated-data---preserving-privacy-and-confidentiality","content":"\r\nTo ensure the risks of potential disclosure of identifiable information are minimised, the integrating authority has responsibility to provide data users with secure access to the integrated dataset, for example, via an on-site or remote access data laboratory. \r\nTo access the integrated dataset, the data user will enter into an agreement with the integrating authority. This agreement will set out the requirements for accessing the integrated dataset and producing outputs. The conditions and nature of access may vary from project to project, according to the requirements of data custodians.\r\nGenerally, the integrating authority will provide the data user with access to integrated data once it has been de-identified and/or confidentialised, in line with the requirements of data custodians.\r\nIt is recommended that data users only be given access to identified or potentially identifiable data where: legislation allows; it is necessary to achieve the approved purpose of the projects; and the data custodians agree.\r\nA checklist for data users"},{"id":133,"title":"Sheet 7","heading":"A checklist for data users","path":"./data-integration/data-integration-projects/sheet-7.html#a-checklist-for-data-users","content":"\r\nThis is a list of considerations for data users who are planning to undertake a data integration project involving Commonwealth data for statistical or research purposes.\r\nProject proposal\r\n\u2714 Is your project in scope of the Commonwealth arrangements for data integration and does it offer public benefit that will outweigh the imposition to privacy?\r\n\u2714 Have you consulted with data custodians to clarify details for the project (particularly in relation to the data items required for the project)?\r\n\u2714 Do you have sufficient funding to meet any fee for service or cost recovery charges?\r\n\u2714 Have you prepared and submitted a project proposal for in principle approval by data custodians, including all relevant details (e.g. listing of responsible officers and researchers, summary project description and objectives, expected outputs, data access arrangements, the required datasets and data items and possible time frames)?\r\nFinal approval\r\n\u2714 Do you understand your obligations regarding the protection of confidentiality and privacy and the consequences if there is a misuse of data or a breach of privacy?\r\n\u2714 Have you entered into a data access agreement with the integrating authority to set out the conditions and arrangements for accessing the integrated data for research and analysis, including any special conditions required by the data custodian for this project?\r\n\u2714 Have all researchers who will access the data signed confidentiality undertakings required by the integrating authority or the data custodian?\r\n\u2714 Have you obtained Ethics Committee approval for the project (if required)?\r\nProject delivery\r\n\u2714 Have all researchers completed any required training?\r\n\u2714 Has the integrated data been received from the integrating authority and verified for completeness?\r\n\u2714 Have you given the data custodians the opportunity to review the research results prior to publication (if required)?\r\n\u2714 Have you destroyed or returned the integrated data to the integrating authority following publication of the project findings, in accordance with the agreement?\r\n\u2714 Do you have any documented feedback to provide to the integrating authority (e.g. procedural or data quality issues)?"},{"id":134,"title":"What is data linking?","heading":"What is Data Linking?","path":"./data-integration/data-integration-projects/what-is-data-linking.html#what-is-data-linking?","content":"\r\nData linking is used to bring together information from different sources in order to create a new, richer dataset. \r\nThis involves identifying and combining information from corresponding records on each of the different source datasets. The records in the resulting linked dataset contain some data from each of the source datasets. \r\nMost linking techniques combine records from different datasets if they refer to the same entity. (An entity may be a person, organisation, household or even a geographic region.) \r\nHowever, some linking techniques combine records that refer to a similar, but not necessarily the same, person or organisation \u2013 this is called statistical linking. For simplicity, this series does not cover statistical linking, but rather focuses on deterministic and probabilistic linking."},{"id":135,"title":"What is data linking?","heading":"Key Terms","path":"./data-integration/data-integration-projects/what-is-data-linking.html#key-terms","content":"\r\nConfidentiality \u2013 the legal and ethical obligation to maintain and protect the privacy and secrecy of the person, business, or organisation that provided their information.\r\nData linking \u2013 creating links between records from different sources based on common features present in those sources. Also known as \u2018data linkage\u2019 or \u2018data matching\u2019, data are combined at the unit record or micro level.\r\nDeterministic (exact) linking \u2013 using a unique identifier to link records that refer to the same entity.\r\nIdentifier \u2013 for the purpose of data linking, an identifier is information that establishes the identity of an individual or organisation. For example, for individuals it is often name and address. Also see Unique identifier.\r\nSource dataset \u2013 the original dataset as received by the data provider.\r\nUnique identifier \u2013 a number or code that uniquely identifies a person, business or organisation, such as passport number or Australian Business Number (ABN).\r\nUnit record level linking \u2013 linking at the unit record level involves information from one entity (individual or organisation) being linked with a different set of information for the same person (or organisation), or with information on an individual (or organisation) with the same characteristics. Micro level includes spatial area data linking. \r\nWhy is data linking important?"},{"id":136,"title":"What is data linking?","heading":"Why is data linking important?","path":"./data-integration/data-integration-projects/what-is-data-linking.html#why-is-data-linking-important?","content":"\r\nLinked datasets create opportunities for more complex and expanded policy and research. \r\nFor example, data linking helped to identify the role of folate in pregnancy in reducing neural tube defects, such as spina bifida. \r\nOn the business front, in New Zealand, the Linked Employer-Employee Data (LEED) links taxation data with business data to provide information such as the employment outcomes of tertiary education and transitions from work to retirement and from benefit to work. \r\nData linking has the advantage of utilising information that already exists. Making use of data collections in this way avoids the time and expense of collecting a whole new set of data. It also avoids imposing extra questions on people and organisations when this information already exists. \r\nWhat are the main ways to link datasets?"},{"id":137,"title":"What is data linking?","heading":"What are the main ways to link datasets?","path":"./data-integration/data-integration-projects/what-is-data-linking.html#what-are-the-main-ways-to-link-datasets?","content":"\r\nThere are a number of different approaches to data linking. \r\nUsually, the most straightforward way is to use a unique identifier (such as a tax file number) present on both files, in order to identify the links between the records on each dataset. This is sometimes referred to as \u2018deterministic\u2019 or \u2018exact\u2019 linking because the unique identifiers on the records either match or they do not \u2013 there is no uncertainty. \r\nWhere a unique identifier is not available, or is not of sufficient quality or completeness to be relied on alone, an alternative approach is to construct a linkage key, which acts as a proxy for the unique identifier. This key (or code) is created using identifiable information, such as name and address, available on both datasets. \r\nLinkage keys can help to preserve privacy because the key replaces name and address, thereby reducing the chance of identification. \r\nProbabilistic linking is another option for linking where a unique identifier is not available. Probabilistic linking is based on a calculation of the likelihood that a pair of records (one drawn from each dataset) refers to the same person/organisation. Complex methods and sophisticated data linking software are used to achieve high-quality results. \r\nProtecting privacy and confidentiality of a linked dataset"},{"id":138,"title":"What is data linking?","heading":"Protecting privacy and confidentiality of a linked dataset","path":"./data-integration/data-integration-projects/what-is-data-linking.html#protecting-privacy-and-confidentiality-of-a-linked-dataset","content":"\r\nDatasets that contain identifiable information need to be handled with care to protect the identity of a person or organisation. There is an increased risk of identification of an individual/business/organisation when two datasets are linked. \r\nEven if identification is protected (such as by removing name and address) in the original datasets, the result of the linking may provide a combination of characteristics which leads to spontaneous recognition of the identity of a person or organisation (e.g., local area school data showing a cardiac specialist who is the mother of six). \r\nTo minimise this risk, data linking should only be conducted in a safe and effective environment ensuring that the methods used are fit-for-purpose. Confidentiality and statistical disclosure techniques are available to manage the privacy risks that can be associated with data linking\r\nIf a data linking project involves Commonwealth datasets and is for statistical and research purposes the project should comply with the High Level Principles for Data Integration Involving Commonwealth Data for Statistical and Research Purposes and the supporting governance and institutional arrangements. \r\nAdditional Sources of Information\r\nChristen, P. 2012, Data Matching: Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection, Springer, Canberra.\r\nNCSIMG 2004, Statistical Data Linkage in Community Services Data Collection, AIHW, Canberra.\r\nNational Statistical Service 2011, Confidentiality Information Series, National Statistical Service, Canberra, Statistical Data Integration\r\nStatistical Data Integration (including the High Level Principles), see National Statistical Service at Statistical Data Integration"},{"id":139,"title":"Appendix A","heading":"Purpose","path":"./data-integration/risk/appendix-a.html#purpose","content":"\r\nThe purpose of this appendix is to demonstrate through a case study, the process of determining the post mitigation risk rating of data integration projects using the draft risk framework guidelines. A practical example is provided in this document with both pre- and post- mitigation risks."},{"id":140,"title":"Appendix A","heading":"Definitions","path":"./data-integration/risk/appendix-a.html#definitions","content":"\r\nFor the purpose of classifying data integration projects, the following definitions are used:\r\n\r\nProject Types\r\n\r\nDefinition\r\n\r\nSingle agencyThere is only one Commonwealth data custodian involved in the data integration project.\r\nMultiple agenciesThere is more than one Commonwealth data custodian involved in the data integration project.\r\nNon-CommonwealthThere is one or more non-Commonwealth data custodian involved in the data integration project."},{"id":141,"title":"Appendix A","heading":"Risks at different stages of the project","path":"./data-integration/risk/appendix-a.html#risks-at-different-stages-of-the-project","content":"\r\nThere are varying levels of risks associated with the different stages of a data integration project. Broadly, the stages include extraction, file transfer, linkage, analysis, publication, storage and destruction. Not all stages will be applicable to all data integration projects. For example, a data integration project may retain the linked dataset indefinitely. Therefore, the destruction stage may not be applicable.\r\nMitigation strategies can be applied at various stages to reduce the likelihood of a breach occurring. The data integration project can be designed in such a way that even if the consequence of a breach occurring is high, the likelihood is reduced such that the project does not require an accredited Integrating Authority. For example, even if the data required for the integration project are sensitive, using the separation principle may mean that the project does not necessarily require an accredited Integrating Authority."},{"id":142,"title":"Appendix A","heading":"Application of the framework through a selected case study","path":"./data-integration/risk/appendix-a.html#application-of-the-framework-through-a-selected-case-study","content":"\r\nThe following section provides a case study of pre- and post-mitigation assessments. The final risk assessment can assist in determining whether an accredited Integrating Authority is required or not.\r\nThe selected case study is:\r\n\r\n#\r\n\r\nType of case study\r\n\r\nProject Name\r\n\r\n4.1High Risk \u2013 Single agencyClient Data Collection (DSS)\r\nCase studies from other agencies will be included later. This will help ensure the framework continues to be developed in a way that is fit for all situations.\r\nHigh Risk \u2013 Single agency\r\nClient Data Collection (CDC) data integration project (DSS) Department of Social Services (DSS) proposed Client Data Collection (CDC) is an example of a high risk single agency project. DSS is the sole data custodian. In this case, DSS is also the integrating authority.\r\nThe purpose of the CDC project is to enable better monitoring and research within and between DSS programs and payments data. This project is still in the planning stage. The following strategies are hypothetical and subject to change.\r\nPre-mitigation Assessment\r\nThere are three dimensions that influence the consequence of a breach (from the eight risk dimensions agreed upon). The table below outlines the consequence (or impact) on individuals if there is a breach.\r\n\r\nDimension\r\n\r\nImpact\r\n\r\nComments\r\n\r\n\r\nSensitivity\r\nHighThe project involves integrating all DSS programs and payments data. Information collected includes educational background, health status, income level and much more. The data is considered to be highly sensitive. If leaked, there is the potential to cause harm to individuals and the Commonwealth Government as a whole.\r\n\r\nConsent\r\nHighSome of the programs directly obtain consent (Endnote 1) from clients. However, the majority of them do not. Generally, both programs and payments data are collected as an administrative by-product.\r\n\r\nAmount of information about a data provider\r\nHighThere may be twenty or more variables with different personal information about a data provider.\r\n\r\nPre-mitigation Consequence Assessment\r\nHigh\r\nThere are five dimensions that influence the likelihood of a breach (from the agreed eight risk dimensions).\r\n\r\nDimension\r\n\r\nRating\r\n\r\nComments\r\n\r\n\r\nManagerial complexity\r\nLowThere will only be one agency involved in this project. However, a considerable number of internal stakeholders will be part of the project team. The number of DSS staff directly involved in the integration is fewer than ten.\r\n\r\nNature of access\r\nLowRestricted. Access granted to approved staff and access control to be reviewed regularly. The separation principle is applied.\r\n\r\nDuration of the project\r\nHighData is proposed to be retained for more than three years.\r\n\r\nLikelihood of identification\r\nHighA high rating is given as there are a lot of different variables including quasi-identifying variables (such as date of birth, address, indigenous status etc.) contained in the programs and payments data that will be used in the data integration project.\r\n\r\nTechnical complexity\r\nLowTechnical complexity here refers to the output. That is, how difficult it is to confidentialise data for external publication and/or ensuring that external users who need access have access to unit record data. For example, external users may need access to linked data for research purposes. At this stage, external output is not proposed.\r\nPre-mitigation Likelihood Assessment - Medium\r\nThis pre-mitigation likelihood assessment of medium aligns with the risk framework guidelines.\r\nOverall pre-mitigation assessment - High\r\nBased on the above assessment, this project is classified as \u2018high\u2019 risk. The data is highly sensitive, with a large number of identifiable variables on both the programs and payments data. Having assessed the initial risk, DSS can now take actions to reduce the risk of undertaking this project.\r\nPost-mitigation Assessment\r\nThere are a number of things that can be done to mitigate against the likelihood of a breach occurring. The data integration project can be designed in such a way that even if the consequence of a breach occurring is high, the likelihood is reduced such that the project does not require an accredited Integration Authority. These are the mitigation strategies applied to reduce the consequence risk:\r\n\r\nElements\r\n\r\nReducing the likelihood of a breach occurring in the first place\r\n\r\n\r\nSensitivity\r\n\r\nInitially, the data is assessed as highly sensitive. However, the project design is such that the entire dataset is not required. The separation principle plays a big role here.\r\n\r\nIt is proposed that a SLK would be created for programs and payments data using the same algorithm. This would negate the need for access to variables that are highly sensitive on the original dataset. A file with the record identifier between the programs and payments data would be retained. This means that the linked file would not contain any sensitive data. Only if a research request is approved would they be given access to the linked dataset.\r\nDSS already has processes in place to handle research requests.\r\nAll internal research requests would also need to go through an approval stage.\r\n\r\n\r\nConsent\r\nThe data being linked is all an administrative by-product. The purpose of this linking activity is to analyse client pathways through the whole social security system to improve programs and policies. Ultimately, this is the objective of the organisation and thus this project is a strategic move to enable us to provide sound policy advice and better design our programs to achieve quality outcomes.\r\n\r\nAmount of information about a data provider\r\n\r\nLinkage stage:\r\nIt is proposed that only five or fewer variables be used to create the SLK. These would include variables such as:\r\nName (surname and given name)\r\nSex\r\nDate of Birth\r\n\r\nStorage stage:\r\nThe linked file would only contain the SLK, weight (the strength indicator of the link) and record identifier. There is only one quasi-identifying variable in the linked file, as an SLK includes date of birth. This is not enough for identification.\r\n\r\nAnalysis stage:\r\nResearchers (internal) would need to go through an approval stage and access would only be granted once it can be shown that the public benefit of the research outweigh the risk. Throughout the separation principle is applied.\r\nBelow are the mitigation strategies that DSS proposes to adopt to reduce the likelihood of a breach:\r\n\r\nDimension\r\n\r\nInitial rating\r\n\r\nMitigation strategies (reducing likelihood of breach)\r\n\r\nRevised rating\r\n\r\n\r\nManagerial complexity\r\nLowDSS will be responsible for managing the internal stakeholders and ensuring that there is clarity around the complex data governance of this project. They will report to a steering committee to ensure that the risk of breaches are minimised. There would be clear terms of reference for the steering committee.Low\r\n\r\nNature of access\r\nLow\r\nDifferent staff members require access to various aspects of the data at different stages of the project. To mitigate against this risk, the separation principle is applied throughout the project.\r\n\r\nExtraction stage:\r\nStaff members with appropriate security clearance will create the SLK based on the four variables identified above.\r\n\r\nFile transfer stage:\r\nNo external file transfer is required for this project. Internally, access to the system/s would only be granted on a need-to-know basis. Internal data transfers (if required) would only be undertaken by staff with appropriate level of clearance.\r\n\r\nLinkage stage:\r\nStaff members responsible for data linking would only have access to variables needed for the linkage \u2013 in this case this is the SLK variable.\r\n\r\nAnalysis stage:\r\nThe internal researcher is only given data extracts required for their research.\r\n\r\nStorage stage:\r\nThe variables from both datasets are never stored in full in a single file.\r\nLow\r\n\r\nDuration of the project\r\nHigh\r\nWhile the duration of the project is long-term, the stored linked file does not contain any variables that would pose a risk to individuals in the event of a breach.\r\n\r\nIt\u2019s only when the content data is extracted for researchers that there is a risk of a breach. However, there are already policies and protocols in place (such as departmental protective security) to ensure this does not occur.\r\nMedium\r\n\r\nLikelihood of identification\r\nHigh\r\nRisk mitigation strategies can be applied to various stages in the data linking cycle, including extraction, file transfer, linkage, analysis and storage.\r\n\r\nExtraction stage:\r\nThere are two extraction stages \u2013 one to create the SLK and the other to extract the content data for the researcher. In the first stage, only four variables are needed to create the SLK (and SLK in itself cannot spontaneously identify an individual).\r\n\r\nIn the second stage, the extraction of content data for research purposes is already subject to systems that protect the privacy of data providers and confidentiality of data, including protective security measures.\r\n\r\nFile transfer stage:\r\nAs there is only one data custodian involved and access to data is already established, there are no security issues involved with file transfer.\r\n\r\nLinkage stage:\r\nAs SLKs are used to link the two datasets together, only one quasi-identifying variable (date of birth) used in the linkage stage.\r\n\r\nAnalysis stage:\r\nThe release of contents data to the researcher would go through already established practices and Protective Security. No name data is provided for analysis.\r\n\r\nStorage stage:\r\nThe linked file would contain content variables, the SLK and a weight variable. There are no spontaneously identifying variables.\r\nMedium\r\n\r\nTechnical complexity\r\nLowAt this stage, output is not proposed to be published externally.Low\r\n\r\nPost-mitigation Likelihood Assessment\r\nLow\r\nPost-mitigation risk rating - Medium\r\nIn this particular case, an accredited Integrating Authority is not required (Endnote 2)\r\nNext Steps: Register project on the Data Integration project register. An accredited Integrating Authority is not required for this project."},{"id":143,"title":"Introduction","heading":"Summary","path":"./data-integration/risk/introduction.html#summary","content":"\r\nData integration increases the value of Commonwealth datasets by combining them to create more comprehensive information about Australia. Currently, data integration and the risks of integration are managed inconsistently across the Commonwealth. The arrangements for the integration of Commonwealth data were proposed in 2010 to manage the risks of data integration. Their purpose is to encourage Commonwealth agencies to share their data for linking purposes in an effective and safe way. Consistent and robust processes were proposed to increase Commonwealth agencies\u2019 confidence in data integration projects, in particular the management of systemic risk.\r\nThe purpose of the risk assessment is to help Commonwealth agencies assess the level of risk of data integration projects as part of determining if a project should proceed and whether an accredited integrating authority is required to manage the integration project. \r\nThe risk assessment is only one element that needs to be considered in making a decision on whether to proceed with a project. Data custodians need first to consider whether a project is appropriate and supported by the agency, taking the level of community acceptance, cost/benefit and political considerations of the project into account. \r\nThe risk assessment process involves the development of two risk assessments. The initial risk assessment assesses the risk of the data integration project against criteria specified by the Cross Portfolio Data Integration Oversight Board (the pre-mitigation risk assessment). A subsequent risk assessment assesses the residual risk after accounting for risk mitigation strategies (the post-mitigation risk assessment). The risk assessments are compiled either by a lead data custodian appointed by the data custodians for the project, or jointly by all the data custodians (as appropriate given the legislative environment), and may include input provided by one or more integrating authorities and data users. These two assessments are then submitted as part of project registration. The Oversight Board is able to review the risk assessments to ensure they are undertaken accurately and consistently across agencies, and provide advice to agencies on how they could manage risk. \r\nThese guidelines ensure that only truly \u2018high\u2019 risk projects require the use of accredited Integrating authorities (IAs), reinforcing the aim of the arrangements to encourage and enable greater sharing of Commonwealth data in an effective and systemically safe way. \r\nPurpose"},{"id":144,"title":"Introduction","heading":"Purpose","path":"./data-integration/risk/introduction.html#purpose","content":"\r\nThe purpose of the Guidelines is to help Commonwealth agencies assess the level of risk of data integration projects. This assists data custodians in determining if a project should proceed and whether an accredited integrating authority is required to manage the project. An accredited integrating authority is required if, even once risk mitigation strategies are put in place, there is a \u2018high\u2019 risk of harm to data providers (including persons, families, households or organisations who have contributed data) or a loss of public trust in the Australian Government or its institutions.\r\nBackground"},{"id":145,"title":"Introduction","heading":"Background","path":"./data-integration/risk/introduction.html#background","content":"\r\nData integration combines information from different data sources to produce new datasets. In 2010, the Secretaries Board endorsed a set of principles that govern the integration of Commonwealth data for statistical and research purposes, as well as a set of governance and institutional arrangements to support these principles. This paper introduces the revised risk framework guidelines (the Guidelines) that enable Commonwealth data to be safely integrated.\r\nWhether a project should proceed"},{"id":146,"title":"Introduction","heading":"Whether a project should proceed","path":"./data-integration/risk/introduction.html#whether-a-project-should-proceed","content":"\r\nThe risk assessment is only one element that needs to be considered by agencies in deciding if a project should proceed. Other critical decisions are whether benefits outweigh costs, the level of community acceptance of a project and contextual issues. Contextual issues relate to the political, social and economic landscapes. A project also requires the support of data custodians. The appropriateness of a project may be influenced by whether the project is legally required, is a decision of government or meets a broad community need.\r\nPrivacy concerns have a strong bearing on community acceptance of a project. These concerns are influenced by the perceived sensitivity of the data being used. Public trust in government may be negatively impacted by projects integrating data people perceive to be sensitive or for a purpose they do not support. An assessment on the likely public perception of integration is therefore important. Transparent processes and community engagement will reduce the concerns the public have in integration projects (Endnote 1).\r\nWhile a decision on whether to proceed with an integration project should be based on all of these elements, this risk framework focuses on assessing the risk of a breach of confidentiality and privacy. Breaches have negative consequences for public trust in government and for individuals and organisations that are affected by the breaches.\r\nENDNOTES\r\n\r\nPrinciples 4 & 7, High Level Principles for Data Integration Involving Commonwealth Data for Statistical and Research Purposes"},{"id":147,"title":"Key Concepts","heading":"Players in the process","path":"./data-integration/risk/key-concepts.html#players-in-the-process","content":"\r\nData Custodian\r\nis an agency accountable for managing the use, disclosure and protection of its data.\r\noperates within legislative authority (where it exists) to provide data to integrating authorities for integration.\r\nremains accountable for the data it has responsibility for throughout the integration process (Endnote 1).\r\napproves data integration projects and appoints an integrating authority.\r\nconsults with other data custodians and the integrating authority to ensure all appropriate risk assessments are undertaken.\r\nWhere there is more than one data custodian, a lead data custodian may be appointed by the data custodians to compile the risk assessments.\r\nIn this framework, the term data custodian refers to either the sole data custodian, the lead data custodian where appointed, or custodians jointly where there are multiple custodians and no lead custodian. \r\nIntegrating authority\r\nis an organisation appointed by the data custodian to integrate two or more datasets, at least one of which is a Commonwealth dataset.\r\nis the single agency (Endnote 2) accountable for the sound conduct of the integration project, including ongoing risk management.\r\nmay also be a data custodian or data user.\r\nmay be an accredited Integrating Authority\r\nmay suggest changes to the risk assessments completed by the data custodian/data custodians. \r\nData user\r\nis a person or an organisation that undertakes analysis of an integrated dataset.\r\nmay also be a data custodian and/or an integrating authority.\r\ndoes not need to be a Commonwealth agency.\r\nThere may be many data users involved in a project. \r\nThe Cross Portfolio Data Integration Oversight Board\r\nThe Oversight Board:\r\nis responsible for the arrangements for the integration of Commonwealth data for statistical and research purposes on behalf of Secretaries Board.\r\nprovides strategic and collaborative leadership, supports effective governance and may provide advice to help manage the risks of particular data integration projects.\r\nhelps manage the systemic risk associated with conducting multiple data integration projects involving Commonwealth data through assessment of proposed risk mitigation strategies and the provision of advice.\r\nendorses any changes or additions to the overall environment, including amendments to the principles or guidelines, or the development of new general tools to support integration or safe access to integrated data for statistical and research purposes.\r\nIn practice, the Oversight Board:\r\nhas ten working days following registration of the project and receipt of the risk assessment to raise any concerns about the project with the data custodians or integrating authority. These concerns relate to the management of systemic risks of data integration. \r\nhas no authority to approve or delay data integration projects. Approval is given by data custodians.\r\nensures that the risk mitigation strategies proposed when a project is registered are implemented. To ensure this, the Oversight Board may request a review of one or more of a data custodian\u2019s integration projects.\r\nmay work with data custodians and integrating authorities to improve their risk assessment processes.\r\ncan delegate its review functions.\r\nThe Oversight Board will work with data custodians and integrating authorities to resolve any issues relating to unacceptably high systemic risks or inappropriately managed projects. If the issues cannot be resolved or managed to the satisfaction of the Oversight Board, then the Chair of the Oversight Board will engage in direct discussion and negotiation with the agency head of each data custodian that is party to the project to resolve the matter. Where there is a conflict of interest for the Chair of the Oversight Board to engage in direct discussion with the head of each the agency concerned, the matter will be referred to another member of the Oversight Board and where resolution cannot be achieved, to the Secretaries Board. \r\nData provider\r\nis an individual, household, business or other organisation which supplies data to a data custodian.\r\nRisk concepts"},{"id":148,"title":"Key Concepts","heading":"Risk concepts","path":"./data-integration/risk/key-concepts.html#risk-concepts","content":"\r\nRisk Assessment Guidelines\r\nThe Guidelines provide a platform to assess the risk of harm to a data provider and the risk of a reduction of public trust in the Australian Government and its institutions as a result of a breach. \r\nData custodians can decide that the assessment guidelines on risk dimensions are not valid for their particular context. However, deviations from the assessment guidelines must be explained in the risk assessment. \r\nBreach\r\nA breach is \u201Cwhen personal information or the confidential information of an organisation held by an agency or another organisation is lost or subjected to unauthorised access, use, modification, disclosure, or other misuse.\u201D \r\nFor example, a breach occurs when: \r\na USB with unconfidentialised data is left on a train and viewed by an individual not authorised to see the data.\r\ndata is poorly confidentialised and exposes information about a data provider.\r\nan aggregate table is published with small cells that allow identification of data providers. For example consider a table that cross-tabulates the number of recipients of carer payments by sex, suburb and income, which contains a cell showing only one male recipient living in Glebe. Any users who know a male in Glebe who receives a carer payment will be able to use the table to determine his income.\r\nIf there is legislation which impacts on the dissemination and management of data, the more stringent understanding should apply. \r\nRisk Assessment\r\nThe risk assessments are undertaken by the data custodian and involve several steps: \r\na pre-mitigation risk assessment is conducted following consultation with other stakeholders.\r\nmitigation strategies are developed. This step may involve consultation with the integrating authority and data users.\r\na post-mitigation risk rating is calculated which determines whether an accredited Integrating Authority is required.\r\nIf the post-mitigation risk rating for a project is \u2018low\u2019 or \u2018medium\u2019, the use of an accredited Integrating Authority is optional. \r\nThe risk assessments and post mitigation risk rating for a data integration project are submitted to the Oversight Board via the project registration process to ensure that they have been completed appropriately. Registration occurs after a project has been approved by data custodians and agreements signed. \r\nLikelihood of a breach\r\nLikelihood is the measurement of the potential for a breach to occur (Endnote 3). \r\nIt assesses the parts of a project in which a breach is possible. \r\nFor example, the security of an agency\u2019s IT systems will determine how likely a breach is to occur due to hacking. \r\nConsequences of a breach\r\nConsequence is a measurement of the potential outcome of any breach. \r\nIt includes harm to a data provider, including humiliation, or a reduction in public trust in the Commonwealth\u2019s ability to store and protect sensitive data (Endnote 4). \r\nRisk review\r\nThere are two types of review outlined in the Guidelines: \r\nAn initial review within the ten day period of the Oversight Board receiving a risk assessment for a particular project, and\r\na review of a data custodian\u2019s completed integration projects.\r\nThe ten day review allows the Oversight Board to provide advice and guidance on specific projects. The advice may be in the form of concern around a particular project, or suggestions of ways to manage risk. This advice should focus on minimising the systemic risks of a project. \r\nThe review of completed integration projects involves an assessment of public reaction to the project and how public understanding and acceptance was managed throughout the project, as well as an assessment of the application and effectiveness of the mitigation strategies.\r\nSuch a review will be conducted by a party: \r\napproved by the data custodian;\r\nthat is at arm\u2019s length to the risk assessment process, but need not be external to the agency; and\r\nthat has the ability to provide an objective expert assessment of whether the mitigation strategies initially proposed were implemented.\r\nRisk mitigation strategies\r\nMitigation strategies attempt to minimise the risk of a project. In this risk framework, mitigation strategies will mostly act on the likelihood of a breach. \r\nMultiple mitigation strategies may be required to lower the risk of a breach. \r\nIt is possible that mitigation strategies may lower one risk while increasing another. \r\nPublic trust in the Government\r\nPublic trust in the Government and its institutions is the degree to which individuals and organisations trust the Commonwealth, state, territory and local governments to manage their data. \r\nMany people do not distinguish between government agencies. Therefore, the actions of one agency affects people\u2019s trust in all government agencies. \r\nPublic trust also impacts on the Australian Statistical System in general. \r\nPublic trust affects how likely it is that individuals and organisations will participate in research conducted by government agencies. \r\nConfidentialised data\r\nConfidentialised data is individual (Endnote 5) or micro level unit information (Endnote 6) that has been de-identified and has had other information removed or modified to reduce the risk of a data provider being identified. \r\nInternal data integration\r\nInternal data integration is integration that is undertaken completely within an agency, not provided to external agencies or researchers and where the agency is also the custodian for all the Commonwealth datasets being integrated. \r\nWork being undertaken internally does not automatically lower the risk of a breach. However, there are many elements of internal work that are likely to be effective risk mitigation strategies. For example, the IT environment is likely to be more secure and legislative penalties for a breach high. \r\nThe mitigation strategies should be included in the post-mitigation risk assessment. \r\nENDNOTES\r\n\r\nThe accountability of the data custodian is described in Principle 2 of the High Level Principles for Data Integration Involving Commonwealth Data for Statistical and Research Purposes.\r\nMore than one integrating authority may be consulted or asked for a quotation on each project before it commences. However, only one integrating authority can have full responsibility for the way in which each data integration project is conducted, and this must be determined before the project commences.\r\nThese definitions draw on Standards Australia/Standards New Zealand\u2019s definitions of likelihood and consequence in the Risk management \u2013 principles and guidelines (2009). \r\nThese concepts are further discussed in the NHMRC National Statement on Ethical Conduct in Human Research.\r\nThat is, a person or an organisation.\r\nThat is, a family, household, community, or organisation group."},{"id":149,"title":"Risk Assessment Guidelines","heading":"Consequence of a breach","path":"./data-integration/risk/risk-assessment-guidelines.html#consequence-of-a-breach","content":"\r\nSensitivity\r\nSensitivity assesses the effect of a breach on the data providers. \r\nThe National Health and Medical Research Council\u2019s National Statement on Ethical Conduct in Human Research (Endnote 1) provides a good framework for assessing the sensitivity of the data in relation to persons. The main elements of a risk of harm are: \r\nphysical harm,\r\npsychological harm,\r\neconomic harm,\r\nsocial harm,\r\nlegal harm, and\r\ndevaluation of personal worth.\r\nThe National Statement focuses on individuals, but many of the concepts are relevant to organisations. \r\nMost ethical risk frameworks assess whether the risk might affect populations over which the data user has additional duty of care obligations. These populations are usually children, people with mental illness, and people with cognitive or intellectual impairments. This may also extend to other small population groups where their information may be sensitive, such as Aboriginal or Torres Strait Islander populations or groups from particular ethnic or religious backgrounds. A way to account for this additional duty of care is to increase the risk rating of a project if these populations are likely to be affected. For example, an initial sensitivity rating of \u2018low\u2019 may be increased to \u2018medium\u2019 if a project included children. However, there are exceptions to this rule. For example, some information about school children may be less sensitive if there is little variation in the dataset, or where the subject/topic is inherently of low sensitivity (for example, participation in sport). \r\nThe Guidelines take a different position on the classification of harm in comparison to the National Statement on Ethical Conduct. The Guidelines classify harm risk ratings as the following: \r\n\u2018High\u2019 consequence involves a foreseeable risk of serious harm to data providers in any of the main elements of harm.\r\n\u2018Medium\u2019 consequence involves a foreseeable risk of any harm to data providers.\r\n\u2018Low\u2019 consequence involves no foreseeable risk of harm.\r\nThe reason for this is the need to focus the risk management effort of the Oversight Board on those projects that pose the greatest risk to public trust and thus have the greatest potential to undermine the value of Commonwealth data as a strategic asset. Many projects carry some risk of harm in the event of a breach, but in general this risk must be managed by those directly involved (the data custodians, the integrating authority, and the data users). \r\nConsent\r\nConsent is the component of the nature of data collection that impacts on public trust in the Government. If an agency has informed consent from the provider, the consequences of a breach may be lower. Consent may lower the consequence as data providers are aware, or partially aware, of the research being undertaken and the risks of participating in the research. To be able to consent, there must be an option to opt-out for the data provider (Endnote 2). \r\n\u2018High\u2019 consequence involves no consent, or coerced consent.\r\n\u2018Medium\u2019 includes partially-informed consent.\r\n\u2018Low\u2019 consequence exists when informed consent has been obtained and the risks of integration have been explained and are understood (Endnote 3).\r\nThere is much literature on the notion of consent. While most focuses on the notion of an individual, the concepts that apply to an individual can easily be applied to organisations. \r\n\r\nAmount of information about a data provider\r\n\r\nThe number and nature of variables containing information about a data provider in a dataset affects the consequence of breach. For example, the separation principle limits the number of variables in a given dataset by splitting datasets into linking variables and analysis variables. \r\n\r\nRating Consequence Risk\r\n\r\n\r\nA project is assessed as having a \u2018high\u2019 consequence risk if: \r\nThe level of consent or sensitivity of data risks have been rated as \u2018high\u2019, or\r\nThe level of consent or sensitivity of data risks have been rated \u2018medium\u2019 and the risk due to the amount of information about a data provider rated \u2018high\u2019.\r\nA project with \u2018low\u2019 consequence risk has no dimensions rated \u2018high\u2019 and a maximum of one dimension assessed as \u2018medium\u2019. \r\nIf the amount of personal information is rated as \u2018high\u2019, but the other two are \u2018low\u2019 then the overall rating is \u2018medium\u2019. \r\nAll other combinations of risk are rated as \u2018medium\u2019. \r\nThe sensitivity of data, and consent have been weighted equally as they are both can have very serious consequences. The amount of personal information is covered to a certain degree by the sensitivity of the data dimension. \r\nLikelihood of a breach"},{"id":150,"title":"Risk Assessment Guidelines","heading":"Likelihood of a breach","path":"./data-integration/risk/risk-assessment-guidelines.html#likelihood-of-a-breach","content":"\r\nLikelihood of identification\r\nSome variables are subjective (for example, have you been depressed most of the time for more than a month).\r\nSome have low visibility to others (for example, do you play golf).\r\nOther variables may be easy to assess objectively (for example, do you work as a teacher).\r\nSome are highly identifying (for example, name and address).\r\nThe number and nature of the variables contained in a dataset affect the likelihood of identification. The inclusion of some variables, known as quasi-identifying variables, quickly increases the probability of spontaneous identification of records and identification through list matching (Endnote 4). For example date of birth and country of birth are quasi-identifying variables. In isolation they are not identifying; however, in combination they may be unique to an individual. \r\nIn many circumstances, three quasi-identifying variables in combination may be enough to enable identification. For example, a male working in Department of Social Services that was born on 29 August 1987 and lives in Lyneham is likely to be identifying.\r\nAdditionally matching these details against a publicly available dataset may provide ample information to identify persons or organisations within the de-identified dataset. However, removing one of these pieces of information may remove the identifying nature. The likelihood of a breach rises quickly with the number of quasi-identifying variables, especially where datasets are to be released at a unit record level, for example in a confidentialised unit record file (CURF). This risk is: \r\n\u2018High\u2019 where there is a high probability that an individual can be identified using a combination of quasi-identifying and other variables on a dataset.\r\n\u2018Low\u2019 where it is unlikely that quasi-identifying and other variables can be combined to identify an individual.\r\nTechnical complexity\r\nThe technical complexity of a project affects the likelihood of a breach. It includes the complexity of confidentialisation and of methodology. \r\n\u2018High\u2019 risk involves complex data that is likely to be published as a CURF, or multiple aggregate tables that require consequential confidentialisation.\r\n\u2018Low\u2019 risk involves publishing simple aggregated data with basic confidentialisation required.\r\nManagerial complexity\r\nData governance becomes more complex as the number of people and organisations involved in an integration project increases. This potentially leads to diminishing control over data management practices and therefore increases the risk of a breach. \r\nThe more organisations involved, the harder it is for the data custodians to influence the practices of these organisations. The more people involved, the higher the risk of data being leaked or used inappropriately. \r\n\u2018High\u2019 managerial complexity risk would have:four or more agencies involved in the process, or\r\nthirty or more staff directly involved in the integration.\r\n\r\n\u2018Low\u2019 managerial complexity risk would have:only one agency involved, and\r\nfewer than ten staff directly involved in the integration.\r\nDuration of project\r\nThe longer data are stored following a project, the more likely a breach becomes. Similarly, the longer a project runs, the more likely a breach becomes. There are two reasons for the increased likelihood of a breach, data storage and documentation. \r\nData access that is poorly controlled, or data that are exposed to external attack, are poorly stored. The longer the data exists in this storage, the more likely it is that one of these deficiencies will be exposed and a breach will occur. \r\nPoor metadata, or data documentation, may lead to new staff publishing data without appropriate confidentialisation, or using data inappropriately. \r\nA project with \u2018high\u2019 duration of project risk would:retain data for more than three years, or\r\nrun for more than three years.\r\n\r\nA project with \u2018low\u2019 duration of project risk would:destroy data on the completion of the project, and\r\nrun for less than one year.\r\nNature of access\r\nThe nature of access is concerned with the quality, consistency and coverage of governance and controls placed around access to data at all stages of the integration project. \r\nUnrestricted or unaudited access is a \u2018high\u2019 risk. \r\n\u2018Low\u2019 risk requires: \r\naccess to be granted on a demonstrated \u2018need to know\u2019 basis, and\r\nthe separation principle to be applied, and\r\nregularly audited and restricted access.\r\nRating likelihood risk\r\nIt is difficult to weight the likelihood dimensions of risk, as the importance and impact of these dimensions depends on the context in which they are applied. As a guide the overall likelihood risk is \r\n\u2018high\u2019 if three or more likelihood dimensions have been assessed as \u2018high\u2019, and\r\n\u2018low\u2019 if no dimensions are rated \u2018high\u2019 and less than three are rated medium.\r\nMitigation strategies, especially for work undertaken internally within a Commonwealth agency, should reduce the likelihood risk considerably. \r\nRelevant legislation"},{"id":151,"title":"Risk Assessment Guidelines","heading":"Relevant legislation","path":"./data-integration/risk/risk-assessment-guidelines.html#relevant-legislation","content":"\r\nLegislation influences the way data are used and shared. Legislation that broadly covers data dissemination includes: \r\nPrivacy Amendment (Enhancing Privacy Protection) Act 2012\r\nPrivacy Act 1988\r\nPrivacy and Personal Information Protection Act 1998 (NSW)\r\nHealth Records and Information Privacy Act 2002 (NSW)\r\nInformation Act 2002 (NT)\r\nInformation Privacy Act 2009 (Qld)\r\nPersonal Information and Protection Act 2004 (Tas)\r\nInformation Privacy Act 2000 (Vic)\r\nFreedom of Information Act 1992 (WA)\r\nIndustry Research and Development Act 1986\r\nPooled Development Funds Act 1992\r\nVenture Capital Act 2002\r\nHowever, there are many specific pieces of legislation that govern the use of data. An example of specific legislation is the Social Security (Administration) Act 1999 which governs the way data collected by Centrelink is used and shared. \r\nLikelihood and consequence risk matrix"},{"id":152,"title":"Risk Assessment Guidelines","heading":"Likelihood and consequence risk matrix","path":"./data-integration/risk/risk-assessment-guidelines.html#likelihood-and-consequence-risk-matrix","content":"\r\n\r\nThe likelihood and consequence risk matrix assists in determining the overall risk of a project. The overall risk rating is determined by the combination of the likelihood and consequence risk ratings. Once this rating is known, risk mitigation strategies can be identified and applied. \r\nMitigation strategies"},{"id":153,"title":"Risk Assessment Guidelines","heading":"Mitigation strategies","path":"./data-integration/risk/risk-assessment-guidelines.html#mitigation-strategies","content":"\r\nThere are many possible mitigation strategies that can be applied to reduce the likelihood risks. However, there are very few mitigation strategies that can be applied to the consequence risk dimensions without changing the scope of the project. For example, a dataset with highly sensitive data can have the sensitive data removed; however, this changes the project as the component data is now different. \r\nRisk mitigation examples\r\nData labs for external data users\r\nRequiring data users to use secure data labs ensures that the IT environment is more secure, limiting the potential for loss or theft of the data. \r\nLegislative penalties\r\nThe data supplied by data providers may be subject to the Privacy Act and/or protected by one or more confidentiality/secrecy provisions that govern the management of that data. Data custodians, integrating authorities and data users are obliged to comply with the Privacy Act and the confidentiality/secrecy provisions in relevant legislation governing the collection, use and disclosure of the information. \r\nElements of the integration Best Practice Guidelines\r\nSome elements of the integration Best Practice Guidelines can be applied more easily than others, and they can be applied to different extents. For example, applying the separation principle may be costly and may be an operational challenge. However, separating a dataset into linking and analysis variables is relatively straight forward and reduces the size of the datasets. Therefore, if one of the datasets is compromised, only a subset of the information is made public, and harm may be averted. The consequence of the breach of one of these datasets is therefore lower than the breach of the combined dataset \r\nExperienced data integrating staff\r\nUsing experienced staff ensures that processes are able to run more smoothly and efficiently. They will also be more likely to have an understanding of the data governance that applies to data integration and the purpose of the governance. Therefore, there is a lower risk of breaches resulting from negligence or ignorance. \r\nThis is by no means an exhaustive list of mitigation strategies. However, most mitigation strategies will impact on the IT environment, staff accountability and organisational procedures. As the risk assessment process matures, more mitigation strategies will become apparent. Choosing which to implement will in general be up to the data custodian and integrating authority involved in a data integration project. There are many mitigation strategies to consider for implementation. The key element of the post mitigation risk assessment is about how, and how much, the mitigation strategies proposed will lower the overall risk of a data integration project. The justification needs to satisfy the data custodians, integrating authority and, ultimately, the Oversight Board. \r\nENDNOTES\r\n\r\nThe NHMRC National Statement on Ethical Conduct in Human Research can be found here: https://www.nhmrc.gov.au/about-us/publications/national-statement-ethical-conduct-human-research-2007-updated-2018\r\nOpt-out refers to the concept of being able to decline to be involved in a research project without fear of repercussions. For example, those on government payments would have to be reassured that by not consenting for their information being used for research purposes that their current and future potential to claim payments will not be jeopardised. It is not enough to say that a payment is voluntary and therefore if they do not want their information used they can choose not to receive the payment. \r\nThe Australian Communications and Media Authority\u2019s (ACMA) paper Community research on informed consent: Qualitative research report (2011) notes that \u201C[customers] often gave \u2018consent\u2019 but claimed that in reality it was not always \u2018informed consent\u2019, as\u2026they often provided consent without a full understanding and comprehension of the terms and conditions of the agreement.\u201D \r\nList matching is where a user has access to another source of data, such as an external administrative dataset, and attempts to match the two datasets using common data items. "},{"id":154,"title":"Risk Assessment Process","heading":"Pre-mitigation risk assessment","path":"./data-integration/risk/risk-assessment-process.html#pre-mitigation-risk-assessment","content":"\r\nThe first stage of the process involves the data custodian undertaking consultation with stakeholders. Key stakeholders are data custodians, integrating authority and data users. A data custodian compiles the pre-mitigation risk assessment. This assessment follows the assessment guidelines set out in Appendix A of this paper. In compiling this assessment, the data custodian needs to consider whether the information in Appendix A is relevant to the context of the particular project. For example, a project that is working with data that are culturally sensitive may need to consider the cultural impact of the research.\r\nMitigation strategies"},{"id":155,"title":"Risk Assessment Process","heading":"Mitigation strategies","path":"./data-integration/risk/risk-assessment-process.html#mitigation-strategies","content":"\r\nMitigation strategies lower the risk of a data breach. To analyse mitigation strategies, their impact on the overall risk of a project is assessed over the duration of the project. The data custodian leads this work, although other key stakeholders may play an active role in this process. The positive and negative effects of any mitigation strategies need to be assessed. For example, using expert contractors to undertake the integration decreases the technical complexity risk, yet it increases the managerial complexity of the project. As the aim of the Guidelines is to enable the research while managing risks, there should be a focus on what satisfies data custodians that data will be managed appropriately.\r\nPost-mitigation risk assessment"},{"id":156,"title":"Risk Assessment Process","heading":"Post-mitigation risk assessment","path":"./data-integration/risk/risk-assessment-process.html#post-mitigation-risk-assessment","content":"\r\nOnce it has been decided which mitigation strategies will be used, a post-mitigation assessment is compiled by the data custodian. This justifies the mitigation strategies and explains how they lower the risk of a breach. The risk assessments are then submitted to the Oversight Board as part of the project registration process. The post-mitigation risk assessment may need review as the project progresses. Risk assessments are an ongoing responsibility for the data custodians and integrating authority. If the project\u2019s risk changes significantly during the life of the project, then the risk assessment will need to be updated by the integrating authority inconsultation with the data custodians and data users.\r\nIntegrating decision"},{"id":157,"title":"Risk Assessment Process","heading":"Integrating decision","path":"./data-integration/risk/risk-assessment-process.html#integrating-decision","content":"\r\nThe risk assessment process establishes whether an accredited integrating authority is required. If a project remains \u2018high\u2019 risk after mitigation strategies have been applied, then an accredited integrating authority is required. Where appropriate, the data custodian may assist the integrating authority in applying the best practice for integration (Endnote 1). \r\nNext steps"},{"id":158,"title":"Risk Assessment Process","heading":"Next steps","path":"./data-integration/risk/risk-assessment-process.html#next-steps","content":"\r\nThe next steps for the project involve data custodians making a final decision to proceed with the project, based on public benefit and acceptance considerations, the risk assessment and the ability to mitigate that risk. If the data custodians approve the project, they will appoint an integrating authority, which may also be one of the data custodians, who will be responsible for the ongoing risk management of the project. The integrating authority, in consultation with the data custodians and data users, will finalise the details of the project and prepare agreements to formalise relationships between the parties involved in the integration project where required. \r\nOversight Board review"},{"id":159,"title":"Risk Assessment Process","heading":"Oversight Board review","path":"./data-integration/risk/risk-assessment-process.html#oversight-board-review","content":"\r\nRegistration of a data integration project occurs after the project is approved by the data custodians and agreements signed. The risk assessment for an integration project must be submitted to the Oversight Board when the project is registered. \r\nThe Oversight Board has ten working days to raise any concerns about or suggest improvements to the project with data custodians and the integrating authority. This step is not a road block to a project and the project may proceed immediately. The Oversight Board will work with data custodians and integrating authorities to resolve any issues relating to unacceptably high systemic risks or inadequate risk mitigation. The Oversight Board may delegate this role to another body. If the issues cannot be resolved or managed to the satisfaction of the Oversight Board, then the Chair of the Oversight Board will engage in direct discussion and negotiation with the agency head of each data custodian that is party to the project to resolve the matter. Where there is a conflict of interest for the Chair of the Oversight Board to engage in direct discussion with the head of each the agency concerned, the matter will be referred to another member of the Oversight Board and where resolution cannot be achieved, to the Secretaries Board. \r\nThe Oversight Board may also change the risk assessment process in future, in consultation with stakeholders, if it finds that the process does not accurately assess the true risk of projects. \r\nENDNOTES\r\n\r\nThe Best Practice Guidelines will have further information on best practices for integration."},{"id":160,"title":"Data Custodians","heading":"Introduction","path":"./data-integration/roles-and-responsibilities/data-custodians.html#introduction","content":"\r\n1. This paper identifies the rights, responsibilities and roles of data custodians relative to those of the other key participants in data integration projects involving Commonwealth data for statistical and research purposes, namely integrating authorities and users of integrated datasets. Who is a data custodian? \r\n2. Data custodians are agencies responsible for managing the use, disclosure and protection of source data used in a statistical data integration project. Data custodians collect and hold information on behalf of a data provider (defined as an individual, household, business or other organisation which supplies data either for statistical or administrative purposes). The role of data custodians may also extend to producing source data, in addition to their role as a holder of datasets. \r\n3. For any given data integration project (or family of projects) involving Commonwealth data, there may be one or more data custodians (Endnote 1) . These may be from the same organisation or from separate institutions, will include at least one Commonwealth agency, and may include state/territory agencies and non-government organisations such as universities and private sector businesses. "},{"id":161,"title":"Data Custodians","heading":"Commonwealth data integration arrangements","path":"./data-integration/roles-and-responsibilities/data-custodians.html#commonwealth-data-integration-arrangements","content":"\r\n4. Figure 1 is a stylised representation of the interactions between data custodians, integrating authorities, and data users around data integration arrangements that involve the use of at least one Commonwealth dataset for statistical and research purposes. The figure shows the key factors which data custodians need to consider before releasing data to an integrating authority, namely: \r\nExisting legislation which enables the release of, and access to, data by integrating authorities (i.e., legislation which applies to data custodians and integrating authorities).\r\nPrivacy impacts relating to the use and disclosure of personal information or business data. This may include an assessment against the Commonwealth Privacy Act and equivalent state/territory or other legislation. Agency-specific legislation will also need to be considered.\r\nThe existence of any data protocols governing access to, and the use of, datasets. An example is the need for ethics committee approval for projects using human research data (e.g., clinical trials, population health research and health services data).\r\nEnsuring that the data integration project takes into account the public benefit which can be derived from the use of integrated datasets.\r\n5. The choice of integrating authority will be based on a consultative process led by the data custodians taking into account any preferences of the data users. Data custodian need to give in principle approval for the project to proceed before an integrating authority is appointed. Data custodian(s) remain individually accountable for the source data used in statistical data integration projects (refer to the Commonwealth\u2019s Statistical Integration Principle 2 \u2013 Custodian\u2019s Accountability) and must ultimately be satisfied with the chosen integrating authority. \r\n6. Commonwealth data custodians are required to address all of these factors. The requirements will vary among different data custodians as indicated in Figure 1. \r\n"},{"id":162,"title":"Data Custodians","heading":"The rights and responsibilities of data custodians","path":"./data-integration/roles-and-responsibilities/data-custodians.html#the-rights-and-responsibilities-of-data-custodians","content":"\r\n7. Data custodians have a number of \u2018rights and responsibilities\u2019 related to the release of, and access to, source datasets for data integration projects. These form the basis for how data custodians will work collaboratively with other participants involved in data integration projects. \r\n8. The key rights and responsibilities of data custodians in relation to integrating authorities are listed below. \r\nIt is the responsibility of data custodians to ensure they are authorised by legislation or consent to release identifiable data to an integrating authority. The data custodians must also be satisfied that the integrating authority has the necessary legislative protections in place prohibiting disclosure of identifiable data, before the commencement of a data integration project.\r\nIf a data custodian approves a project, the data custodian will need to provide data to the relevant integrating authority for that project. Data will be protected and safely managed by the integrating authority throughout the project life cycle and in accordance with any requirements of data custodians.\r\nIt is the responsibility of data custodians to ensure good data management practices, (including clear documentation, the use of standard definitions and classifications, the maintenance of appropriate metadata, and quality assurance) are undertaken before data is provided to an integrating authority.\r\nIt is the right of data custodians to have data linkage, merging and access services provided on their behalf by an integrating authority.\r\nWhere the Cross Portfolio Data Integration Oversight Board advises on amendments to \u2018high risk\u2019 (Endnote 2) projects (or where a concern is raised), data custodians, the integrating authority and data users will need to collaborate on how to make improvements to such project(s).\r\nData custodians may collaborate with integrating authorities on the content of training material provided to data users. Input, advice and assistance will be provided at the discretion of data custodians.\r\nData custodians are responsible for consulting with the integrating authority about the information the integrating authority will provide when registering the project on the Public Register of Data Integration Projects.\r\n9. Data custodians also have rights and responsibilities in relation to data users. \r\nData custodians are responsible, along with the integrating authority for consulting with data users on any material changes or updates to a data integration project (regardless of whether changes originate from data custodians or integrating authorities). This will occur before data users start examining integrated datasets. Possible issues raised by integrating authorities may include the technical feasibility of the project or the limitations of data use.\r\nData custodians may provide input, advice and assistance to integrating authorities on the content of training material.\r\nData custodians can expect that data users are aware of, and understand, sanctions which apply for attempts to identify (or re-identify) individuals or organisations; disseminating outputs that enable the identification of individuals or organisations; or the misuse of data.\r\nIt is the right of data custodians to approve or disapprove project proposals, in whole or in part (this decision could be influenced by the technical feasibility assessment made by the integrating authorities). Data custodians also have the right to prioritise and schedule data extraction work associated with project proposals, taking account of the range of data extraction requests that may be outstanding at the time. Data custodians are responsible for informing data users of these outcomes.\r\nData custodians may collaborate with data users and integrating authorities on how to make improvements to \u2018high risk\u2019 project(s), based on advice provided by the Cross Portfolio Data Integration Oversight Board.\r\nData custodians have a right to implement cost recovery policies (to recover the costs of preparing and extracting datasets, for example) for data integration projects. Note: cost recovery by Commonwealth agencies must comply with the Australian Government Cost Recovery Guidelines (July 2005) published by the Department of Finance and Deregulation.\r\nData custodians and data users are responsible for ensuring that datasets are used for the approved purposes only. This is facilitated by practices which help avoid the misinterpretation of data. Examples include the supply of appropriate metadata by data custodians and the testing of assumptions made in respect of the data by researchers."},{"id":163,"title":"Data Custodians","heading":"The role of data custodians in data integration projects","path":"./data-integration/roles-and-responsibilities/data-custodians.html#the-role-of-data-custodians-in-data-integration-projects","content":"\r\n10. Data custodians have six key roles in the Commonwealth data integration arrangements. These roles reflect the need for data custodians to strike a balance between maximising the inherent value of data assets and minimising privacy concerns associated with the use of this data. The roles are: \r\nSafe storage of unit record level information;\r\nAssessing the level of risk for each data integration project;\r\nEnsuring compliance with relevant legislation, including privacy, for data release;\r\nEntering into agreements with integrating authorities;\r\nSafe transmission of data; and\r\nMaximising the value of data holdings."},{"id":164,"title":"Data Custodians","heading":"(1) Safe storage of unit record level information","path":"./data-integration/roles-and-responsibilities/data-custodians.html#(1)-safe-storage-of-unit-record-level-information","content":"\r\n11. Data custodians must have policies and procedures in place which contain information on how data custodians will interact with integrating authorities and data users, along with the rights and obligations that exist, to ensure the safe storage of unit record level information. Examples include communication, information security, training and governance strategies. \r\n12. The safe storage of unit record data should be considered along with quality assurance. Data custodians must ensure, as far as practicable, the accuracy, currency and timeliness of data supplied to an integrating authority. The need to ensure data quality aligns with the high level statistical integration principles, which specify the importance of data custodians following good data management practices and maintaining the quality attributes of data (Endnote 3). For personal information, it is also consistent with Information Privacy Principle 8 of the Privacy Act 1988 which states the record-keeper (i.e. the data custodian) is responsible for checking the accuracy and completeness of personal information before it is used. Equivalent principles for business data should also be considered. \r\n13. Quality assurance is an essential step to help minimise any potential problems which may arise with integrated datasets. Good data management practices include the provision of clear documentation, the use of standard definitions and classifications, and the maintenance of appropriate metadata, including quality attributes of the data. Any quality (or software) issues arising from the use of integrated datasets will be addressed by a governance protocol developed by data custodians and integrating authorities (see Role 4: Entering into agreements with Integrating Authorities). "},{"id":165,"title":"Data Custodians","heading":"(2) Assessing the level of risk for each data integration project","path":"./data-integration/roles-and-responsibilities/data-custodians.html#(2)-assessing-the-level-of-risk-for-each-data-integration-project","content":"\r\n14. A key role of data custodians is to determine the level of risk for a data integration project, using the risk assessment framework developed for Commonwealth data integration projects. The level of risk is an important part of determining if a project should proceed and whether an accredited Integrating Authority is required to manage the integration project (i.e. if the project is assessed as high risk). Where there is more than one data custodian, a lead data custodian may be appointed by the data custodians to compile the risk assessments. "},{"id":166,"title":"Data Custodians","heading":"(3) Ensuring compliance with relevant legislation, including privacy, for data release","path":"./data-integration/roles-and-responsibilities/data-custodians.html#(3)-ensuring-compliance-with-relevant-legislation,-including-privacy,-for-data-release","content":"\r\n16. Data custodians need to take into account the potential privacy impacts for any given data integration project. Guidelines for the collection, use and disclosure of personal information by Commonwealth and ACT government agencies are stipulated in Information Privacy Principles contained in the Privacy Act 1988. The same legislation also extends to some private sector organisations and small businesses (including non-profit organisations or unincorporated associations) under National Privacy Principles (Endnote 4). \r\n17. Agency-specific legislation also affects the disclosure of personal information obtained through data collections. Examples include secrecy provisions that apply to statistical collections under the Census and Statistics Act 1905 (ABS), identifiable data disclosed under the Health Insurance Act 1973 and National Health Act 1953 (Department of Health), and the disclosure of protected information relating to income support (Social Security (Administration) Act 1999) and family payments (A New Tax System (Family Assistance) (Administration) Act 1999) (Department of Social Services). \r\n18. For all data integration projects, data custodians must determine whether they are authorised to release identifiable data to an integrating authority either by the data custodian\u2019s legislation or by consent from the data provider (that is, the person, family, household, business or other organisation who originally supplied the data for statistical and administrative purposes). \r\n19. The data custodian must be satisfied that the integrating authority has the necessary legislative protections in place prohibiting disclosure of identifiable data, other than where allowed by law. In particular accredited Integrating Authorities undertaking high risk data integration projects must be bound by the Commonwealth Privacy Act (or a state/territory equivalent) and be subject to criminal penalties for a breach of legislation with regard to an unauthorised disclosure of information. For low and medium risk projects, at a minimum, integrating authorities must have an appropriate policy framework in place to ensure that no identifiable data is disclosed, other than where allowed by legislation (Endnote 5). \r\n20. A Privacy Impact Assessment should be considered for \u2018high risk\u2019 projects. This will help data custodians identify and address any potential privacy risks around the collection, use and release of data. An example of work undertaken as part of a Privacy Impact Assessment is an examination of the public interest test by health data custodians. Under Section 95a of the Privacy Act 1988, National Health and Medical Research Council (NHMRC) guidelines allow for the use and disclosure of health information where it substantially outweighs the public interest in maintaining privacy. \r\n21. Where legislative authority does not exist to release data to an integrating authority, informed consent must be obtained from data providers before the release of data to an integrating authority. "},{"id":167,"title":"Data Custodians","heading":"(4) Entering into agreements with integrating authorities","path":"./data-integration/roles-and-responsibilities/data-custodians.html#(4)-entering-into-agreements-with-integrating-authorities","content":"\r\n22. Each data custodian must enter into an agreement with a nominated integrating authority. This agreement may take the form of a contract, Memorandum of Understanding or other arrangement as appropriate for the parties concerned. When the data custodian and integrating authority is the same agency, appropriate internal governance arrangements, rather than an agreement, will need to be in place. The purpose of a project agreement is to help ensure that datasets are managed and used in accordance with data custodian requirements throughout the life of the project (Endnote 6). \r\n23. The terms of the agreement will vary on a project-by-project basis, but will generally consist of core elements such as: \r\nInformation on how data will be safely managed, including the provision of secure data arrangements by integrating authorities, to help manage project risks;\r\nThe use of data protocols that balance risk and public benefit (e.g., the use of ethics committees for human-based health research);\r\nSpecifying control mechanisms, in collaboration with integrating authorities, to assess and ensure that individual or business data is not likely to be identified. This may take the form of data modification or data reduction techniques.\r\nDeveloping governance protocols to investigate and resolve software issues, along with any anomalies, outliers and data quality issues not previously identified or which arise from the creation of new integrated datasets. Given that data custodians have a key role in quality assurance, it is expected that the data supplied to integrating authorities will be of high quality. The protocol will specify how data custodians will work with integrating authorities and data users. Data custodians should always consider intellectual property rights when deciding whether they are able to make data available for a particular project that would involve using any externally owned software or other technology for transmission of data to the integrating authority or allowing the integrating authority to use such software.\r\nSpecifying any special conditions which must be adhered to by data users. This may include, for example, training requirements and the signing of confidentiality agreements with data custodians. It may also include assurances that data users will make valid use of datasets. For example, data users may be required to seek clearance from data custodians on the use and interpretation of data before publishing research outputs. However, this is not a uniform requirement across Commonwealth agencies.\r\nThe use of communication, technology, training and other processes to minimise the risk of identification of individuals or businesses."},{"id":168,"title":"Data Custodians","heading":"(5) Safe transmission of data","path":"./data-integration/roles-and-responsibilities/data-custodians.html#(5)-safe-transmission-of-data","content":"\r\n24. A key function of data custodians is to ensure the safe transmission of data to integrating authorities. The safe transmission of data should be undertaken in accordance with legislative and policy requirements prior to the commencement of data linkage operations, and in accordance with project agreements. The Australian Protective Security Policy Framework provides further information on the safe transmission of Commonwealth data. "},{"id":169,"title":"Data Custodians","heading":"(6) Maximising the value of data holdings","path":"./data-integration/roles-and-responsibilities/data-custodians.html#(6)-maximising-the-value-of-data-holdings","content":"\r\n25. Data custodians must seek to maximise the value of any administrative datasets that are collected and take into account the public benefit which can be derived from statistical and research proposals submitted by data users, as per Commonwealth Statistical Principle 1 (treat data as a strategic resource). However, Commonwealth administrative data cannot be used for statistical or research purposes if this contravenes legislation or any commitment made to data providers regarding the purpose for which their data may be used, or the data is commercial in confidence. \r\n26. Cross-Commonwealth data integration projects are particularly useful for informing whole-of-government policy perspectives and helping to make the best possible use of data that already exists and where possible, minimising respondent burden around data collections. Two current examples of such data integration projects are listed below. \r\nThe Longitudinal Study of Australian Children (LSAC) links one study period to the next. It also links to administrative databases and aggregate census data as a supplement to information collected in the survey. LSAC aims to help improve the understanding of factors influencing childhood development and collects information on children\u2019s physical, cognitive and emotional development. This will help guide policies and interventions to address issues affecting the development and wellbeing of Australian children.\r\nThe Business Longitudinal Database combines small and medium size business characteristics (sourced from the ABS) with financial data from the Australian Taxation Office and the Australian Customs and Border Protection Service. The project provides a basis for measuring the performance over time, as well as key business drivers."},{"id":170,"title":"Data Custodians","heading":"Multiple roles of data custodians in data integration projects","path":"./data-integration/roles-and-responsibilities/data-custodians.html#multiple-roles-of-data-custodians-in-data-integration-projects","content":"\r\n27. For some data integration projects, it is possible that data custodians may have multiple roles where a data custodian may also be the data user (e.g., a Commonwealth agency) and/or the integrating authority. \r\n28. When an entity has more than one role, appropriate internal governance and project documentation, consistent with the Commonwealth principles and governance arrangements for data integration should be in place. "},{"id":171,"title":"Data Users","heading":"Introduction","path":"./data-integration/roles-and-responsibilities/data-users.html#introduction","content":"\r\n1. This page identifies the rights, responsibilities and roles of data users relative to those of the other key participants in data integration projects involving Commonwealth data for statistical and research purposes, namely data custodians and integrating authorities "},{"id":172,"title":"Data Users","heading":"Who is a data user?","path":"./data-integration/roles-and-responsibilities/data-users.html#who-is-a-data-user?","content":"\r\n2. A data user refers to a person involved in accessing and investigating integrated datasets for statistical and research purposes (Endnote 1). This page focuses on data users accessing integrated datasets created using at least one Commonwealth dataset, for statistical and research purposes. \r\n3. Data users include academics working in research institutions and employees undertaking research in Commonwealth and state/territory agencies. It can also include multiple data users working as part of a consortium, alliance or collaborative network. \r\n4. \u2018Data users\u2019 differ from \u2018end users\u2019 of data. Data users are directly involved in analysing integrated datasets at the unit record level to conduct and undertake research. As such, they will work closely with integrating authorities. In contrast, end users examine research findings rather than produce outputs. End users include employees undertaking research in public and private sector organisations, representatives from media outlets and consumer advocacy groups, and members of the wider community. \r\n5. The Commonwealth\u2019s data integration arrangements are shown in Figure 1 \u2013 Appendix 1. This provides a stylised representation of how data users fit within the arrangements, and their interactions with data custodians and integrating authorities. The nomination of an integrating authority will be based on a consultative process led by the data custodian(s). Data custodians need to give in principle approval for the project to proceed before an integrating authority is appointed, remain individually accountable for the source data used in statistical data integration projects (refer to the Commonwealth\u2019s Statistical Integration Principle 2 \u2013 Custodian\u2019s Accountability) and must ultimately be satisfied with the chosen integrating authority. \r\nFor some data integration projects, it is possible that data users may have multiple roles where the data user may also be a data custodian (e.g., a Commonwealth agency) and/or the integrating authority. \r\nWhen an entity has more than one role, appropriate internal governance and project documentation, consistent with the Commonwealth principles and governance arrangements for data integration should be in place (for more information refer to the Best Practice Guidelines for Statistical Data Integration Involving Commonwealth Data). "},{"id":173,"title":"Data Users","heading":"Benefits of the Commonwealth arrangements for data users","path":"./data-integration/roles-and-responsibilities/data-users.html#benefits-of-the-commonwealth-arrangements-for-data-users","content":"\r\n6. The governance and institutional arrangements endorsed by the (Commonwealth) Secretaries Board for data integration projects involving the use of Commonwealth data for statistical and research purposes will deliver significant enhancements for data users. \r\n7. The Commonwealth data integration arrangements will provide benefits to data users including greater transparency about how to access Commonwealth datasets for statistical and research purposes, and ultimately greater access to more Commonwealth data holdings. The arrangements will also provide opportunities for greater collaboration between data users, integrating authorities and data custodians at the pre-approval stage of a project. Data users will be supported by training opportunities. "},{"id":174,"title":"Data Users","heading":"The rights and responsibilities of data users","path":"./data-integration/roles-and-responsibilities/data-users.html#the-rights-and-responsibilities-of-data-users","content":"\r\n8. Data users have a number of \u2018rights and responsibilities\u2019 associated with accessing and using integrated datasets that involve the use of at least one Commonwealth dataset. These exist within the governance and institutional framework designed to minimise risks around the management of data, once data is received by the integrating authority and after it has been integrated. \r\n9. The key rights and responsibilities of data users in relation to data custodians are: \r\nIt is the right of data users to consult with data custodians and the integrating authority on any material changes or updates to a data integration project (regardless of whether changes originate from data custodians or integrating authorities). This will occur before data users start examining integrated datasets. The consultation is likely to include issues raised by integrating authorities such as the technical feasibility of the project or the limitations of data use.\r\nData users are entitled to receive appropriate training covering high level statistical integration principles, governance and institutional arrangements, data protocols (e.g., ethical approval processes in the case of human-based health research), legislative frameworks and security requirements. This training will be facilitated by integrating authorities. Course material will also be determined by integrating authorities, with possible input, advice and assistance provided by data custodians. Data users can also expect to access a range of self-help tools to enhance their understanding of the Commonwealth arrangements.\r\nData users must be aware of, and understand, sanctions which apply for attempts to identify (or re-identify) individuals or organisations; disseminating outputs that enable the identification of individuals or organisations; or the misuse of data.\r\nIt is the right of data users to be informed by data custodians of the project status (i.e. approval or disapproval). Data custodians have the right to approve or disapprove a project proposal, in whole or in part. This decision could take into consideration the technical feasibility assessment made by integrating authorities. Data custodians may also need to prioritise and schedule data extraction work associated with project proposals, taking into account the range of data extraction requests that may be outstanding at the time.\r\nWhere the Cross Portfolio Data Integration Oversight Board advises on amendments to \u2018high risk\u2019 (Endnote 2) projects (or where a concern is raised), data users, data custodians and integrating authorities will need to collaborate on how to make improvements to such project(s).\r\nData users have a responsibility to pay cost recovery payments to data custodians, where applicable.\r\nData users and data custodians are responsible for ensuring that datasets are used for the approved purposes only. This is facilitated by practices which help avoid the misinterpretation of data. Examples include the testing of assumptions made in respect of the data by researchers and the supply of appropriate metadata by data custodians.\r\n10. Data users also have rights and responsibilities in relation to integrating authorities: \r\nIt is the right of data users to receive appropriate training from integrating authorities. \r\nData users can expect to be informed by integrating authorities on the technical feasibility of a research proposal.\r\nIt is the responsibility of integrating authorities to provide integrated datasets to data users, along with full information on cost recovery or fee-for-service policies (where applicable).\r\nData users have a right to receive information on data access arrangements from integrating authorities (subject to written approval from all data custodians and in line with their requirements).\r\nData users are responsible for paying data integration fees to integrating authorities (where cost recovery or fee-for-service charges apply). These costs need to be built into project funding proposals by data users.\r\nData users may collaborate with data custodians and integrating authorities on how to make improvements to \u2018high risk\u2019 project(s), based on advice provided by the Cross Portfolio Data Integration Oversight Board."},{"id":175,"title":"Data Users","heading":"The role of data users in data integration projects","path":"./data-integration/roles-and-responsibilities/data-users.html#the-role-of-data-users-in-data-integration-projects","content":"\r\n11. The Commonwealth governance and institutional arrangements will bring about a major shift in the role of data users. Under the current approaches to data integration used in a number of Commonwealth agencies, researchers undertake data merging and data access functions. These roles will now be carried out by an integrating authority, which will be responsible for the end-to-end management of data integration projects. \r\n12. The five main roles of data users are: \r\nDeveloping research proposals that produce significant overall benefits to the public;\r\nCollaborating with integrating authorities and data custodians at the pre-approval stage; \r\nEntering into agreements with integrating authorities to ensure the safe management and use of datasets;\r\nAccessing integrated datasets through secure arrangements; and\r\nLiaising with data custodians on the valid uses of integrated datasets."},{"id":176,"title":"Data Users","heading":"(1) Developing research proposals that produce significant overall benefits to the public","path":"./data-integration/roles-and-responsibilities/data-users.html#(1)-developing-research-proposals-that-produce-significant-overall-benefits-to-the-public","content":"\r\n13. A key role of data users is to develop research proposals that make the best use of integrated datasets. These proposals need to take into account the public good which can be derived from a data integration project (e.g., social, economic and scientific benefits) (Endnote 3). The public benefit derived from a project should outweigh the imposition to privacy and any risks to the trust and goodwill that the Australian public has in Commonwealth data collection activities. "},{"id":177,"title":"Data Users","heading":"(2) Collaborating with integrating authorities and data custodians at the pre-approval stage","path":"./data-integration/roles-and-responsibilities/data-users.html#(2)-collaborating-with-integrating-authorities-and-data-custodians-at-the-pre-approval-stage","content":"\r\n14. Data users should seek in-principle agreement from data custodians on the project proposal during the pre-approval stage. Data users will then liaise with the integrating authority appointed by the data custodians. It is the role of integrating authorities to assess project feasibility, which includes an examination of the technical complexities that arise from attempting to combine multiple datasets and the provision of advice on such matters to data users. This includes, for example, advising data users of issues such as coding difficulties, missing variables and/or inaccurate records. \r\n15. Following an assessment of the project proposal by data custodians and integrating authorities, data users will then need to implement any suggested modifications during the pre-approval stage (assuming that all data custodians choose to release the source datasets for the project). "},{"id":178,"title":"Data Users","heading":"(3) Entering into agreements with integrating authorities to ensure the safe management and use of datasets","path":"./data-integration/roles-and-responsibilities/data-users.html#(3)-entering-into-agreements-with-integrating-authorities-to-ensure-the-safe-management-and-use-of-datasets","content":"\r\n16. Data users will need to enter into an agreement with an integrating authority for data integration projects. This agreement may take the form of a contract, Memorandum of Understanding or other arrangement as appropriate for the parties concerned. When the data custodian and integrating authority is the same agency, appropriate internal governance arrangements, rather than an agreement, will need to be in place. This agreement or arrangement will be administered by the integrating authority on behalf of every data custodian involved in a data integration project. \r\n17. The agreement or arrangement will cover: \r\nInformation on penalties for the identification (or re-identification) of individuals or businesses, the misuse of data or violation of data access arrangements.\r\nDetails on the cost recovery or fee-for-service policies of integrating authorities, where applicable. Fees will be set at the discretion of integrating authorities and may reflect local practices and arrangements.\r\nGovernance protocols that address how to investigate and resolve software issues, along with data anomalies, outliers and other quality concerns that arise from a data integration project. Data users may raise such issues with the integrating authority and, where applicable, have some input into the development of such protocols.\r\nAny special conditions which must be adhered to by data users, including, for example, training requirements and the signing of confidentiality agreements with data custodians. \r\n18. The purpose of such agreements is to help ensure that datasets are managed in accordance with data custodian requirements while protecting privacy and ensuring that data is not likely to enable the identification (or re-identification) of individuals and businesses. "},{"id":179,"title":"Data Users","heading":"(4) Accessing integrated datasets through secure arrangements","path":"./data-integration/roles-and-responsibilities/data-users.html#(4)-accessing-integrated-datasets-through-secure-arrangements","content":"\r\n19. Data users will only be able to access integrated datasets through secure arrangements provided by the integrating authority. The data will be in a form that is not likely to enable the identification of individuals or businesses, and will be subject to the requirements of the data custodians. The access arrangements used will also be dependent on custodian requirements (e.g., data users may be required to visit a data laboratory for \u2018high risk\u2019 projects to ensure the protection of sensitive datasets). \r\n20. Data users will also be subject to audits conducted by integrating authorities to check their compliance with custodian\u2019s access arrangements. This could include spot checks, vetting of data outputs by integrating authorities and monitoring activities undertaken by data users (e.g., keystrokes, mouse movements and screen captures). "},{"id":180,"title":"Data Users","heading":"(5) Liaising with data custodians on the valid uses of integrated datasets","path":"./data-integration/roles-and-responsibilities/data-users.html#(5)-liaising-with-data-custodians-on-the-valid-uses-of-integrated-datasets","content":"\r\n21. A key role for data users is to seek agreement from data custodians on valid uses of integrated datasets before the publication and dissemination of research findings. This could include data users checking with data custodians that data has been used and interpreted correctly. However, it should be noted that this is not a uniform requirement across Commonwealth agencies. "},{"id":181,"title":"Data Users","heading":"Appendix 1","path":"./data-integration/roles-and-responsibilities/data-users.html#appendix-1","content":"\r\n"},{"id":182,"title":"Integrating Authorities","heading":"Introduction","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#introduction","content":"\r\n1. This paper identifies the rights, responsibilities and roles of integrating authorities relative to those of the other key participants in data integration projects involving Commonwealth data for statistical and research purposes, namely data custodians and users of integrated datasets. \r\n2. Commonwealth Statistical Integration Principle 3, endorsed by the (Commonwealth) Secretaries Board in February 2010, states that an integrating authority must be nominated for each data integration project (or family of projects) involving Commonwealth data for statistical and research purposes (Endnote 1). \r\n3. Integrating Authorities will need to be accredited to undertake high risk projects."},{"id":183,"title":"Integrating Authorities","heading":"What is an \u2018integrating authority\u2019?","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#what-is-an-\u2018integrating-authority\u2019?","content":"\r\n4. An Integrating Authority is the single agency ultimately accountable for the implementation of a statistical data integration project. Integrating authorities must ensure that risks have been assessed, managed and mitigated throughout the duration of the project, in line with the agreed requirements of data custodians. Integrating authorities, along with the data custodians, are responsible for achieving an appropriate balance between: \r\nmaximising the inherent value of Commonwealth data sources;\r\nminimising privacy concerns associated with the use of data once it is received by the integrating authorities and after it has been integrated; and\r\nfacilitating the use of this data within the constraints of privacy and legislation.\r\n5. The Commonwealth\u2019s data integration arrangements are shown in Figure 1 \u2013 Appendix 1. This provides a stylised representation of how integrating authorities fit within the arrangements, and their interactions with data custodians and data users. The choice of integrating authority will be based on a consultative process led by the data custodian(s), taking into account any preferences of the data users. The data custodian(s) need to give in principle approval for the project to proceed before an integrating authority is appointed. \r\n6. For some data integration projects, it is possible that the integrating authority may have multiple roles where the integrating authority may also be a data custodian (e.g., a Commonwealth agency) and/or the data user. When an entity has more than one role, appropriate internal governance and project documentation, consistent with the Commonwealth principles and governance arrangements for data integration should be in place. "},{"id":184,"title":"Integrating Authorities","heading":"The rights and responsibilities of integrating authorities","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#the-rights-and-responsibilities-of-integrating-authorities","content":"\r\n7. Integrating authorities have a number of key \u2018rights and responsibilities\u2019 around the management of datasets for data integration projects. These form the basis for how they will work collaboratively with other participants involved in data integration projects. \r\n8. The key rights and responsibilities of integrating authorities in relation to data custodians are listed below. \r\nIt is the responsibility of integrating authorities to assure the data custodians that they have the necessary legislative protections in place prohibiting disclosure of identifiable data, other than where allowed by law. For high risk projects, the accredited Integrating Authority must be bound by the Commonwealth Privacy Act (or a state/territory equivalent) and be subject to criminal penalties for a breach of legislation with regard to an unauthorised disclosure of information. For low and medium risk projects, integrating authorities must have a policy framework in place to ensure that no identifiable data is disclosed, other than where allowed by legislation, to the satisfaction of data custodian requirements.\r\nIt is the responsibility of integrating authorities to ensure that the project is feasible and that all necessary approvals are obtained (for example, Ethics Committee approvals), before the data custodians give final approval for the project. This may also include undertaking a Privacy Impact Assessment for projects that present a very high risk, unless this has been completed by the data custodians as part of the risk assessment process.\r\nIntegrating authorities are required to safely manage data entrusted to them by data custodians throughout the project life cycle and in accordance with any special requirements of data custodians.\r\nIt is the right of integrating authorities to receive quality-assured data from data custodians.\r\nIt is the responsibility of integrating authorities to provide data linkage, merging and access services on behalf of data custodians.\r\nWhere the Cross Portfolio Data Integration Oversight Board advises on amendments to \u2018high risk\u2019 projects (or where a concern is raised), integrating authorities, data custodians and data users will need to collaborate on how to make improvements to such project(s).\r\nIntegrating authorities may collaborate with data custodians on the content of training material provided to data users. Input, advice and assistance to such training will be provided at the discretion of data custodians.\r\nThe integrating authority is responsible for using the Public Register of Data Integration Projects (launched in December 2012) to register any data integration project which is done for statistical and research purposes and involves Commonwealth data. The integrating authority will consult with the data custodian(s) when preparing the information to be submitted for registration.\r\n9. Integrating authorities also have rights and responsibilities in relation to data users. \r\nIt is the responsibility of integrating authorities to facilitate appropriate training courses for data users. This training will cover high level statistical integration principles, governance and institutional arrangements, data protocols (e.g., ethical approval processes in the case of human-based health research), legislative frameworks and security requirements.\r\nIntegrating authorities should always consider intellectual property rights when deciding whether they are able to provide access to data for a particular project that would involve using any externally owned software or other technology for transmission of data to a data user or allowing the data user to use such software.\r\nIntegrating authorities in conjunction with data custodians are responsible for consulting with data users on any material changes or updates to a data integration project (regardless of whether changes originate from data custodians or integrating authorities). This will occur before data users start examining integrated datasets.\r\nIntegrating authorities are responsible for assessing the technical feasibility of data integration projects and advising data users of outcomes.\r\nIt is the responsibility of integrating authorities to provide integrated datasets to data users, along with full information on cost recovery policies or fee-for-service charges (where applicable).\r\nIntegrating authorities must stipulate data access arrangements for data users, subject to written approval from all data custodians and in line with their requirements.\r\nIt is the right of integrating authorities to be paid by data users for the provision of data integration services (where cost recovery or fee-for-service charges apply).\r\nIntegrating authorities may collaborate with data custodians and data users on how to make improvements to \u2018high risk\u2019 project(s), based on advice provided by the Cross Portfolio Data Integration Oversight Board."},{"id":185,"title":"Integrating Authorities","heading":"The role of Integrating Authorities in data integration projects","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#the-role-of-integrating-authorities-in-data-integration-projects","content":"\r\n10. The four main roles of an Integrating Authority are listed below: \r\nNegotiating and implementing agreements with data custodians to achieve adequate control and manage risk appropriate to their datasets, as well as entering into agreements with data users;\r\nImplementing safe and effective arrangements for data integration projects involving the use of Commonwealth data for statistical and research purposes;\r\nManaging datasets for the duration of the project, including the provision of suitable access for data users and ensuring that the agreed data retention and/or data destruction policies are carried out; and\r\nProviding transparency in its operation."},{"id":186,"title":"Integrating Authorities","heading":"(1) Negotiating and implementing agreements with data custodians to achieve adequate control and manage risk appropriate to their datasets, as well as entering into agreements with data users ","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#(1)-negotiating-and-implementing-agreements-with-data-custodians-to-achieve-adequate-control-and-manage-risk-appropriate-to-their-datasets,-as-well-as-entering-into-agreements-with-data-users","content":"\r\n11. Integrating authorities will need to enter into agreements with data custodians and data users for data integration projects. This agreement may take the form of a contract, Memorandum of Understanding or other arrangement as appropriate for the parties concerned. When the data custodian and the integrating authority is the same agency, appropriate internal governance arrangements, rather than an agreement, will need to be in place. This agreement or arrangement will be administered by the integrating authority on behalf of every data custodian involved in the data integration project. \r\n12. Agreements with data custodians will cover: \r\nThe provision of secure arrangements by integrating authorities to ensure appropriate management and security of the data;\r\nThe use of data protocols that balance risk and public benefit (e.g., the use of ethics committees for human-based health research);\r\nThe use of control mechanisms, in collaboration with data custodians, to assess and ensure that outputs from the statistical data integration are not likely to enable the identification of individuals or businesses;\r\nGovernance protocols to investigate and resolve anomalies, outliers and data quality concerns, along with any software issues;\r\nSpecial conditions that must be adhered to by data users as stipulated by data custodians; and\r\nThe use of communication, technology, training and other processes to ensure that information likely to enable the identification of individuals or organisations is not disclosed.\r\n13. Agreements with data users will cover: \r\nInformation on penalties for the identification (or re-identification) of individuals or businesses, the misuse of data or violation of data access arrangements;\r\nDetails on cost recovery policies or fee-for-service charges of integrating authorities, where applicable. Fees will be set at the discretion of integrating authorities and may reflect local practices and arrangements;\r\nSpecific details on governance protocols for examining data quality and software issues; and \r\nAny special conditions which must be adhered to by data users."},{"id":187,"title":"Integrating Authorities","heading":"(2) Implementing safe and effective arrangements for data integration projects involving the use of Commonwealth data for statistical and research purposes","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#(2)-implementing-safe-and-effective-arrangements-for-data-integration-projects-involving-the-use-of-commonwealth-data-for-statistical-and-research-purposes","content":"\r\n14. Integrating authorities are required to: \r\nprovide a \u2018trusted\u2019 single accountability point for the implementation of each statistical data integration project;\r\nhave a high level of relevant expertise, including a strong understanding of, and capability for, maintaining security (e.g., appropriate level of building security, security clearances for staff and mechanisms to monitor the compliance of data users);\r\nhave the technical infrastructure necessary to undertake data integration projects;\r\ndemonstrate a consistently high standard of behaviour by all employees based on a strong culture and set of values;\r\ndemonstrate how any conflict of interest will be managed;\r\nhave the policy and legislative coverage deemed necessary to provide adequate protection (examples of policies include data linkage protocols, data custodian policies and data access arrangements);\r\nadhere to the separation principle for high risk projects and optionally as best practice for low or medium risk projects (e.g., the separation of identifiers used in linkage activities, such as date of birth, from remaining information relating to the individual, such as clinical or benefit information) (Endnote 2);\r\nensure that outputs from the statistical data integration (in particular, integrated datasets) are not likely to enable the identification of individuals or businesses (e.g., through directly-programmed aggregation and/or manual reviews of outputs released from a data integration project);\r\nprovide information on statistical disclosure control techniques used to minimise the risk of identification of individuals or businesses when multiple datasets are combined; and\r\nprovide secure data access arrangements (e.g., data laboratories, remote access procedures). "},{"id":188,"title":"Integrating Authorities","heading":"(3) Managing datasets for the duration of the project, including the provision of suitable access for data users and ensuring that the agreed data retention and/or data destruction policies are carried out","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#(3)-managing-datasets-for-the-duration-of-the-project,-including-the-provision-of-suitable-access-for-data-users-and-ensuring-that-the-agreed-data-retention-and/or-data-destruction-policies-are-carried-out","content":"\r\n15. Integrating authorities are required to: \r\nmanage data for the entire duration of the project, including implementing agreed data retention and/or data destruction policies;\r\nensure datasets are managed in a way that gives the community and businesses confidence that no individual or organisation is likely to be identified;\r\nensure good data management practices, including clear documentation, the use of standard definitions and classifications, and the maintenance of appropriate metadata, including quality attributes of the data;\r\nensure that access to outputs from statistical data integration would be limited to those which are not only de-identified, but which are also not likely to enable the identification of individuals or businesses;\r\ngrant broad and flexible access to data users, subject to the above constraints, and the agreements with data custodians;\r\nwork with data users to facilitate the effective use of this data within the constraints of privacy and legislation; and\r\nwhere applicable, implement fee-for-service charges or cost-recovery mechanisms to cover all or part of the costs (recognising that there are costs associated with creating integrated datasets, managing data access arrangements and conducting quality assurance checks), and provide information to data users (i.e., researchers) on fee-for service or cost-recovery policies. It is up to the discretion of integrating authorities as to whether they charge for the provision of data integration services. Some integrating authorities may be influenced by the existence of local practices and arrangements."},{"id":189,"title":"Integrating Authorities","heading":"(4) Providing transparency in its operations","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#(4)-providing-transparency-in-its-operations","content":"\r\n16. Integrating authorities are required to: \r\nensure appropriate governance arrangements are in place;\r\nhave the ability to transparently apply sanctions for unauthorised disclosure or inappropriate use of the data as required;\r\nwork collaboratively together, where appropriate, to share knowledge and infrastructure; \r\nensure stakeholders and the community are kept informed of any statistical data integration project by registering the project on the Public Register of Data Integration Projects;\r\npublish information on cost recovery and fee-for-service policies, where applicable;\r\nundertake audits and checks to evaluate security; and\r\npublish other relevant documents (e.g., data retention statements)."},{"id":190,"title":"Integrating Authorities","heading":"Requirements for integrating authorities handling \u2018high risk\u2019 projects","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#requirements-for-integrating-authorities-handling-\u2018high-risk\u2019-projects","content":"\r\n17. The governance and institutional arrangements for data integration involving Commonwealth data recognise that it is the large, complex projects involving sensitive data which engender the major systemic risk to government information based activities across the board. A systematic approach to monitoring and managing this risk has been agreed by the Cross Portfolio Data Integration Oversight Board. \r\n18. For each high risk project, an assessment of the Legal and policy framework for IAs undertaking high risk projects must be made by data custodians and integrating authorities to ensure that there is authorisation to release the data to the integrating authority (by legislation or consent) and that there are appropriate legal protections in place prohibiting the integrating authority from disclosing identifiable data. \r\n19. Additionally, integrating authorities undertaking high risk projects will also need to be accredited. Accredited Integrating Authorities are assessed by the Oversight Board as having the infrastructure and capability to undertake high risk data integration projects by meeting a set of criteria agreed by the Commonwealth Portfolio Secretaries including, for example, being subject to the Privacy Act 1988 or a state equivalent. A full description of the accreditation criteria can be found in the interim accreditation process document. "},{"id":191,"title":"Integrating Authorities","heading":"Requirements for integrating authorities handling low and medium risk projects","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#requirements-for-integrating-authorities-handling-low-and-medium-risk-projects","content":"\r\n20. For medium and low risk projects, data custodians and integrating authorities will need to assess the Legal and policy framework for IAs undertaking low and medium risk projects for each project to ensure there is authorisation to release the data to the integrating authority and that the integrating authority has the appropriate procedures and policy framework in place to ensure that no identifiable data is disclosed. \r\n"},{"id":192,"title":"Integrating Authorities","heading":"Appendix 1","path":"./data-integration/roles-and-responsibilities/integrating-authorities.html#appendix-1","content":"\r\n"},{"id":193,"title":"Statistical Data Integration","heading":"What is statistical data integration?","path":"./data-integration/statistical-data-integration.html#what-is-statistical-data-integration?","content":"\r\nStatistical data integration involves combining information from different administrative and/or survey sources to provide new datasets for statistical and research purposes.\r\nA safe and effective environment for statistical data integration involving Commonwealth data"},{"id":194,"title":"Statistical Data Integration","heading":"A safe and effective environment for statistical data integration involving Commonwealth data","path":"./data-integration/statistical-data-integration.html#a-safe-and-effective-environment-for-statistical-data-integration-involving-commonwealth-data","content":"\r\nIn 2010, the Secretaries Board (i.e. heads of all Commonwealth government agencies and the Australian Public Service Commission) endorsed a set of principles to govern integration of Commonwealth data for statistical and research purposes, as well as a set of governance and institutional arrangements to support these principles.\r\nAn important part of the governance and institutional arrangements is being able to hold one agency accountable for the safe implementation of a data integration project. To make this happen, an integrating authority must be appointed for every data integration project involving Commonwealth data. For data integration proposals that involve Commonwealth data and are considered 'high risk', an accredited Integrating Authority must be used.\r\nInitial implementation"},{"id":195,"title":"Statistical Data Integration","heading":"Initial implementation","path":"./data-integration/statistical-data-integration.html#initial-implementation","content":"\r\nInitial implementation of the Commonwealth arrangements commenced on 1 July 2014.\r\nProjects in scope"},{"id":196,"title":"Statistical Data Integration","heading":"Projects in scope","path":"./data-integration/statistical-data-integration.html#projects-in-scope","content":"\r\nIn July 2015, the Oversight Board endorsed amendments to the Scope of the Commonwealth arrangements for data integration.\r\nA project is now in scope if it meets all of the following criteria:\r\nIs statistical and research in nature;\r\nThat is, integration for non-statistical purposes (such as delivery of services to particular individuals, compliance monitoring, incident investigation or regulatory purposes) is out of scope as these activities have different processes and legislative requirements governing them.\r\n\r\nAND\r\n\r\nHas cross portfolio status;\r\nThat is, involves two or more data custodians, where at least one is Commonwealth.\r\n\r\nAND\r\n\r\nInvolves users beyond the Commonwealth data custodian(s) participating in the project;\r\nFor example, the intended use by other Commonwealth agencies, state& territory governments, academic researchers or the public.\r\n\r\nAND\r\n\r\nDerives a benefit from the application of the Commonwealth data integration arrangements.\r\nThat is, utilising a structured framework to maximise the use of public data assets, safeguard privacy and maintain trust in Government around managing data appropriately for statistical and research purposes.\r\nNote: Where a data integration project is assessed as high risk post mitigation (see Risk) the integrating authority must be accredited.\r\nOnce approved all in scope projects should be registered on the Public Register of data integration projects."},{"id":197,"title":"Creating an Account","heading":"Creating an Account","path":"./getting-started/creating-an-account.html#creating-an-account","content":"\r\nIf you will not be publishing data to data.gov.au, there is no need for a user account as all datasets can be accessed without an account.\r\nIf you intend to publish data to data.gov.au, you will need to register an account with an email belonging to a federal, state or local government organisation (i.e. email ending in .gov.au or .edu.au).\r\nYou must be a member of the organisation and have appropriate permission from your organisation to publish data on their behalf. You will also be required to request publishing permissions from the data.gov.au support staff.\r\nData.gov.au requires all new data custodians to get sign off from their organisation before creating a publishing account. The data.gov.au team reviews publisher accounts periodically to ensure appropriate access to publishing on data.gov.au is maintained.\r\nWe strongly recommend that you do not use an individual\u2019s email address for the main management account for your data.gov.au organisation. It is much better to use a shared inbox as it provides for continuity should the named data custodian change.\r\nTo create an account, email support@data.gov.au (template within) to verify who you are and that you wish to be granted publishing privileges. "},{"id":198,"title":"Creating an Account","heading":"Opportunity for councils","path":"./getting-started/creating-an-account.html#opportunity-for-councils","content":"\r\nCouncils joining data.gov.au can follow the standards and recommendations published at opencouncildata.org.\r\nThe Open Data Council\u2019s initiative aims to maximise reuse and interoperability of datasets by promoting the release of specific high-value, commonly-available datasets, with standard data schemas.\r\nThe goal is that datasets can be easily joined up for greater value (for example, state-wide register of trees) and apps developed for one dataset will work across council boundaries (for example, a bin night reminder app).\r\nThe standards are created and refined by a working group of local government representatives, which is free and open for anyone to join. \r\nResetting your password"},{"id":199,"title":"Creating an Account","heading":"Resetting your password","path":"./getting-started/creating-an-account.html#resetting-your-password","content":"\r\nIf you already have an account, go to https://data.gov.au/user/login to change your password. "},{"id":200,"title":"Enabling Accessible Open Data","heading":"Enabling accessible open data","path":"./getting-started/enabling-accessible-open-data.html#enabling-accessible-open-data","content":"\r\nOpen data is about giving open access to data that is:\r\nStructured \u2013 The data is recorded in a uniform way based on a common model. This can be as simple as a spreadsheet with rules around how the data is recorded. For example, if one of the inputs is the state or territory that a program is run in, there could be a rule that the state is recorded as \u2018WA\u2019 rather than \u2018Western Australia\u2019 or \u2018Wstn Aus\u2019.\r\nMachine Readable \u2013 The data is digitised and available in a format that can be read automatically by machines for retrieval, downloading, indexing and searching.\r\nLicenced to minimise the limits on how people can use and redistribute the data.\r\nThere are three broad data types found in Government Agencies:\r\nRaw data generated out of business as usual activities \u2013 such as spatial data from a program, energy ratings data, crime statistics, administration data, etc. Often this data is stored in databases and primarily used in business applications.\r\nProcessed data \u2013 new data that results from a process such as tables from annual reports, FOI logs, other data generated for the functions and running of agencies. This could also be an aggregate view of a raw data set, fit for public access.\r\nSystem data \u2013 data that is automatically generated from other processes such as web analytics, project management, access logs and other systems.\r\nIdentifying different data across your organisation means getting out of the traditional data teams and looks at other datasets that exist and how you can leverage them to improve services, policies and efficiencies."},{"id":201,"title":"Managing your Organisation","heading":"Editing your organisation\u2019s information","path":"./getting-started/managing-your-organisation.html#editing-your-organisation\u2019s-information","content":"\r\nEach entity has its own \u201Corganisation\u201D in CKAN. The organisation is the name under which all of your entity/jurisdiction datasets are published and as the entity representative, you will have administrator privileges to your organisation.\r\n\r\nThis means you can edit information to do with your organisation, add or remove other publishers from your organisation and most importantly, you can add, edit and delete datasets belonging to your organisation.\r\n\r\nIf you have a Machinery of Government (MoG) change, you may be required to change your organisation name and details. DPMC recommends you have your organisation logo and some descriptive text about your organisation.\r\n\r\nTo update your organisation\u2019s information, simply follow the below instructions:\r\nLog in as the organisation administrator by visiting your\u202Forganisation's pageSee image\r\n\r\n\r\nClick the\u202FManage\u202Fbutton located near top right of the page See image\r\n\r\n\r\nIn the Edit tab, you\u2019ll be able to change the following attributes associated with your organisation: See image\r\n\r\nName: The name displayed to users for your organisation\r\nURL: The location at which your organisation can be found on data.gov.au.The URL also acts as an identifier for your organisation and every organisation must have a unique URL\r\nImage URL: The crest to be displayed alongside your organisation\u2019s name. To ensure clarity and uniformity we recommend the image be 350 x 350 pixels\r\nParent: The parent entity of your organisation \u2013 can be used when a specific section of an organisation is required to publish a large volume (100+) of datasets\r\nJurisdiction: The jurisdiction to which your organisation belongs\r\nGeospatial Coverage: The area covered by your organisation. Can be plain text (Australia, Victoria, Brisbane City, etc) but can also receive GeoJSON as input. For example a bounding box around Australia could be represented as: :: {\"type\": \"Polygon\", \"coordinates\": [[[112.0, -44.0], [154.0, -44.0], [154.0, -9.0], [112.0, -9.0], [112.0, -44.0]]]}\r\nWebsite: Your organisation\u2019s website\r\nEmail: A generic contact point for your organisation. We strongly recommend you use a shared inbox for this field\r\nTelephone: A generic phone contact point for your organisation\r\n\r\nOnce you have made the required changes click the\u202FSave Organisation\u202Fbutton See image"},{"id":202,"title":"Managing your Organisation","heading":"Adding users to your organisation","path":"./getting-started/managing-your-organisation.html#adding-users-to-your-organisation","content":"\r\nOnce the user has registered on data.gov.au, log in as the organisation Admin account:\r\nLog in as the organisation administrator by visiting your\u202Forganisation's pageSee image\r\n\r\n\r\nClick the\u202FManage\u202Fbutton located near top right of the pageSee image \r\n\r\n\r\nClick the\u202FMembers\u202Ftab button located on the top centre of the page See image\r\n\r\n\r\nClick the\u202F+ Add Member\u202Fbutton See image\r\n\r\n\r\nSelect the drop down under\u202FExisting User:\u202Fand type in the username of the account you wish to add as an uploader See image\r\n\r\n\r\nSelect a\u202FRole\u202Ffrom the dropdown - Member, Editor or AdminSee image \r\n\r\nMembers\u202F- are able access all datasets, including those set to private, under the organisation but will not be able to edit content\r\nEditors\u202F- can create, edit and delete datasets and organisational information\r\nAdmin\u202F- can perform the same functions as editors and can also assign privileges to other users\r\n\r\nClick\u202FAdd Member\u202Flocated to the bottom right of the page See image"},{"id":203,"title":"Managing your Organisation","heading":"Removing users from your organisation","path":"./getting-started/managing-your-organisation.html#removing-users-from-your-organisation","content":"\r\nLog in as the organisation administrator by visiting your\u202Forganisation's pageSee image\r\n\r\n\r\nClick the\u202FManage\u202Fbutton located near top right of the pageSee image \r\n\r\n\r\nClick the\u202FMembers\u202Ftab button located on the top centre of the pageSee image \r\n\r\n\r\nFrom the list of\u202Fmembers,\u202Flocate the user you are looking to remove and click the\u202Fred 'x'\u202FbuttonSee image \r\n\r\n\r\nYou\u2019ll be asked to\u202FConfirm\u202Fthat you\u2019d like to remove the userSee image "},{"id":204,"title":"Automated Publishing","heading":"Automated Publishing","path":"./publishing-data/automated-publishing.html#automated-publishing","content":"\r\nData.gov.au has built-in capabilities to enable custodians processes in automating the publication of datasets through either:\r\nHarvesting of own government portal (see Harvested Portals)\r\nUtilising the API\r\nContact the support team at support@data.gov.au to discuss setting up a harvest schedule.\r\nDocumentation on the API can be found within the official CKAN API documentation as this is the Data Management System data.gov.au is built upon.\r\nBefore commencing your own development of an application to hook into our API, it is recommended to do the following:\r\nRetrieve API Key \u2013 Found within Account > Manage\r\nManually publish the dataset once to retrieve the URL address\r\nBasic examples of various applications utilising the API can be found on our GitHub page"},{"id":205,"title":"Manual Publishing","heading":"Manual Publishing","path":"./publishing-data/manual-publishing.html#manual-publishing","content":"\r\nLog in with an authenticated account\r\nBrowse to Datasets (top menu)See image\r\n\r\n\r\nClick\u202FAdd DatasetSee image\r\n\r\n\r\nOn the first page you\u2019ll be asked to complete fields to describe your data (the metadata):Title\u202F(required): Name of the dataset.\r\nDescription: Descriptive information about the dataset can also include further information or caveats pertaining to the data.\r\nKeywords: Some keywords (or tags) that describe your data.\r\nLicense\u202F(required): A dropdown of available licenses for data.gov.au (the default is Creative Commons Attribution 3.0 Australia)\r\nOrganisation: A dropdown of organisations you can publish to. Most users can only publish to a single organisation. This will be automatically filled in.\r\nVisibility: Whether the dataset will be viewable to all users once complete. The default is private.\r\nGeospatial Coverage\u202F(required): inherited from organisation metadata, this is the area which the data covers. It can be;a point/polygon (Well-known text);\r\nan administrative boundary API; or,\r\nGazetteer reference URL \u2013 Can be found by using Place Names (fsdf.org.au) and searching for a place. You can then copy the most appropriate location (Record ID) and paste into Data.gov.au\r\n\r\nTemporal Coverage From / To\u202F(required): the span of time from/to which the data is applicable. If the data applies only to a single point in time you should only fill in the Temporal Coverage From field.\r\nLanguage: the language in which the dataset is published. The default is English.\r\nData Status\u202F(required): the status of the data with regard to whether it is kept updated (active, yes) or historic (inactive, no).\r\nUpdate Frequency\u202F(required): how often the dataset is updated. Eg: Daily, Weekly, Never. (for remote machine readable files this field will be used to fetch new versions of this data).\r\nExpose User Contact Information: display additional contact information for the dataset.\r\nAGIFT Function/Theme: the\u202FAGIFT\u202Ftop level government function to which the dataset relates.\r\nPublisher: name of entity/publishing organisation. The default is set to the organisation\u2019s name.\r\nJurisdiction: name of the jurisdiction in which the dataset belongs. The default is set to the organisation\u2019s jurisdiction.\r\n\r\nClick\u202FNext: Add DataSee image\r\n\r\n\r\nClick\u202FUpload\u202Fand select the file you wish to add to the dataset. Add a description for this file and add the (likely) 3 letter file extension to the Format field. You can add additional files to the dataset by clicking\u202FSave and add another\u202Fand repeating the process.See image\r\n\r\n\r\nClick the\u202FFinish\u202Fbutton.See image"},{"id":206,"title":"Metadata Definitions and Requirements","heading":"Create Dataset (Page 1)","path":"./publishing-data/metadata-definitions-and-requirements.html#create-dataset-(page-1)","content":"\r\n\r\nTerm Name\r\n\r\nTerm Definition \r\n\r\nRequired Field \r\n\r\n\r\n\r\n\r\nTitleThe title or name given to the data setYes\r\n\r\nURLThe online location of the data set/sYes\r\n\r\nDescriptionA description of the content/and or components of the data setNo\r\n\r\nKeywordsA description of the content and/orcomponents of the data setNo\r\n\r\nLicenseLicense details giving official permission to use the data set/sYes\r\n\r\nUnpublishedMetadata stays at draft status; therefore, Users will not be able to view data sets or access links No\r\n\r\nOrganisationThe agency or division responsible for publication of the data represented in the data setYes\r\n\r\nVisibilityPublic: Data set is visible to all Users/Custodians\r\nPrivate: Data set is only available to Organisation/Custodian responsible for data set No\r\n\r\nGeospatial CoverageGeographical area covered by the data Yes\r\n\r\nTemporal Coverage From:Date of commencement of data set Yes\r\n\r\nTemporal Coverage To:Date of conclusion of data set Yes\r\n\r\nLanguageThe language the data set is presented in, default language is English No\r\n\r\nData StatusThe status of the data with regard to whether it is kept updated (active, yes) or historic (inactive, no)Yes\r\n\r\nUpdate FrequencyHow often the dataset is updated. Eg: Daily, Weekly, NeverYes\r\n\r\nExpose User Contact InformationWhether the user contact details should be public as well as the organisation contact detailsNo\r\n\r\nAdd AGIFT Function/ThemeThe Australian Government Interactive Functions Thesaurus (AGIFT) function to which the data set relatesYes\r\n\r\nAuthorThe agency; division; department or 3rd party authorised to release and/or share the data setNo\r\n\r\nContactContact email address for questions about content of published data setYes\r\n\r\nJurisdiction The country/region in which the server on which data is stored is locatedYes\r\n\r\nGeospatial TopicThe high level ISO1 9115 topics (drop down box)No\r\n\r\nData ModelsLinks to information on relevant data models, ontologies, taxonomies etc specific to your dataset.No\r\n\r\nFields of Research The Australian and New Zealand Standard Research Classification field or fields of research relevant to the dataset.No\r\nAdd Data (Page 2)"},{"id":207,"title":"Metadata Definitions and Requirements","heading":"Add Data (Page 2)","path":"./publishing-data/metadata-definitions-and-requirements.html#add-data-(page-2)","content":"\r\n\r\nTerm Name\r\n\r\nTerm Definition \r\n\r\nRequired Field \r\n\r\n\r\n\r\n\r\nFileUpload:  manually uploading data set file\r\nLink:  adding link to API data set URLNo\r\n\r\nNameName of the data setYes\r\n\r\nDescriptionUseful information explaining the content of the data set No\r\n\r\nFormatThe file type of the data set that is uploaded Yes (will automatically fill if left blank)\r\n\r\nExtract Resources from Zip FilesWhether any resources inside zip files should be extracted into separate resources.No\r\n\r\nData Last ModifiedThe date that the uploaded data file was last modifiedYes\r\n\r\n\r\n\r\nPrevious\r\n\r\nEnabling Accessible Open Data\r\n\r\n\r\nNext\r\n\r\nManual Publishing"},{"id":208,"title":"Recommended Data Formats","heading":"Recommended Data Formats","path":"./publishing-data/recommended-data-formats.html#recommended-data-formats","content":"\r\nOpen data is contingent upon the use of accessible data formats. The data.gov.au platform will host files of nearly any type and currently allows entities to publish multiple formats where appropriate or useful to users, though we strongly discourage the use of PDFs as they are not easily accessible. We recommend that you post tabular data in CSV if you want API access to be automatically generated for your dataset.\r\nSupported Filetypes"},{"id":209,"title":"Recommended Data Formats","heading":"Supported Filetypes","path":"./publishing-data/recommended-data-formats.html#supported-filetypes","content":"\r\nCurrently supported vector filetypes are: MapInfo TAB, KML, KMZ and SHP. Currently supported raster filetypes are: GeoTIFF and ESRI ArcGRID (ASCII and binary)\r\nFor the moment, other formats can be converted using the Feature Manipulation Engine (FME) or Geospatial Data Abstraction Library (GDAL). There is currently no limit for the size of a file uploaded, but whenever possible, please make the data.gov.au team aware should you need to upload a large file.\r\nClean Data"},{"id":210,"title":"Recommended Data Formats","heading":"Clean Data","path":"./publishing-data/recommended-data-formats.html#clean-data","content":"\r\nData.gov.au will only enable API or data visualisation for \u2018clean\u2019 CSV files. Make sure at least one of the data files you upload to your dataset is as clean as possible. This will make it easier for others to reuse.\r\nMake sure the CSV file has as few mistakes or bad data entries as possible. This means making sure all the dates are a common format and that there are no missing entries and no non-text data embedded.\r\nFor tabular data, you just want a spreadsheet with a single header row and then multiple fields. KML data has its own format that must be followed. \r\nCKAN specifically understands tabular and spatial data types and generates API access to such datasets, if the data files are clean. Clean means the datasets are raw and appropriately structured data. More information on clean data can be found\u202Fhere\r\nFor example: \r\n\r\n\r\nImportant Note: Due to the nature of our database if you would like to allow API access to your dataset you will need to keep your\u202Fcolumn headings under 63 characters.\r\nRemoving Author Metadata: It is possible that some filetypes will contain additional author metadata. It is possible to remove this metadata using the Windows interface. "},{"id":211,"title":"Recommended Data Formats","heading":"Compressing a CSV into a Zip","path":"./publishing-data/recommended-data-formats.html#compressing-a-csv-into-a-zip","content":"\r\nCompressing CSV's reduces the amount of time it takes to upload and download a file. This is particularly useful when a\u202FCSV\u202Fhas a large amount of data. \r\nFor windows users:\r\nBrowse to the relevant\u202FCSV\r\nSelect the file you wish to compress\r\nRight click on the\u202FCSV\r\nHover over\u202F\u201Csend to\u201D\r\nClick \"Compressed (zipped) file\"\r\nYou will now have a\u202FZIP\u202Ffile in the same folder as your original\u202FCSV\r\nPlease note that you should only compress one csv at a time if you are uploading it to data.gov.au.\r\nTo upload your newly created ZIP file follow the instructions on\u202FManual Publishing"},{"id":212,"title":"Recommended Data Formats","heading":"Spatial Data ","path":"./publishing-data/recommended-data-formats.html#spatial-data","content":"\r\nAt the end of 2013, we expanded the geospatial functionality of data.gov.au. These changes established additional and improved support specifically for spatial data services. This means data.gov.au can now present a spatial API endpoint for certain types of spatial files. An example of the new functionality can be found seen in the\u202FGeelong Roofprints dataset.\r\nWhen any of the supported filetypes are uploaded through the CKAN platform, they will automatically be added to the GeoServer. There should be no need for user intervention, but it can take up to 24 hours for the file to be ingested. We are looking at ways to make ingestion more immediate. (GeoJSON, WMS and WFS resources will be automatically added to spatial datasets if ingested correctly) \r\nSpatial data on data.gov.au is also viewable through the\u202FNationalMap. To access the visualisation, click the\u202FData\u202Fbutton on the left, then click\u202FData Providers and then click data.gov.au. It may take up to 24 hours for newly added datasets to become available on the National Map."},{"id":213,"title":"Recommended Data Formats","heading":"Uploading Spatial Data ","path":"./publishing-data/recommended-data-formats.html#uploading-spatial-data","content":"\r\nAt this time, data.gov.au only supports a single spatial file per dataset. If a dataset contains multiple spatial resources it will be ignored by the geoserver ingestor. Once the spatial file is successfully ingested into the geoserver data.gov.au will automatically generate a number of additional resources for the dataset. \r\nKML / KMZ files\r\nData.gov.au will accept either KML and KMZ files. Simply upload the file using the normal process as outlined in Manual Publishing.\r\nShape files\r\nBefore uploading a shape file you should zip all the relevant files into a single archive. When adding the zip file as a resource set the format to \u2018shp\u2019. \r\nColours / Styles / Symbology\r\nIt is possible that the incorrect display style for spatial data is displayed in the WMS preview. It is important to note that this does not modify the data as it is served via the WMS/WFS APIs. \r\nTo provide a custom display style, attach another data resource in \"SLD\" Styled Layer Definition format.\u202FClick to view resource.\r\nIt may be possible to convert ESRI .style/.lyr files to SLD.\u202FClick to view resource.\r\nIt is also possible to modify the default display type for the data for any user which has admin access to the GeoServer: \r\nPoint your browser to\u202Fhttps://data.gov.au/geoserver/web/\r\nIf required login using the form at the top of the page.\r\nFrom the admin screen, select the Layers link\r\nFrom here select the layer you\u2019d like to change by clicking the Layer Name\r\nSelect the Publishing tab\r\nFrom the Default Style dropdown select the style you\u2019d like to use\r\nScroll to the bottom of the page and click the Save button"},{"id":214,"title":"Recommended Data Formats","heading":"Spatial API Access","path":"./publishing-data/recommended-data-formats.html#spatial-api-access","content":"\r\nWeb Map Service (WMS) and Web Feature Service (WFS) API links will be created with the datasets when a supported filetype is added. Information about available methods can be found here\u202Fand\u202Fhere"},{"id":215,"title":"Updating a Dataset","heading":"Updating a dataset's metadata","path":"./publishing-data/updating-a-dataset.html#updating-a-dataset's-metadata","content":"\r\nBrowse to the relevant datasetSee image \r\n\r\n\r\nClick the\u202FManage\u202Fbutton located near top right of the pageSee image \r\n\r\n\r\nOn the subsequent page, the\u202Fmetadata associated\u202Fwith a dataset can be updated (Fields marked with\u202Fa red asterisk\u202Fare mandatory)See image \r\n\r\n\r\nOnce finished, click the\u202FUpdate Dataset\u202Fbutton at the bottom of the pageSee image "},{"id":216,"title":"Updating a Dataset","heading":"Adding additional resources to an existing dataset","path":"./publishing-data/updating-a-dataset.html#adding-additional-resources-to-an-existing-dataset","content":"\r\nBrowse to the relevant datasetSee image \r\n\r\n\r\nClick the\u202FManage\u202Fbutton located on the near top right of the pageSee image \r\n\r\n\r\nClick the\u202FResources\u202Flink at the top of the page See image \r\n\r\n\r\nClick the\u202F+ Add new resource\u202Fbutton See image \r\n\r\n\r\nIf uploading a file click the\u202FUpload\u202Fbutton See image \r\n\r\n\r\nIf linking to an existing service, file or site click the\u202FLink\u202Fbutton See image \r\n\r\nWhen linking to a file the user will be presented with an option to generate an API using the linked data. This option will only work with formats compatible with CKAN or Geoserver\r\n\r\nEnter a\u202FName\u202Ffor the resourceSee image \r\n\r\n\r\nIf required enter a specific\u202FDescription\u202Ffor the resource (markdown applies)See image \r\n\r\n\r\nEnter a\u202FFormat\u202F(filetype e.g., csv, kml, shp\u2026) for the resourceSee image \r\n\r\nData.gov.au will attempt to guess format of the file if the field is left blank\r\nFormat\u202Fdetermines which visualisation will be automatically attached to the resource\r\n\r\nIf left blank\u202FLast Modified\u202Fwill default to time of addition See image \r\n\r\n\r\nClick the\u202FAdd\u202FbuttonSee image "},{"id":217,"title":"Updating a Dataset","heading":"Updating a resource in an existing dataset","path":"./publishing-data/updating-a-dataset.html#updating-a-resource-in-an-existing-dataset","content":"\r\nBrowse to the relevant datasetSee image \r\n\r\n\r\nClick on the resource that requires an updateSee image \r\n\r\n\r\nClick the\u202FManage\u202Fbutton located on the near top right of the pageSee image \r\n\r\n\r\nClick the red\u202FRemove\u202Fbutton to remove the current version of the resourceSee image \r\n\r\n\r\nIf uploading an updated file click the\u202FUpload\u202FbuttonSee image \r\n\r\n\r\nIf updating a link to an existing service, file or site click the\u202FLink\u202FbuttonSee image \r\n\r\n\r\nIf required update the\u202FNameSee image \r\n\r\n\r\nIf required update the\u202FDescription\u202F(markdown applies)See image \r\n\r\n\r\nIf required update the\u202FFormat\u202F(filetype e.g., csv, kml, shp\u2026)See image \r\n\r\n\r\nIf left blank\u202FLast Modified\u202Fwill default to time of updateSee image \r\n\r\n\r\nClick the\u202FUpdate Resource\u202FbuttonSee image "},{"id":218,"title":"Updating a Dataset","heading":"Changing the order in which resources are displayed","path":"./publishing-data/updating-a-dataset.html#changing-the-order-in-which-resources-are-displayed","content":"\r\nBrowse to the relevant datasetSee image \r\n\r\n\r\nClick the\u202FManage\u202Fbutton located on the near top right of the pageSee image \r\n\r\n\r\nClick the\u202FResources\u202Flink at the top of the pageSee image \r\n\r\n\r\nClick the\u202FReorder resources\u202FbuttonSee image \r\n\r\n\r\nResources can now be reordered by dragging and dropping into a new positionSee image \r\n\r\n\r\nOnce finished click the\u202FSave order\u202FbuttonSee image "},{"id":219,"title":"Updating a Dataset","heading":"Deleting resources from a dataset","path":"./publishing-data/updating-a-dataset.html#deleting-resources-from-a-dataset","content":"\r\nDeleting a resource will mean that it is no longer available for use. If you are planning to remove a resource and replace it with an updated version, we recommend overwriting the resource. Updating a resource will mean its unique identifier will not change.\r\nBrowse to the relevant datasetSee image \r\n\r\n\r\nClick on the resource that is to be deleted See image \r\n\r\n\r\nClick the\u202FManage\u202Fbutton located on the near top right of the page See image \r\n\r\n\r\nClick the\u202FDelete\u202Fbutton See image \r\n\r\n\r\nClick the\u202FConfirm\u202Fbutton See image "},{"id":220,"title":"Updating a Dataset","heading":"A note on updating existing resources","path":"./publishing-data/updating-a-dataset.html#a-note-on-updating-existing-resources","content":"\r\nIf you wish to replace an existing resource with a new version, ensure that whenever possible, the new file continues to use the same structure for the document. Developers and others are able to access the resource via its unique identifier (eg: [ad5c6594-571e-4874-994c-a9f964d789df]). If you overwrite a resource with a new file which is formatted differently, or a different file type (replacing CSV with an XLS) you will run the risk of disrupting applications which utilise the resource.\r\nIf you plan to radically change the structure or format the data is delivered, you should consider adding the new file as a different resource to the existing dataset. This will allow developers to continue to use the existing resource\u2019s API while they make the necessary changes to their existing applications."},{"id":221,"title":"Contacting the Data Custodian","heading":"Contacting the Data Custodian","path":"./using-data-gov-au/contacting-the-data-owner.html#contacting-the-data-custodian","content":"\r\nAs the hosting platform for open data, we cannot edit or guarantee the quality and timeliness of data as it is owned by the data custodian.\r\nPlease note: The DGA support team will not respond to queries requesting further information on datasets.\r\nIf you have questions or need additional clarification on a specific dataset, please contact the organisation responsible for the data. The contact details can be located on the dataset page under Contact Point. If there is no direct contact, there will be prompts to assist you in locating the original data source contact.\r\n\r\nYou will also see on the data set page that there is an option to \u2018Ask a question about this dataset.\u2019 By clicking this link, you can complete the pre-populated prompts and send your query directly to the relevant organisation. \r\n\r\n"},{"id":222,"title":"Harvested Portals","heading":"Federal","path":"./using-data-gov-au/harvested-portals.html#federal","content":"\r\n\r\n\r\nName\r\n\r\nURL \r\n\r\nHarvest Schedule \r\n\r\nAustralian Institute of Marine Sciencehttps://www.aims.gov.au/dataAt 01:00 on every 3rd day-of-month\r\nAustralian Oceans Data Networkhttp://catalogue.aodn.org.au/geonetwork/srv/eng/catalog.search#/homeAt 01:30 on every 3rd day-of-month\r\nAustralian Urban Research Infrastructure Networkhttps://data.aurin.org.au/At 01:00 on every 3rd day-of-month\r\nBureau of Meteorologyhttp://www.bom.gov.au/At 13:00 on every 3rd day-of-month\r\nCSIRO Marlinhttps://marlin.csiro.au/At 03:30 on every 3rd day-of-month\r\nCSIROhttps://data.csiro.au/At 14:00 on every Saturday\r\nDepartment of the Environment and Energyhttps://www.dcceew.gov.au/At 13:30 on every 3rd day-of-month\r\nGeoscience Australiahttps://ecat.ga.gov.au/At 05:00 on every 3rd day-of-month\r\nTerrestrial Ecosystem Research Networkhttps://www.tern.org.au/At 11:00 on every 3rd day-of-month\r\n\r\nState"},{"id":223,"title":"Harvested Portals","heading":"State","path":"./using-data-gov-au/harvested-portals.html#state","content":"\r\n\r\n\r\nName\r\n\r\nURL \r\n\r\nHarvest Schedule \r\n\r\nACT Government data.act.gov.auhttps://www.data.act.gov.au/At 00:00 on every 3rd day-of-month\r\nACT Government ACTMAPihttps://actmapi-actgov.opendata.arcgis.com/At 00:45 on every 3rd day-of-month\r\nMelbourne Datahttps://data.melbourne.vic.gov.au/At 06:00 on every 3rd day-of-month\r\nMelbourne Water Corporationhttps://data-melbournewater.opendata.arcgis.com/At 04:30 on every 3rd day-of-month\r\nMineral Resources Tasmaniahttps://www.mrt.tas.gov.au/homeAt 06:30 on every 3rd day-of-month\r\nNew South Wales Governmenthttps://data.nsw.gov.au/At minute 20 on every hour\r\nNSW Land and Propertyhttps://sdi.nsw.gov.au/At 09:00 on every 3rd day-of-month\r\nQueensland Governmenthttps://data.qld.gov.au/At minute 30 on every hour\r\nSouth Australia Governmenthttps://data.sa.gov.au/At minute 40 on every hour\r\nTasmania TheListhttps://www.thelist.tas.gov.au/app/content/dataAt 10:30 on every 3rd day-of-month\r\nVictoria Governmenthttps://discover.data.vic.gov.au/dataset/At minute 50 on every hour\r\nWestern Australia Governmenthttps://catalogue.data.wa.gov.au/At minute 55 on every hour\r\n\r\nCouncil"},{"id":224,"title":"Harvested Portals","heading":"Council","path":"./using-data-gov-au/harvested-portals.html#council","content":"\r\n\r\n\r\nName\r\n\r\nURL \r\n\r\nHarvest Schedule \r\n\r\nBrisbane City Councilhttps://www.data.brisbane.qld.gov.au/At minute 10 on every day-of-month\r\nBundaberg Regional Councilhttps://opendata-bundabergrc.hub.arcgis.com/At 13:30 on every day\r\nCardinia Shire Councilhttps://data-cscgis.opendata.arcgis.com/At 11:30 on every day\r\nCity of Darwinhttps://open-darwin.opendata.arcgis.com/At 12:00 on every 3rd day-of-month\r\nCity of Hobart Open Data Portalhttps://data-1-hobartcc.opendata.arcgis.com/At 02:30 on every 3rd day-of-month\r\nCity of Launceston Open Datahttps://opendata.launceston.tas.gov.au/At 03:00 on every 3rd day-of-month\r\nGBRMPA Geoportalhttps://geoportal.gbrmpa.gov.au/At 15:30 on every 3rd day-of-month\r\nLogan City Councilhttps://data-logancity.opendata.arcgis.com/At 05:30 on every 3rd day-of-month\r\nMoreton Bay Regional Council Data Portalhttps://datahub.moretonbay.qld.gov.au/At 07:00 on every 3rd day-of-month\r\nSouthern Grampians Shire Councilhttps://www.connectgh.com.au/data.jsonAt 12:30 on every 3rd day-of-month"},{"id":225,"title":"Searching for Data","heading":"Searching for Data","path":"./using-data-gov-au/searching-for-data.html#searching-for-data","content":"\r\nData.gov.au provides several different ways to find data on our site. You can search for data using the following mechanisms:"},{"id":226,"title":"Support","heading":"Support","path":"./using-data-gov-au/support.html#support","content":"\r\nIf you require support in relation to any of data.gov.au\u2019s functionalities or you are having issues downloading datasets, please contact the support team at support@data.gov.au. You can also find the 'Contact Us' support link on the data.gov.au homepage. \r\nPlease note that whilst the support team will endeavour to get back to you as soon as possible, we advise that you allow up to five business days for the team to respond.\r\n"},{"id":227,"title":"Using NationalMap","heading":"What is the NationalMap","path":"./using-data-gov-au/using-nationalmap.html#what-is-the-nationalmap","content":"\r\nThe NationalMap is a website for map-based access to government spatial data.\r\nIt is designed to:\r\nProvide easy access to data for government, business and the public\r\nIntegrate datasets into a \u2018front end map\u2019 for data.gov.au\r\nProvide an open framework of geospatial data services that supports commercial and community innovation\r\nProvide agencies with an easy map to embed on their own websites\r\n\r\n\r\nHow do you use the data?"},{"id":228,"title":"Using NationalMap","heading":"How do you use the data?","path":"./using-data-gov-au/using-nationalmap.html#how-do-you-use-the-data?","content":"\r\n\r\nTo view a data set on the NationalMap, go to https://nationalmap.gov.au/, select Data then National Data Sets. This will display a list of available data topics.\r\nOther tips:\r\nTo zoom to a data set\u2019s area on the map, click on the name of the data set.\r\nFor detail about specific information captured in a data set, click on the specific point, line or area on the map.\r\nFor detail about the entire data set, click \u2018info\u2019 next to the name of a data set for more information, conditions of use and a link to download the data.\r\nNationalMap is best used with a browser with WebGL support such as the latest versions of Google Chrome, Mozilla Firefox and Internet Explorer 11. It will work with limited functionality in older browsers such as Internet Explorer 9 and Internet Explorer 10.\r\nPossible uses for the NationalMap include:\r\nFinding data sets and services (for any data set or service visible in the NationalMap, click \"info\" to view how to access the data set/service directly).\r\nSet up a Web Map Service (WMS) or Web Feature Service (WFS) and load the URL for that service into NationalMap. For example, you can use the open source software Geoserver to do this or use one of many commercial GIS systems such as ESRI ArcGIS Server, Pitney Bowes' Mapinfo or Google Maps Engine and enable WMS and/or WFS services from it.\r\nBuild a website that uses the value-add service API. Email nationalmap@lists.csiro.au to find out how.\r\n\r\nHow do you add data?"},{"id":229,"title":"Using NationalMap","heading":"How do you add data?","path":"./using-data-gov-au/using-nationalmap.html#how-do-you-add-data?","content":"\r\n\r\nGovernment data can be added to the NationalMap by uploading it to data.gov.au in a common spatial data format. The main data formats supported by the NationalMap are GeoJSON, KML, KMZ and CSV (with latitude and longitude columns).\r\nThe NationalMap routinely harvests spatial services from data.gov.au and FIND. It takes between 24 - 48 hours from when a spatial data set is uploaded to data.gov.au for it to appear on the NationalMap. If the issues is not resolved, email spatial@pmc.gov.au\r\nA data set can be added to NationalMap for a single session by dragging it on to the map or clicking on \u2018Add Data\u2019 under the Data tab. This is particularly relevant when working with personal, private or temporary data that cannot be uploaded to data.gov.au. Data added to a map in this way will not be saved on the NationalMap and cannot be shared using the share button on the site.\r\nFor large data sets that are better streamed than uploaded, email nationalmap@lists.csiro.au to discuss options for making data available in more detail.\r\n\r\nHow does the NationalMap work?"},{"id":230,"title":"Using NationalMap","heading":"How does the NationalMap work?","path":"./using-data-gov-au/using-nationalmap.html#how-does-the-nationalmap-work?","content":"\r\n\r\nThe NationalMap is a fully open architecture that provides a direct link between the user and the government department or agency who is the custodian of the data. For example, if you access data relating to \"broadband availability and quality\", you are accessing that directly from the Department of Communications and the Arts; when you access data relating to surface geology, it is accessed directly from Geoscience Australia.\r\nThe NationalMap itself does not store any data - it provides a map-based view to data that is stored by a growing number of government bodies.\r\n\r\nOpen source software"},{"id":231,"title":"Using NationalMap","heading":"Open source software","path":"./using-data-gov-au/using-nationalmap.html#open-source-software","content":"\r\n\r\nThe NationalMap was created with the following open source software. The developers contribute back to the software projects as appropriate.\r\nCesium (open source under the Apache 2.0 licence)\r\nLeaflet (open source under the simplified BSD licence)\r\nGeoserver (open source under the GNU GPL 2.0 licence)\r\njquery, URI.js, proj4js, html2canvas, knockout (all open source under the MIT licence)\r\nesri-leaflet.js (open source under the Apache 2.0 licence)\r\ntogeojson, Tilelayer.Bing.js (open source under the wtfpl ver 2)\r\nSee the Data61 Github page for more information about the NationalMap"}];